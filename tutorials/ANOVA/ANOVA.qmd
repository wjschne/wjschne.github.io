---
title: "ANOVA in R"
author: "W. Joel Schneider"
format: 
  html: 
    df-print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(easystats)
library(haven)
library(sjstats)
options(digits = 2)
```

# Load Packages

```{r load}
library(tidyverse)
library(easystats)
```

# Import Data and Create Labelled Factors



```{r import}
# File location
file <- "https://github.com/wjschne/EDUC5325/raw/master/Attachment.sav"


# Import SPSS data file using haven
# Also, change Attachment variable to a factor
d <- haven::read_spss(file) %>%
  mutate(Attachment = as_factor(Attachment))
```

# Descriptives

Let's look at the means and standard deviations for anxiety of each attachment group.

```{r summarize}
d %>% 
  summarize(Mean = mean(Anxiety_Questionnaire),
            SD = sd(Anxiety_Questionnaire), 
            .by = Attachment) 
```

# Plot



```{r plot, message=FALSE}
d |> 
  ggplot(aes(x = Attachment,
             y = Anxiety_Questionnaire)) +
  geom_violin() +
  stat_summary()
```

Just looking at the plot, we can see that the Ambivalent group has a higher mean anxiety than the other two groups. However, let's conduct a formal test of the difference of the group means.

# Create One-Way ANOVA

The `aov` (Analysis of Variance) function is what you want to use. The `anova` function is better used for comparing models. The dependent variable goes on the left, and any predictor variables are on the right hand side of the ~.

```{r fit}
fit <- aov(Anxiety_Questionnaire ~ Attachment, data = d)
```

## Diagnostic Plots

```{r assumptions}
#| fig-height: 9
check_model(fit)
```

None of the diagnostic checks raise any alarms. Specifically, the residuals are reasonably normal and have consistent variance acrross groups (i.e., the homogeneeity of variance assumption is reasonable).

## Summary

The base R function `summary` gives us most of what we might want to know.

```{r summary}
summary(fit)
```

We can see that overall model is significant, meaning that at least two groups have reliably different means. At this point we do not know which means differ, but from the plot we have a good guess that the Ambivalent group scores higher on the Anxiety Questionnaire than the other two groups.

A similar, but tidier display can be found with the `parameters` function:

```{r}
parameters(fit)
```


## Other Summary Functions

The overall "fit" or "performance" of the model:

```{r}
performance(fit)
```

* `AIC`: [Akaike's Information Criterion](https://en.wikipedia.org/wiki/Akaike_information_criterion)
* `AICc`: AIC with a correction for small sample sizes
* `BIC`: [Bayesian Information Criterion](https://en.wikipedia.org/wiki/Bayesian_information_criterion)
* `R2`: R-squared: [Coefficient of Determination](https://en.wikipedia.org/wiki/Coefficient_of_determination)
* `R2_adj`: [Adjusted r-squared](https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2)
* `RMSE`: Root mean squared error $=\sqrt{\frac{\sum_{i = 1}^{n}{e_i}}{n}}$
* `SIGMA`: Residual standard deviation (The SD of the residuals $=\sqrt{\frac{\sum_{i = 1}^{n}{e_i}}{n-k-1}}$) 


## Automated Interpretation

```{r}
report(fit)

```


## Post-hoc Tests

We would like to compare all means but control for family-wise error.

```{r contrasts, fig.height=8}
estimate_contrasts(fit)
estimate_contrasts(fit) |> 
  report()
```






