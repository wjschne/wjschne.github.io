<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>W. Joel Schneider</title>
<link>https://wjschne.github.io/assessingpsyche.html</link>
<atom:link href="https://wjschne.github.io/assessingpsyche.xml" rel="self" type="application/rss+xml"/>
<description>{{&lt; meta description-meta &gt;}}</description>
<generator>quarto-1.6.37</generator>
<lastBuildDate>Tue, 12 Sep 2023 04:00:00 GMT</lastBuildDate>
<item>
  <title>Overture Redux</title>
  <dc:creator>W. Joel Schneider</dc:creator>
  <link>https://wjschne.github.io/AssessingPsyche/2010-10-07-overture/</link>
  <description><![CDATA[ 





<p>The original title of this blog (<a href="https://assessingpsyche.wordpress.com/">Assessing Psyche, Engaging Gauss, Seeking Sophia</a>) was more of an aspiration than a description. To keep things simple, going forward the blog’s title will be just <em>AssessingPsyche</em>.</p>
<p>The purpose of this blog remains the same from the <a href="https://assessingpsyche.wordpress.com/2010/10/07/overture/">original post in 2010</a>:</p>
<blockquote class="blockquote">
<p>When we are at our best, clinicians skilled in psychological assessment see beyond the obvious and communicate something useful and true to a person who needs our help. Uncovering something true often requires a bit of science, sometimes a little math, and always a lot of empathy. Communicating what is true so that it is useful requires still more empathy and a bit of art. We facilitate in our clients a deeper understanding of what is happening to them and present to them a different vision of what they can be.</p>
<p>In this blog, I hope to communicate something useful and true to other professionals about psychological assessment. I hope that in communicating what I know, I will come to know more than I do now.</p>
</blockquote>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{schneider2023,
  author = {Schneider, W. Joel},
  title = {Overture {Redux}},
  date = {2023-09-12},
  url = {https://wjschne.github.io/AssessingPsyche/2010-10-07-overture/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-schneider2023" class="csl-entry quarto-appendix-citeas">
Schneider, W. J. (2023, September 12). Overture Redux.
<em>AssessingPsyche</em>. <a href="https://wjschne.github.io/AssessingPsyche/2010-10-07-overture/">https://wjschne.github.io/AssessingPsyche/2010-10-07-overture/</a>
</div></div></section></div> ]]></description>
  <guid>https://wjschne.github.io/AssessingPsyche/2010-10-07-overture/</guid>
  <pubDate>Tue, 12 Sep 2023 04:00:00 GMT</pubDate>
</item>
<item>
  <title>The RESCA-E Subtests Are Thoughtfully Designed and Highly Refined Measures of CHC Constructs</title>
  <dc:creator>W. Joel Schneider</dc:creator>
  <link>https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE.html</link>
  <description><![CDATA[ 





<section id="introduction" class="level1 page-columns page-full">
<h1>Introduction</h1>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Conflict of Interest Statement:</strong> <a href="https://www.academictherapy.com/support/assessments.tpl">ATP Assessments</a>, the publisher of the RESCA-E, commissioned me to write a descriptive account of the likely relations among the RESCA-E subtests and CHC Theory constructs. I billed them for the hours that I spent researching this topic and writing my thoughts on the matter. However, I was so impressed the the RESCA-E that I wanted to write a short review of it, and I also conducted additional analyses about its structure. Because ATP Assessments did not ask for my opinion about the quality of the RESCA-E nor for the statistical analyses I conducted, I did not bill for the many additional hours I spent on these activities. If I were not impressed with the RESCA-E, this document would have been much shorter.”)</p>
</div></div><p>The <a href="https://www.academictherapy.com/detailATP.tpl?action=search&amp;eqskudatarq=8995-7">Receptive, Expressive &amp; Social Communication Assessment–Elementary (RESCA-E)</a> is a new measure of language abilities for children in the elementary school years. The purpose of this review is to evaluate the RESCA-E in terms of the Cattell-Horn-Carroll Theory of Cognitive Abilities <span class="citation" data-cites="McGrew2005 Schneider2012">(CHC theory; McGrew, 2005; Schneider &amp; McGrew, 2012)</span>. However, some preliminary remarks about the test’s design are in order.</p>
<section id="first-impressions" class="level2">
<h2 class="anchored" data-anchor-id="first-impressions">First Impressions</h2>
<p>Modest elegance, by its nature, attracts little praise. I will do my part here to rectify this injustice. The RESCA-E test materials, stimuli, and protocols are designed for practical efficiency but sacrifice nothing in aesthetic appeal. This might not seem to matter, but it does. Spending time with ugly, frustrating test materials makes one yearn for early retirement.</p>
<p>The application of sound typographical principles has enhanced the readability and ease of use of the protocol; the whole document is thoughtfully coded by font, color, and shading. The protocol does not feel cramped; it has generous space for notes, yet no space is wasted. Sure, the designers could have shortened the protocol by making everything smaller and more compact, but that would have been <em>penny wise, pound foolish.</em> This same care and consistency was extended to everything in the test kit.</p>
</section>
<section id="looking-deeper" class="level2">
<h2 class="anchored" data-anchor-id="looking-deeper">Looking Deeper</h2>
<p>I do not know the test’s authors, Patricia Hamaguchi and Deborah Ross-Swain, and I have had no contact with them. Yet, I can tell something about their work process and their scholarly values. To someone who has never tried to design an ability test, it may not be obvious that the RESCA-E subtest items were labored over for untold hours until they were just right. In most test batteries I find several items (or whole subtests) that seem a bit off, like bum notes in a singer’s solo. I found none here. The items are so smoothly written that they draw no attention to themselves—no small feat.</p>
<p>Even more importantly, the item content reflects a deep understanding on the part of the authors of what matters in the evaluation of children. No item is merely easy or merely difficult, chosen to meet some psychometric need. No, each item is intended to measure something substantial and relevant to everyday functioning. A rare patience was required to keep working with each item until it was easy to understand, quick to administer, and simple to score, all the while remaining clinically relevant, yet psychometrically sound. For this accomplishment, Patricia Hamaguchi, Deborah Ross-Swain, and their associates at ATP Assessments deserve a tip of the hat and hearty congratulations.</p>
</section>
</section>
<section id="chc-theory-a-work-in-progress" class="level1 page-columns page-full">
<h1>CHC Theory: A Work in Progress</h1>
<p>Because a complete description of CHC theory can be found in <a href="http://www.iapsych.com/articles/schneider2012.pdf">Schneider and McGrew (2012)</a>, no space will be wasted on a summary here. Figure&nbsp;1 displays the broad abilities arranged conceptually.</p>
<div class="cell fig-cap-location-bottom page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-chc" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-cap-location="bottom" alt="A graphical depiction of CHC Theory">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-chc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<img src="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/CHC.svg" class="img-fluid figure-img column-page-right" style="width:100.0%" alt="A graphical depiction of CHC Theory">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-chc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Conceptual Groupings in the Cattell-Horn-Carroll Theory of Cognitive Abilities
</figcaption>
</figure>
</div>
</div>
</div>
<p>CHC theory is largely based on John Carroll’s <span class="citation" data-cites="Carroll1993">(1993)</span> Three-Stratum Theory of Cognitive Abilities.<sup>1</sup> Because it was based on all the factor-analytic evidence available at the time, Carroll’s synthesis created more consensus in the the field of individual differences in cognitive abilities research than any previous work. However, this strength was also its weakness—one that Carroll <span class="citation" data-cites="Carroll2003 Carroll1998">(1998, 2003)</span> was candid about. Because his theory was based on all the world’s existing data sets, his theorizing process was necessarily exploratory. None of the data sets were designed explicitly to confirm or disconfirm his theory. No one was more aware that the Three-Stratum Theory was incomplete than Carroll (1998) himself:</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Carroll’s conceptualization drew heavily from John Horn’s taxonomy of intelligence, which was an elaboration of Raymond Cattell’s theories, which extended Spearman’s model, which was a work of singular genius.</p></div></div><blockquote class="blockquote">
<p>Whether or not my book on human cognitive abilities can be regarded as an important milestone in its field, I hope that it can at least serve as a guide and reference for future researchers. However, I also think that my book leaves much to be desired, in that it fails to answer a plethora of fundamental questions about cognitive abilities—their structure, sources and meanings. (p.&nbsp;22)</p>
</blockquote>
<p>With Carroll’s passing in 2003, it now falls to us to trim the parts of Carroll’s theory that are inaccurate and supplement those parts that are admittedly incomplete. CHC theory represents such an effort. Although this creative synthesis was instigated by the tireless wizard, Kevin McGrew, CHC theory is a constantly evolving theory and anyone can participate in its upkeep. Schneider &amp; McGrew (2012) issued this standing invitation:</p>
<blockquote class="blockquote">
<p>CHC theory is put forward as a candidate for a common framework for cognitive abilities researchers. All are invited to help build it, and anyone is entitled to try to knock it down by subjecting it to critical tests of its assumptions. (p.&nbsp;100)</p>
</blockquote>
<p>When CHC theory was new, considerable effort was necessarily devoted to retrofitting the meaning of old tests to the new framework <span class="citation" data-cites="Schneider2015a">(Schneider &amp; Flanagan, 2015)</span>. With new tests like the RESCA-E, we should resist the urge to fit each innovation into an existing slot in the CHC taxonomy. Nevertheless, if there are places where the fit is comfortable, it should be acknowledged so that future research with the RESCA-E can more easily build on existing knowledge. I therefore turn to an examination of each subtest of the RESCA-E and speculate how it might relate to CHC narrow and broad abilities.</p>
</section>
<section id="receptive-language-subtests" class="level1 page-columns page-full">
<h1>Receptive Language Subtests</h1>
<section id="comprehension-of-vocabulary" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="comprehension-of-vocabulary">Comprehension of Vocabulary</h2>
<p>The examiner shows four drawings to the examinee and says a word. The examinee points to the one best depicts the word.<sup>2</sup> The advantage of this format is that it cleanly measures the CHC narrow ability <em>Lexical Knowledge</em>, a facet of <em>Comprehension/Knowledge (Gc)</em>. The “disadvantage” of the multiple choice format is that its loading on general intelligence is likely to be smaller than with tests with more open-ended formats (e.g., WISC-V Vocabulary). Why? No judgment is required to decide which aspects of a definition to emphasize. Wechsler’s <span class="citation" data-cites="Wechsler1958">(1958)</span> goal was never to measure things like knowledge <em>per se</em>, but to measure intelligence in all its integrative, glorious complexity.<sup>3</sup> However, when your goal is to measure word knowledge, not judgment, this item format is exactly what you want.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Similar to the <a href="http://www.pearsonclinical.com/language/products/100000501/peabody-picture-vocabulary-test-fourth-edition-ppvt-4.html">Peabody Picture Vocabulary Test, Fourth Edition</a> and the <a href="http://www.academictherapy.com/detailATP.tpl?eqskudatarq=8547-8">Receptive One-Word Picture Vocabulary Test-4</a></p></div><div id="fn3"><p><sup>3</sup>&nbsp;Wechsler (1958, p.&nbsp;15) wrote, “Then, when an examiner employs an arithmetic or a vocabulary test as part of an intelligence scale, the object of the examiner is not to discover the subject’s aptitude for arithmetic or extent of his word knowledge, although these are inevitably involved, but his capacity to function in overall areas which are assumed to require intelligence.” </p></div></div><p>All picture vocabulary tests start with simple objects one encounters frequently (e.g., spoon, ball, dog). Where the test designers go from there matters quite a bit. There are two ways to make a picture vocabulary test more difficult:</p>
<ul>
<li>Show pictures of increasingly unusual objects (e.g., fob, lappets, ait, manometer).</li>
<li>Show pictures illustrating increasingly complex concepts (e.g., relieved, hesitant, shrewd, intimacy) or increasingly subtle distinctions between related words (e.g., ask vs.&nbsp;beg, sad vs.&nbsp;sobbing, consider vs.&nbsp;ponder).</li>
</ul>
<p>Which approach do you think is more applicable to everyday life? Me, too. Fortunately, this is the approach that the RESCA-E takes, with more difficult items focusing mostly on emotions, interpersonal relations, measurements, and abstractions. None of the words are particularly unusual, technical, or esoteric.</p>
</section>
<section id="comprehension-of-oral-directions" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="comprehension-of-oral-directions">Comprehension of Oral Directions</h2>
<p>This measure is similar to the Comprehension of Vocabulary subtest in its format. The examiner shows four drawings to the examinee and says a sentence that contains an instruction. The examinee chooses the picture that is consistent with the instruction. For example, the sentence might be, “You may not ride bicycles in the park.” The four pictures might be various configurations of a child, a bicycle, and a park. The correct answer might be a picture of child in the park with a bicycle chained outside its gates.</p>
<p>The items of this test are ingeniously designed to avoid problems in similar tests of oral direction comprehension. Some tests give increasingly long directions that tax working memory instead of comprehension <em>per se</em>.<sup>4</sup> This subtest minimizes working memory load by presenting directions that rarely have more than three parts. Items become increasingly difficult mostly because of the complexity of the command rather than its length.<sup>5</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Which is fine, if we wish to measure the degree to which working memory deficits interfere with comprehension.</p></div><div id="fn5"><p><sup>5</sup>&nbsp;For example, “Write a letter that has only curved lines or only straight lines, but not both kinds of lines. Which letter could be written? [shows letters] B, D, O, or P”</p></div><div id="fn6"><p><sup>6</sup>&nbsp;You might ask, “If CHC theory has holes in it, why not just fill them?” Good question. Theory building, especially the assembly of a comprehensive taxonomy, must be a slow, deliberate, systematic process. Adding new features that are not well validated into the taxonomy will undermine trust in its utility.</p></div></div><p>In terms of CHC theory, it appears that this subtest measures <em>Listening Ability</em>, a facet of Gc. However, it seems likely that Carroll’s <em>Listening Ability</em> factor comprises multiple subfactors, and that this subtest measures a narrow subset of them (e.g., understanding of English syntax). Thus, the model of language that underlies RESCA-E is more elaborated than the model of language ability in CHC theory. Ideally, research using instruments like the RESCA-E will refine and extend CHC theory’s treatment of language abilities.<sup>6</sup></p>
</section>
<section id="comprehension-of-stories-and-questions" class="level2">
<h2 class="anchored" data-anchor-id="comprehension-of-stories-and-questions">Comprehension of Stories and Questions</h2>
<p>In this subtest, the examiner reads a short story to the examinee and asks questions about the examinee’s understanding of it. For each question, there are four possible answers that the examinee can point to (either words that the examiner reads aloud or pictures that are shown). The passages are carefully crafted to be stories rather than barely concealed lists of random details and events. To answer the questions correctly, the examinee must understand the gist of the story rather than recall highly specific details. Thus, it is a true comprehension test rather than a memory test.</p>
<p>Comprehension of Stories and Questions is, like Comprehension of Oral Directions, a measure of <em>Listening Ability</em>, but less about syntax and more about semantics. To some degree, it is also a measure of <em>Meaningful Memory</em> (Gl).</p>
</section>
<section id="comprehsion-of-basic-morphology-and-syntax" class="level2">
<h2 class="anchored" data-anchor-id="comprehsion-of-basic-morphology-and-syntax">Comprehsion of Basic Morphology and Syntax</h2>
<p>Like the other receptive language subtests, this supplementary subtest is a multiple-choice test. It is cleverly designed to measure a child’s understanding of syntax and morphology. For example, to measure one’s understanding of plurality, the prompt could be “The birds are swimming.” The child has to choose among pictures of birds swimming, but only one picture has more than one bird. In similar fashion, understanding of a variety of other features of English are tested: past vs.&nbsp;present vs.&nbsp;future tense, negation (e.g., none, not, never), prepositions (e.g., on, in, above, between), gender (he vs.&nbsp;she, him vs.&nbsp;her), singular vs.&nbsp;plural, self vs.&nbsp;other (me vs.&nbsp;her), before vs.&nbsp;after, active vs.&nbsp;passive voice (e.g., the boy touched the dog, the boy was touched by the dog).</p>
<p>This subtest is another measure of <em>Listening Ability</em> but with a focus on syntax. From the name of Carroll’s <em>Grammatical Sensitivity</em> factor, it might seem that this is what Comprehension of Basic Morphology and Syntax measures. However, the Grammatical Sensitivity ability factor was a measure of formal knowledge of grammar. Obviously, knowing formal grammatical rules will help on this test but that is not what is being measured here directly.</p>
</section>
<section id="executing-oral-directions" class="level2">
<h2 class="anchored" data-anchor-id="executing-oral-directions">Executing Oral Directions</h2>
<p>This supplementary test is of obvious importance. It can resolve questions such as, “Does the child understand simple commands?” The subtest is similar to and is most correlated with Comprehension of Oral Directions (<em>r</em> = .52). It differs from that test in that it is not a multiple-choice test. Instead, it requires the examinee to follow simple commands at first (e.g., “Touch your knee. Go.”) and increasingly complex sentences at the end of the test (e.g., “Stand up and walk to the door. When you get there, knock on it three times or open it, but not both. Go.”). Near the end of the test, the commands are long and thus the working memory demands are high.</p>
</section>
</section>
<section id="expressive-language-subtests" class="level1 page-columns page-full">
<h1>Expressive Language Subtests</h1>
<section id="expressive-labeling-of-vocabulary" class="level2">
<h2 class="anchored" data-anchor-id="expressive-labeling-of-vocabulary">Expressive Labeling of Vocabulary</h2>
<p>Like the Comprehension of Vocabulary subtest, this test measures <em>Lexical Knowledge</em>. On some items examinee is asked what object is in a picture. In many confrontational naming tests, the objects in the pictures become increasingly unusual. Not so, here. As with the Comprehension of Vocabulary subtest, the pictures measure knowledge of words related to abstract concepts, emotions, and interpersonal relations.</p>
<p>Although Comprehension of Vocabulary (CV) and Expressive Labeling of Vocabulary (ELV) have the highest correlation of all the RESCA-E subtests (<em>r</em> = .6), the correlation is not so high that they are redundant. In my opinion, the RESCA-E should have a Vocabulary composite score consisting of these tests. Using formulas explained in <span class="citation" data-cites="schneider2013principles">Schneider (2013)</span>, you can compute a custom vocabulary composite score like so:</p>
<p><em>Vocabulary Composite</em> = 2.795(<em>CV</em> + <em>ELV</em>) − 44.1</p>
</section>
<section id="expressive-skills-for-describing-and-explaining" class="level2">
<h2 class="anchored" data-anchor-id="expressive-skills-for-describing-and-explaining">Expressive Skills for Describing and Explaining</h2>
<p><span class="citation" data-cites="Guilford1967">Guilford (1967)</span> distinguished between tests requiring <em>convergent</em> production (i.e., a single answer is correct) and tests requiring <em>divergent production</em> (e.g., the examinee gives as many correct answers, such as naming as many ice cream flavors as possible within the time allotted). Cattell originally grouped divergent production tests with crystallized intelligence. The reason for this is that his tests had generous time limits so that the tests were measures of <em>how much</em> information was in the person’s knowledge banks instead <em>how fast</em> it could be pulled out of memory. The results will be quite different if one is given 1 minute to name as many words as possible ending in <em>-tion</em> compared to the same task but with a 5-minute time limit. With generous time limits, the test becomes more like a breadth-of-vocabulary test rather than a memory retrieval speed test. Almost all commercially available tests of divergent production have short time limits and thus function as memory retrieval speed tests.</p>
<p>In this subtest, the examinee is shown a picture (e.g., a family preparing a meal) or given a scenario (e.g., a child getting ready for bed) and the examinee is prompted to tell the examiner everything he or she knows about this situation. Unlike many divergent processing tests (e.g., COWAT), the child does not get 1 point for every answer. Instead there is a checklist of criteria for scoring points. In general, the examinee is awarded points for mentioning aspects of the picture or scenario that are most salient or of central importance.</p>
<p>This is a test paradigm I have never seen before. If it is indeed novel, it is potentially a major advance. It is rare in life to have to name as many exemplars of a category as possible (e.g., sports, furniture, animals, words that begin with H). In contrast, spontaneously describing the most salient aspects of a situation is a hallmark of intelligence. I look forward to seeing validation efforts to evaluate this paradigm’s utility.</p>
<p>This subtest has relatively small correlations with the other tests (<em>r</em> in the .2–.3 range), suggesting that it is not merely a Gc test, though it is undoubtedly influenced by Gc. In CHC theory, there is a little-understood narrow ability called <em>Associational Fluency</em> in the Gr (Memory Retrieval Fluency) broad ability cluster. It is distinguished from the better-known <em>Ideational Fluency</em> factor in that the quality of the responses matters more than the number. Given how points are awarded for mentioning important aspects of a picture or scenario, it seems likely that this is what is being measured. It also seems like that having general knowledge, an intermediate factor within Gc, would help a person perform well on this test.</p>
</section>
<section id="narrative-skills" class="level2">
<h2 class="anchored" data-anchor-id="narrative-skills">Narrative Skills</h2>
<p>In this subtest, the examinee is prompted to tell the gist of a narrative that the examiner read. Another type of item involves telling the examiner about an experience (e.g., taking a long trip in a car or bus). As with the Expressive Skills for Describing and Explaining subtest, the examiner scores the response for the quality of the answers, not for how much is said. It may sound from this description that this subtest is a bear to score, but it is quite straightforward.</p>
<p>The Narrative Skills subtest is most highly correlated with Expressive Skills for Describing and Explaining. It seems likely that it too is a measure of <em>Associational Fluency</em>. It does not seem to draw on background knowledge to the same degree and instead requires <em>Meaningful Memory</em>. Supporting this interpretation is the fact that its second-highest correlation is with Comprehension of Stories and Questions, which is also hypothesized to be influenced by <em>Meaningful Memory.</em></p>
</section>
<section id="expressive-use-of-basic-morphology-and-syntax" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="expressive-use-of-basic-morphology-and-syntax">Expressive Use of Basic Morphology and Syntax</h2>
<p>In this subtest, the examiner prompts the examinee to answer questions about pictures. The questions are cleverly worded so that the examinee’s answers are expected to conform to certain syntactical rules (e.g., “This girl here is running. What is this other girl doing? Answer: Walking”).</p>
<p>Given the similarity in names, it seems reasonable to suppose that this subtest would be strongly correlated with Comprehension of Basic Morphology and Syntax. Its correlation is only <em>r</em> = .45, a value that is similar to the correlations it has with many other subtests. Factor analyses of the RESCA-E reveal no evidence that there is a special relationship between these two measures of morphology and syntax understanding. Examining the pattern of critical difference scores in the Technical Manual, it appears that the correlation between these two tests decreases with age. Why this happens deserves scrutiny. One likely explanation is that both tests have very low ceilings for older children, which means that the scores are imprecise for children with average or better understanding of morphology and syntax.<sup>7</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;A test with a <em>low ceiling</em> does not have enough difficult items to distinguish reliably among high-ability examinees. Low ceilings are a major problem for intelligence tests, but are not so problematic for tests like the RESCA-E, which are designed to identify children with language deficits rather than designed to identify the superstars of syntactic sophistication.</p></div></div><p>In terms of CHC theory, it appears that this subtest measures aspects of <em>Communication Ability</em>, a little-researched factor. As with Comprehension of Basic Morphology &amp; Syntax, it seems likely that Grammatical Sensitivity also influences performance on the test.</p>
</section>
</section>
<section id="social-communication" class="level1">
<h1>Social Communication</h1>
<p>Note that there is no reason to suppose that social communication is distinct from receptive and expressive language. We can imagine receptive social comprehension and expressive social communication. Nevertheless, there is reason to suppose that there as aspects of social communication that deserve separate consideration.</p>
<section id="comprehension-of-body-language-and-vocal-emotion" class="level2">
<h2 class="anchored" data-anchor-id="comprehension-of-body-language-and-vocal-emotion">Comprehension of Body Language and Vocal Emotion</h2>
<p>In this subtest, the examiner shows the examinee four pictures of people making different gestures or with different facial expressions. The examiner plays an audio CD that asks a question like, “Which person is thinking, ‘I am confused.’” and the examinee picks the picture of the person who looks confused. The items are well designed and toward the end of the subtest assess fairly subtle social signals. This subtest would fit it with emotional intelligence tests like the MSCEIT’s <span class="citation" data-cites="Mayer2002">(Mayer et al., 2002)</span> measures of emotion perception.</p>
<p>Because of Guildford’s work in social intelligence, Carroll’s model has a factor called <em>Knowledge of Behavioral Content</em>, an aspect of achievement. However, there is already strong evidence that social and emotional reasoning have several narrow ability factors associated with them <span class="citation" data-cites="Mayer2008a">(Mayer et al., 2008)</span>. It is not clear where these factors belong in CHC theory, but the evidence keeps pouring in that these factors matter. Sooner or later, CHC theory is going to have to provide a more nuanced account of aspects of social and emotional intelligence <span class="citation" data-cites="MacCann2014 schneider2016integrating">(MacCann et al., 2014; Schneider et al., 2016)</span>.</p>
</section>
<section id="social-and-language-inference" class="level2">
<h2 class="anchored" data-anchor-id="social-and-language-inference">Social and Language Inference</h2>
<p>In this test, the examiner presents a scenario in which someone uses indirect or idiomatic language. In many items, the examinee selects the correct answer from four answer choices. For example, two children are talking in class and the teacher says, “Hey, knock it off, you two!” The correct inference will be that the teacher wants the children to stop talking.</p>
<p>In terms of CHC theory, this seems to be a general <em>Language Development</em> measure with emphasis on <em>Knowledge of Behavioral Content</em> as well.</p>
</section>
<section id="situational-language-use" class="level2">
<h2 class="anchored" data-anchor-id="situational-language-use">Situational Language Use</h2>
<p>In this subtest, the examiner presents the examinee with a scenario and prompts the examinee to say how he or she would respond in that situation. For example, “Your mother introduces you to a woman you do not know. The woman smiles and extends her hand, saying ‘Pleased to meet you.’ How would you respond in a friendly and polite manner?” The examinee’s response is scored according to straightforward criteria.</p>
<p>In terms of CHC theory, this subtest measures <em>Communication Ability</em> as well as <em>Knowledge of Behavioral Content</em>.</p>
</section>
<section id="elicited-body-language" class="level2">
<h2 class="anchored" data-anchor-id="elicited-body-language">Elicited Body Language</h2>
<p>In this subtest, the examiner asks the examinee to act out various common situations (e.g., Pretend you just took a bite of your favorite food. Pretend you accidentally hurt your finger. Pretend you are listening to someone who whispers a surprising secret.). This test may supplant the SB5 Verbal Absurdities as the most delightful test to administer.</p>
<p>Once again, CHC theory’s taxonomy is too sparse in this domain to explain what is going on in this subtest. Nevertheless, the narrow ability that is being measured is mostly likely <em>Knowledge of Behavioral Content</em>.</p>
</section>
</section>
<section id="summary-of-influences-on-resca-e-performances" class="level1">
<h1>Summary of Influences on RESCA-E Performances</h1>
<p>Table&nbsp;1 summarizes my hypotheses about which CHC narrow abilities are measured by each RESCA-E subtest. Evidence is cruel to armchair speculation, and the probability that I am right in every case is low. There are two kinds of errors I might have made. First, it is possible that some other CHC narrow ability is a more important influence on test performance than what I have listed. Second, it is possible that CHC theory simply does not have the right categories to characterize what the RESCA-E subtests measure. There is a reasonable chance I have made few or no errors of the first type. However, it is certain that errors of the second type have been made, particularly with respect to the Social Communication subtests.</p>
<div class="cell">
<div id="tbl-subtests" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-subtests-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: CHC Constructs Hypothesized to Influence Performance on RESCA-E Subtests
</figcaption>
<div aria-describedby="tbl-subtests-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="ehshskiaeo" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#ehshskiaeo table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#ehshskiaeo thead, #ehshskiaeo tbody, #ehshskiaeo tfoot, #ehshskiaeo tr, #ehshskiaeo td, #ehshskiaeo th {
  border-style: none;
}

#ehshskiaeo p {
  margin: 0;
  padding: 0;
}

#ehshskiaeo .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ehshskiaeo .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#ehshskiaeo .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ehshskiaeo .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ehshskiaeo .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ehshskiaeo .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ehshskiaeo .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ehshskiaeo .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ehshskiaeo .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ehshskiaeo .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ehshskiaeo .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ehshskiaeo .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ehshskiaeo .gt_spanner_row {
  border-bottom-style: hidden;
}

#ehshskiaeo .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#ehshskiaeo .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ehshskiaeo .gt_from_md > :first-child {
  margin-top: 0;
}

#ehshskiaeo .gt_from_md > :last-child {
  margin-bottom: 0;
}

#ehshskiaeo .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: hidden;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ehshskiaeo .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#ehshskiaeo .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#ehshskiaeo .gt_row_group_first td {
  border-top-width: 2px;
}

#ehshskiaeo .gt_row_group_first th {
  border-top-width: 2px;
}

#ehshskiaeo .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ehshskiaeo .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#ehshskiaeo .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#ehshskiaeo .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ehshskiaeo .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ehshskiaeo .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ehshskiaeo .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#ehshskiaeo .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ehshskiaeo .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ehshskiaeo .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ehshskiaeo .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ehshskiaeo .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ehshskiaeo .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ehshskiaeo .gt_left {
  text-align: left;
}

#ehshskiaeo .gt_center {
  text-align: center;
}

#ehshskiaeo .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ehshskiaeo .gt_font_normal {
  font-weight: normal;
}

#ehshskiaeo .gt_font_bold {
  font-weight: bold;
}

#ehshskiaeo .gt_font_italic {
  font-style: italic;
}

#ehshskiaeo .gt_super {
  font-size: 65%;
}

#ehshskiaeo .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#ehshskiaeo .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#ehshskiaeo .gt_indent_1 {
  text-indent: 5px;
}

#ehshskiaeo .gt_indent_2 {
  text-indent: 10px;
}

#ehshskiaeo .gt_indent_3 {
  text-indent: 15px;
}

#ehshskiaeo .gt_indent_4 {
  text-indent: 20px;
}

#ehshskiaeo .gt_indent_5 {
  text-indent: 25px;
}

#ehshskiaeo .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#ehshskiaeo div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_col_headings header">
<th id="Subtest" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" style="font-weight: bold" scope="col">Subtest</th>
<th id="Primary-Influence" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" style="font-weight: bold" scope="col">Primary Influence</th>
<th id="Secondary-Influences" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" style="font-weight: bold" scope="col">Secondary Influences</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="gt_group_heading_row odd">
<td colspan="3" id="Social Communication" class="gt_group_heading" data-quarto-table-cell-role="th" style="font-weight: bold" scope="colgroup">Social Communication</td>
</tr>
<tr class="gt_row_group_first even">
<td class="gt_row gt_left" headers="Social Communication  Subtest">Comprehension of Body Language and Vocal Emotion</td>
<td class="gt_row gt_left" headers="Social Communication  Primary Influence">Knowledge of Behavioral Content</td>
<td class="gt_row gt_left" headers="Social Communication  Secondary Influences"></td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Social Communication  Subtest">Social and Language Inference</td>
<td class="gt_row gt_left" headers="Social Communication  Primary Influence">Language Development</td>
<td class="gt_row gt_left" headers="Social Communication  Secondary Influences">Knowledge of Behavioral Content</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Social Communication  Subtest">Situational Language Use</td>
<td class="gt_row gt_left" headers="Social Communication  Primary Influence">Communication Ability</td>
<td class="gt_row gt_left" headers="Social Communication  Secondary Influences">Knowledge of Behavioral Content</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Social Communication  Subtest">Elicited Body Language</td>
<td class="gt_row gt_left" headers="Social Communication  Primary Influence">Knowledge of Behavioral Content</td>
<td class="gt_row gt_left" headers="Social Communication  Secondary Influences"></td>
</tr>
<tr class="gt_group_heading_row even">
<td colspan="3" id="Expressive Language" class="gt_group_heading" data-quarto-table-cell-role="th" style="font-weight: bold" scope="colgroup">Expressive Language</td>
</tr>
<tr class="gt_row_group_first odd">
<td class="gt_row gt_left" headers="Expressive Language  Subtest">Expressive Labeling of Vocabulary</td>
<td class="gt_row gt_left" headers="Expressive Language  Primary Influence">Lexical Knowledge</td>
<td class="gt_row gt_left" headers="Expressive Language  Secondary Influences"></td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Expressive Language  Subtest">Expressive Skills for Describing and Explaining</td>
<td class="gt_row gt_left" headers="Expressive Language  Primary Influence">Associational Fluency</td>
<td class="gt_row gt_left" headers="Expressive Language  Secondary Influences">General Knowledge</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Expressive Language  Subtest">Narrative Skills</td>
<td class="gt_row gt_left" headers="Expressive Language  Primary Influence">Associational Fluency</td>
<td class="gt_row gt_left" headers="Expressive Language  Secondary Influences">Meaningful Memory</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Expressive Language  Subtest">Expressive Use of Basic Morphology and Syntax</td>
<td class="gt_row gt_left" headers="Expressive Language  Primary Influence">Communication Ability</td>
<td class="gt_row gt_left" headers="Expressive Language  Secondary Influences">Grammatical Sensitivity</td>
</tr>
<tr class="gt_group_heading_row odd">
<td colspan="3" id="Receptive Language" class="gt_group_heading" data-quarto-table-cell-role="th" style="font-weight: bold" scope="colgroup">Receptive Language</td>
</tr>
<tr class="gt_row_group_first even">
<td class="gt_row gt_left" headers="Receptive Language  Subtest">Comprehension of Vocabulary</td>
<td class="gt_row gt_left" headers="Receptive Language  Primary Influence">Lexical Knowledge</td>
<td class="gt_row gt_left" headers="Receptive Language  Secondary Influences"></td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Receptive Language  Subtest">Comprehension of Oral Directions</td>
<td class="gt_row gt_left" headers="Receptive Language  Primary Influence">Listening Ability</td>
<td class="gt_row gt_left" headers="Receptive Language  Secondary Influences">Working Memory Capacity</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Receptive Language  Subtest">Comprehension of Stories &amp; Questions</td>
<td class="gt_row gt_left" headers="Receptive Language  Primary Influence">Listening Ability</td>
<td class="gt_row gt_left" headers="Receptive Language  Secondary Influences">Meaningful Memory</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Receptive Language  Subtest">Comprehension of Basic Morphology &amp; Syntax</td>
<td class="gt_row gt_left" headers="Receptive Language  Primary Influence">Listening Ability</td>
<td class="gt_row gt_left" headers="Receptive Language  Secondary Influences">Grammatical Sensitivity</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Receptive Language  Subtest">Executing Oral Directions</td>
<td class="gt_row gt_left" headers="Receptive Language  Primary Influence">Listening Ability</td>
<td class="gt_row gt_left" headers="Receptive Language  Secondary Influences">Working Memory Capacity</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
</section>
<section id="the-structure-of-the-resca-e" class="level1">
<h1>The Structure of the RESCA-E</h1>
<p>It is telling that only in the language domain did Carroll offer elaborate speculations that went substantially beyond his data. Carroll was, if anything, an expert in language abilities, having studied them intensely since the beginning of his career in the 1930s. He knew that the available data sets, rich and varied as they were, could not capture all of what he suspected was true of language abilities. For example, although the distinction between receptive language and expressive language could not be verified directly with the available data, he made the distinction nonetheless (Carroll, 1993, p.&nbsp;147).</p>
<p>The fact that we comprehend language and we communicate via language is so obvious a distinction that we simply do not care how the factor analyses shake out. Since the early work of Wernicke and Broca, we have known that damage to certain areas of the brain impair receptive language more than expressive language and that damage to other brain regions produces the opposite pattern of deficits. Even so, nature has no desire to conform to our preferences for theoretical tidiness. For example, damage to Broca’s area impairs expressive language more than receptive language but also impairs understanding of specific aspects of syntax <span class="citation" data-cites="grodzinsky2000neurology">(Grodzinsky, 2000)</span>.</p>
<p>The authors of the RESCA-E not only distinguish between receptive and expressive language abilities, but also social communication as well. These distinctions are important, but it is important to be clear as to what kind of distinction is being made. Are these language domains, expressive, receptive, and social, cohesive broad ability domains? If so, factor analysis should suggest that they are distinct. If not, it should be emphasized that there are many other kinds of theoretical distinctions that factor analysis does not detect <span class="citation" data-cites="schneider2016integrating">(Schneider et al., 2016)</span>. They may be conceptual categories that are useful for pragmatic description even if factor analysis does not show them to be cohesive.</p>
<section id="exploratory-factor-analysis" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-factor-analysis">Exploratory Factor Analysis</h2>
<p>I used the RESCA-E correlation matrix for the entire standardization sample (<em>N</em> = 825) to conduct all analyses. I removed the Social Communication Inventory scale from consideration because it is not an ability test. It has low correlations with the other tests and thus would produce an uninformative singleton factor.</p>
<p>To see how many factors to extract, I conducted a parallel analysis using the <code>psych</code> package <span class="citation" data-cites="revelle2016psych">(Revelle, 2016)</span> in R. I used the type of parallel analysis based on principal factors rather than the more commonly-used principal components method because it is more accurate when there is a large general factor <span class="citation" data-cites="crawford2010evaluation">(Crawford et al., 2010)</span>. As seen in Figure&nbsp;2, the results suggest that extracting five principal factors is a reasonable choice.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-parallel" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-parallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE_files/figure-html/fig-parallel-1.svg" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-parallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Principal Factor Analysis–Based Parallel Analysis of the RESCA-E Subtests
</figcaption>
</figure>
</div>
</div>
</div>
<p>I extracted 1, 2, 3, 4, and then 5 principal factors with an oblimin rotation (See Tables 1–5). In no solution did the three language domains—expressive, receptive, and social communication—hang together. Does this result mean that the structure of RESCA-E is not valid? No, but it suggests that the three ability domains are not the same kind of constructs that factor-analysts are used to. The three language domains are not cohesive clusters of relatively unitary abilities, and the subtests in each of the three composite scores will often not hang together as closely as factor-based composites would.</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption><em>Table 2</em>. Factor loadings of RESCA-E subtests in a principal factor analysis with oblimin rotation (1-factor solution)</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Domain</th>
<th style="text-align: right;">PA1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Comprehension of Stories and Questions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.75</td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Labeling of Vocabulary</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.75</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.73</td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Vocabulary</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.72</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Social and Language Inference</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.69</td>
</tr>
<tr class="even">
<td style="text-align: left;">Situational Language Use</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.68</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Use of Basic Morphology and Syntax</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.66</td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Basic Morphology and Syntax</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.65</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Narrative Skills</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.63</td>
</tr>
<tr class="even">
<td style="text-align: left;">Executing Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.61</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Body Language and Vocal Emotion</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.59</td>
</tr>
<tr class="even">
<td style="text-align: left;">Elicited Body Language</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.54</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Skills for Describing and Explaining</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.54</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption><em>Table 3</em>. Factor loadings of RESCA-E subtests in a principal factor analysis with oblimin rotation (2-factor solution)</caption>
<colgroup>
<col style="width: 72%">
<col style="width: 16%">
<col style="width: 5%">
<col style="width: 5%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Domain</th>
<th style="text-align: right;">PA1</th>
<th style="text-align: right;">PA2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Social and Language Inference</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.80</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Basic Morphology and Syntax</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.77</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Vocabulary</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.73</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.72</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Stories and Questions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.67</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Labeling of Vocabulary</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.63</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Executing Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.59</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Use of Basic Morphology and Syntax</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.57</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Body Language and Vocal Emotion</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.55</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Situational Language Use</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.47</td>
<td style="text-align: right;">.28</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Elicited Body Language</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.33</td>
<td style="text-align: right;">.28</td>
</tr>
<tr class="even">
<td style="text-align: left;">Narrative Skills</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.75</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Skills for Describing and Explaining</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.70</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption><em>Table 4</em>. Factor loadings of RESCA-E subtests in a principal factor analysis with oblimin rotation (3-factor solution)</caption>
<colgroup>
<col style="width: 68%">
<col style="width: 15%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Domain</th>
<th style="text-align: right;">PA1</th>
<th style="text-align: right;">PA2</th>
<th style="text-align: right;">PA3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Comprehension of Vocabulary</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.76</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Labeling of Vocabulary</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.74</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Social and Language Inference</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.74</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Stories and Questions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.69</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Basic Morphology and Syntax</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.68</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.65</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Body Language and Vocal Emotion</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.53</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Skills for Describing and Explaining</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.75</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Narrative Skills</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.61</td>
<td style="text-align: right;">.23</td>
</tr>
<tr class="even">
<td style="text-align: left;">Situational Language Use</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.20</td>
<td style="text-align: right;">.55</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Elicited Body Language</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.20</td>
<td style="text-align: right;">.44</td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Use of Basic Morphology and Syntax</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.32</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.39</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Executing Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.36</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.37</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption><em>Table 5</em>. Factor loadings of RESCA-E subtests in a principal factor analysis with oblimin rotation (4-factor solution)</caption>
<colgroup>
<col style="width: 64%">
<col style="width: 14%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Domain</th>
<th style="text-align: right;">PA1</th>
<th style="text-align: right;">PA3</th>
<th style="text-align: right;">PA2</th>
<th style="text-align: right;">PA4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Comprehension of Vocabulary</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.78</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Labeling of Vocabulary</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.75</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Social and Language Inference</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.69</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Stories and Questions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.65</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Basic Morphology and Syntax</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.62</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.56</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.24</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Body Language and Vocal Emotion</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.54</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Use of Basic Morphology and Syntax</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.32</td>
<td style="text-align: right;">.25</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Situational Language Use</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.93</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Elicited Body Language</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.34</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Skills for Describing and Explaining</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.71</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Narrative Skills</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.68</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Executing Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.79</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption><em>Table 6</em>. Factor loadings of RESCA-E subtests in a principal factor analysis with oblimin rotation (5-factor solution)</caption>
<colgroup>
<col style="width: 61%">
<col style="width: 13%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Domain</th>
<th style="text-align: right;">PA1</th>
<th style="text-align: right;">PA2</th>
<th style="text-align: right;">PA5</th>
<th style="text-align: right;">PA3</th>
<th style="text-align: right;">PA4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Comprehension of Vocabulary</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.73</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Labeling of Vocabulary</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.65</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Stories and Questions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.52</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Social and Language Inference</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.51</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.24</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Body Language and Vocal Emotion</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.49</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.23</td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Basic Morphology and Syntax</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.39</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.31</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Skills for Describing and Explaining</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.79</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Narrative Skills</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.65</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.68</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Executing Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.51</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.29</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Elicited Body Language</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.83</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Situational Language Use</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.33</td>
<td style="text-align: right;">.28</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Use of Basic Morphology and Syntax</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.52</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="might-mulitdimensional-scaling-detect-a-faceted-relationship-among-the-three-language-domains" class="level2">
<h2 class="anchored" data-anchor-id="might-mulitdimensional-scaling-detect-a-faceted-relationship-among-the-three-language-domains">Might Mulitdimensional Scaling Detect a Faceted Relationship Among the Three Language Domains?</h2>
<p>Is there some sort of faceted relationship that the three language domains might have that factor analysis cannot detect (e.g., process × domain)? If so, it should show up in a multidimensional scaling (MDS). Using the correlations subtracted from 1 as distances, a two-dimensional MDS suggests no obvious cohesion of the three domains (See Figure&nbsp;3).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-mds2d" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mds2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE_files/figure-html/fig-mds2d-1.svg" class="img-fluid figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mds2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Two-dimensional Multidimensional Scaling of the RESCA-E Subtests. Blue = Receptive, Red = Expressive, Green = Social Communication
</figcaption>
</figure>
</div>
</div>
</div>
<p>Perhaps there is order that can be seen in three dimensions that cannot be detected in two. You can grab Figure&nbsp;4 with your mouse and rotate it. I am unable to detect any patterns that show the three domains to be elegantly cohesive.</p>
<div class="cell">
<div id="fig-mds3d" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored no-overflow-x">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mds3d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="rgl19852" style="width:100%;height:650px;" class="rglWebGL html-widget" aria-labelledby="rgl19852-aria"></div>
<script type="application/json" data-for="rgl19852">{"x":{"material":{"color":"#000000","alpha":1,"lit":true,"ambient":"#000000","specular":"#FFFFFF","emission":"#000000","shininess":50,"smooth":true,"front":"filled","back":"filled","size":3,"lwd":1,"fog":true,"point_antialias":false,"line_antialias":false,"texture":null,"textype":"rgb","texmode":"modulate","texmipmap":false,"texminfilter":"linear","texmagfilter":"linear","texenvmap":false,"depth_mask":true,"depth_test":"less","isTransparent":false,"polygon_offset":[0,0],"margin":"","floating":false,"tag":"","blend":["src_alpha","one_minus_src_alpha"]},"rootSubscene":6,"objects":{"13":{"id":13,"type":"lines","material":{"lit":false},"vertices":"0","colors":"1","centers":"2","ignoreExtent":false,"flags":32832},"15":{"id":15,"type":"text","material":{"lit":false,"margin":0,"floating":true,"edge":[0,1,1]},"vertices":"3","colors":"4","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"5","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"16":{"id":16,"type":"text","material":{"lit":false,"margin":1,"floating":true,"edge":[1,1,1]},"vertices":"6","colors":"7","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"8","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"17":{"id":17,"type":"text","material":{"lit":false,"margin":2,"floating":true,"edge":[1,1,1]},"vertices":"9","colors":"10","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"11","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"18":{"id":18,"type":"text","material":{"lit":false},"vertices":"12","colors":"13","texts":[["Comprehension of Vocabulary"],["Comprehension of Oral Directions"],["Comprehension of Stories and Questions"],["Comprehension of Basic Morphology and Syntax"],["Executing Oral Directions"],["Expressive Labeling of Vocabulary"],["Expressive Skills for Describing and Explaining"],["Narrative Skills"],["Expressive Use of Basic Morphology and Syntax"],["Comprehension of Body Language and Vocal Emotion"],["Social and Language Inference"],["Situational Language Use"],["Elicited Body Language"]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"14","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"10":{"id":10,"type":"light","vertices":[[0,0,1]],"colors":[[1,1,1,1],[1,1,1,1],[1,1,1,1]],"viewpoint":true,"finite":false},"12":{"id":12,"type":"background","material":{"lit":false,"back":"lines"},"colors":"15","centers":"16","sphere":false,"fogtype":"none","fogscale":1,"flags":32768},"14":{"id":14,"type":"bboxdeco","material":{"front":"culled","back":"culled"},"colors":"17","axes":{"mode":["none","none","none"],"step":[-1,-1,-1],"nticks":[0,0,0],"marklen":[15,15,15],"expand":[1.029999971389771,1.029999971389771,1.029999971389771]},"draw_front":false,"flags":32769},"6":{"id":6,"type":"subscene","par3d":{"antialias":8,"FOV":30,"ignoreExtent":false,"listeners":6,"mouseMode":{"none":"none","left":"trackball","right":"zoom","middle":"fov","wheel":"pull"},"observer":[0,0,2.31765079498291],"modelMatrix":[[0.8736469745635986,0,0,-0.07076582312583923],[0,0.3524267971515656,1.086503148078918,0.05582863464951515],[0,-0.9682846069335938,0.3954548239707947,-2.364319324493408],[0,0,0,1]],"projMatrix":[[3.732050895690918,0,0,0],[0,3.732050895690918,0,0],[0,0,-3.863703727722168,-8.354864120483398],[0,0,-1,0]],"skipRedraw":false,"userMatrix":[[1,0,0,0],[0,0.3420201433256682,0.9396926207859085,0],[0,-0.9396926207859085,0.3420201433256682,0],[0,0,0,1]],"userProjection":[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],"scale":[0.8736469745635986,1.030426979064941,1.156232476234436],"viewport":{"x":0,"y":0,"width":1,"height":1},"zoom":1,"bbox":[-0.2319569736719131,0.3939579129219055,-0.3264305591583252,0.2042510360479355,-0.2680382430553436,0.2049018144607544],"windowRect":[0,0,256,256],"family":"serif","font":1,"cex":1,"useFreeType":false,"fontname":"NULL","maxClipPlanes":2147483647,"glVersion":"NA","activeSubscene":0},"embeddings":{"viewport":"replace","projection":"replace","model":"replace","mouse":"replace"},"objects":[12,14,13,15,16,17,18,10],"subscenes":[],"flags":34129}},"crosstalk":{"key":[],"group":[],"id":[],"options":[]},"width":768,"height":768,"buffer":{"accessors":[{"bufferView":0,"componentType":5126,"count":4,"type":"VEC3"},{"bufferView":1,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":2,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":3,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":4,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":5,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":6,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":7,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":8,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":9,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":10,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":11,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":12,"componentType":5126,"count":13,"type":"VEC3"},{"bufferView":13,"componentType":5121,"count":14,"type":"VEC4","normalized":true},{"bufferView":14,"componentType":5126,"count":13,"type":"VEC3"},{"bufferView":15,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":16,"componentType":5121,"count":1,"type":"VEC3"},{"bufferView":17,"componentType":5121,"count":1,"type":"VEC4"}],"bufferViews":[{"buffer":0,"byteLength":48,"byteOffset":0},{"buffer":0,"byteLength":4,"byteOffset":48},{"buffer":0,"byteLength":24,"byteOffset":52},{"buffer":0,"byteLength":12,"byteOffset":76},{"buffer":0,"byteLength":4,"byteOffset":88},{"buffer":0,"byteLength":12,"byteOffset":92},{"buffer":0,"byteLength":12,"byteOffset":104},{"buffer":0,"byteLength":4,"byteOffset":116},{"buffer":0,"byteLength":12,"byteOffset":120},{"buffer":0,"byteLength":12,"byteOffset":132},{"buffer":0,"byteLength":4,"byteOffset":144},{"buffer":0,"byteLength":12,"byteOffset":148},{"buffer":0,"byteLength":156,"byteOffset":160},{"buffer":0,"byteLength":56,"byteOffset":316},{"buffer":0,"byteLength":156,"byteOffset":372},{"buffer":0,"byteLength":4,"byteOffset":528},{"buffer":0,"byteLength":3,"byteOffset":532},{"buffer":0,"byteLength":4,"byteOffset":535}],"buffers":[{"byteLength":539,"bytes":"IYZtvughp75PPIm+IYZtvughp75PPIm+2rTJPi8nUT7I0VE+2rTJPi8nUT7I0VE+AAAAASGG\nbb7oIae+TzyJvtq0yT4vJ1E+yNFRPgAAwH8AAIBAAACAPwAAAAEAAMB/AACAQAAAgD8AAMB/\nAACAQAAAgD8AAAABAADAfwAAgEAAAIA/AADAfwAAgEAAAIA/AAAAAQAAwH8AAIBAAACAP7SU\n5L2gzKo9u+M1vWZVtL1MVGC89fpNPngDQr2y+pQ9RaaxPCGGbb6swRs9oumyPZf+DL6F022+\nyNFRPhiTRrxAXyA+EcMfPNq0yT7BKUM+FQLMPQVamj6ogD0970G7PaI0SL2bHrS9W/wIvvvS\n1b0vJ1E+TzyJvlZdQ76GovU8NelnO3j3tD3XbCW+twwIvleeQT7oIae+kLkPvkFp4f9BaeH/\nQWnh/0Fp4f9BaeH/siIi/7IiIv+yIiL/siIi/0WLAP9FiwD/RYsA/0WLAP9FiwD/tJTkvaDM\nqj274zW9ZlW0vUxUYLz1+k0+eANCvbL6lD1FprE8IYZtvqzBGz2i6bI9l/4MvoXTbb7I0VE+\nGJNGvEBfID4Rwx882rTJPsEpQz4VAsw9BVqaPqiAPT3vQbs9ojRIvZsetL1b/Ai++9LVvS8n\nUT5PPIm+Vl1Dvoai9Tw16Wc7ePe0PddsJb63DAi+V55BPughp76QuQ++AQEBAQAAAAAAAAE="}]},"context":{"shiny":false,"rmarkdown":null},"vertexShader":"#line 2 1\n// File 1 is the vertex shader\n#ifdef GL_ES\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n#endif\n\nattribute vec3 aPos;\nattribute vec4 aCol;\nuniform mat4 mvMatrix;\nuniform mat4 prMatrix;\nvarying vec4 vCol;\nvarying vec4 vPosition;\n\n#ifdef NEEDS_VNORMAL\nattribute vec3 aNorm;\nuniform mat4 normMatrix;\nvarying vec4 vNormal;\n#endif\n\n#if defined(HAS_TEXTURE) || defined (IS_TEXT)\nattribute vec2 aTexcoord;\nvarying vec2 vTexcoord;\n#endif\n\n#ifdef FIXED_SIZE\nuniform vec3 textScale;\n#endif\n\n#ifdef FIXED_QUADS\nattribute vec3 aOfs;\n#endif\n\n#ifdef IS_TWOSIDED\n#ifdef HAS_NORMALS\nvarying float normz;\nuniform mat4 invPrMatrix;\n#else\nattribute vec3 aPos1;\nattribute vec3 aPos2;\nvarying float normz;\n#endif\n#endif // IS_TWOSIDED\n\n#ifdef FAT_LINES\nattribute vec3 aNext;\nattribute vec2 aPoint;\nvarying vec2 vPoint;\nvarying float vLength;\nuniform float uAspect;\nuniform float uLwd;\n#endif\n\n#ifdef USE_ENVMAP\nvarying vec3 vReflection;\n#endif\n\nvoid main(void) {\n  \n#ifndef IS_BRUSH\n#if defined(NCLIPPLANES) || !defined(FIXED_QUADS) || defined(HAS_FOG) || defined(USE_ENVMAP)\n  vPosition = mvMatrix * vec4(aPos, 1.);\n#endif\n  \n#ifndef FIXED_QUADS\n  gl_Position = prMatrix * vPosition;\n#endif\n#endif // !IS_BRUSH\n  \n#ifdef IS_POINTS\n  gl_PointSize = POINTSIZE;\n#endif\n  \n  vCol = aCol;\n  \n// USE_ENVMAP implies NEEDS_VNORMAL\n\n#ifdef NEEDS_VNORMAL\n  vNormal = normMatrix * vec4(-aNorm, dot(aNorm, aPos));\n#endif\n\n#ifdef USE_ENVMAP\n  vReflection = normalize(reflect(vPosition.xyz/vPosition.w, \n                        normalize(vNormal.xyz/vNormal.w)));\n#endif\n  \n#ifdef IS_TWOSIDED\n#ifdef HAS_NORMALS\n  /* normz should be calculated *after* projection */\n  normz = (invPrMatrix*vNormal).z;\n#else\n  vec4 pos1 = prMatrix*(mvMatrix*vec4(aPos1, 1.));\n  pos1 = pos1/pos1.w - gl_Position/gl_Position.w;\n  vec4 pos2 = prMatrix*(mvMatrix*vec4(aPos2, 1.));\n  pos2 = pos2/pos2.w - gl_Position/gl_Position.w;\n  normz = pos1.x*pos2.y - pos1.y*pos2.x;\n#endif\n#endif // IS_TWOSIDED\n  \n#ifdef NEEDS_VNORMAL\n  vNormal = vec4(normalize(vNormal.xyz), 1);\n#endif\n  \n#if defined(HAS_TEXTURE) || defined(IS_TEXT)\n  vTexcoord = aTexcoord;\n#endif\n  \n#if defined(FIXED_SIZE) && !defined(ROTATING)\n  vec4 pos = prMatrix * mvMatrix * vec4(aPos, 1.);\n  pos = pos/pos.w;\n  gl_Position = pos + vec4(aOfs*textScale, 0.);\n#endif\n  \n#if defined(IS_SPRITES) && !defined(FIXED_SIZE)\n  vec4 pos = mvMatrix * vec4(aPos, 1.);\n  pos = pos/pos.w + vec4(aOfs,  0.);\n  gl_Position = prMatrix*pos;\n#endif\n  \n#ifdef FAT_LINES\n  /* This code was inspired by Matt Deslauriers' code in \n   https://mattdesl.svbtle.com/drawing-lines-is-hard */\n  vec2 aspectVec = vec2(uAspect, 1.0);\n  mat4 projViewModel = prMatrix * mvMatrix;\n  vec4 currentProjected = projViewModel * vec4(aPos, 1.0);\n  currentProjected = currentProjected/currentProjected.w;\n  vec4 nextProjected = projViewModel * vec4(aNext, 1.0);\n  vec2 currentScreen = currentProjected.xy * aspectVec;\n  vec2 nextScreen = (nextProjected.xy / nextProjected.w) * aspectVec;\n  float len = uLwd;\n  vec2 dir = vec2(1.0, 0.0);\n  vPoint = aPoint;\n  vLength = length(nextScreen - currentScreen)/2.0;\n  vLength = vLength/(vLength + len);\n  if (vLength > 0.0) {\n    dir = normalize(nextScreen - currentScreen);\n  }\n  vec2 normal = vec2(-dir.y, dir.x);\n  dir.x /= uAspect;\n  normal.x /= uAspect;\n  vec4 offset = vec4(len*(normal*aPoint.x*aPoint.y - dir), 0.0, 0.0);\n  gl_Position = currentProjected + offset;\n#endif\n  \n#ifdef IS_BRUSH\n  gl_Position = vec4(aPos, 1.);\n#endif\n}","fragmentShader":"#line 2 2\n// File 2 is the fragment shader\n#ifdef GL_ES\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n#endif\nvarying vec4 vCol; // carries alpha\nvarying vec4 vPosition;\n#if defined(HAS_TEXTURE) || defined (IS_TEXT)\nvarying vec2 vTexcoord;\nuniform sampler2D uSampler;\n#endif\n\n#ifdef HAS_FOG\nuniform int uFogMode;\nuniform vec3 uFogColor;\nuniform vec4 uFogParms;\n#endif\n\n#if defined(IS_LIT) && !defined(FIXED_QUADS)\nvarying vec4 vNormal;\n#endif\n\n#if NCLIPPLANES > 0\nuniform vec4 vClipplane[NCLIPPLANES];\n#endif\n\n#if NLIGHTS > 0\nuniform mat4 mvMatrix;\n#endif\n\n#ifdef IS_LIT\nuniform vec3 emission;\nuniform float shininess;\n#if NLIGHTS > 0\nuniform vec3 ambient[NLIGHTS];\nuniform vec3 specular[NLIGHTS]; // light*material\nuniform vec3 diffuse[NLIGHTS];\nuniform vec3 lightDir[NLIGHTS];\nuniform bool viewpoint[NLIGHTS];\nuniform bool finite[NLIGHTS];\n#endif\n#endif // IS_LIT\n\n#ifdef IS_TWOSIDED\nuniform bool front;\nvarying float normz;\n#endif\n\n#ifdef FAT_LINES\nvarying vec2 vPoint;\nvarying float vLength;\n#endif\n\n#ifdef USE_ENVMAP\nvarying vec3 vReflection;\n#endif\n\nvoid main(void) {\n  vec4 fragColor;\n#ifdef FAT_LINES\n  vec2 point = vPoint;\n  bool neg = point.y < 0.0;\n  point.y = neg ? (point.y + vLength)/(1.0 - vLength) :\n                 -(point.y - vLength)/(1.0 - vLength);\n#if defined(IS_TRANSPARENT) && defined(IS_LINESTRIP)\n  if (neg && length(point) <= 1.0) discard;\n#endif\n  point.y = min(point.y, 0.0);\n  if (length(point) > 1.0) discard;\n#endif // FAT_LINES\n  \n#ifdef ROUND_POINTS\n  vec2 coord = gl_PointCoord - vec2(0.5);\n  if (length(coord) > 0.5) discard;\n#endif\n  \n#if NCLIPPLANES > 0\n  for (int i = 0; i < NCLIPPLANES; i++)\n    if (dot(vPosition, vClipplane[i]) < 0.0) discard;\n#endif\n    \n#ifdef FIXED_QUADS\n    vec3 n = vec3(0., 0., 1.);\n#elif defined(IS_LIT)\n    vec3 n = normalize(vNormal.xyz);\n#endif\n    \n#ifdef IS_TWOSIDED\n    if ((normz <= 0.) != front) discard;\n#endif\n\n#ifdef IS_LIT\n    vec3 eye = normalize(-vPosition.xyz/vPosition.w);\n    vec3 lightdir;\n    vec4 colDiff;\n    vec3 halfVec;\n    vec4 lighteffect = vec4(emission, 0.);\n    vec3 col;\n    float nDotL;\n#ifdef FIXED_QUADS\n    n = -faceforward(n, n, eye);\n#endif\n    \n#if NLIGHTS > 0\n    // Simulate two-sided lighting\n    if (n.z < 0.0)\n      n = -n;\n    for (int i=0;i<NLIGHTS;i++) {\n      colDiff = vec4(vCol.rgb * diffuse[i], vCol.a);\n      lightdir = lightDir[i];\n      if (!viewpoint[i]) {\n        if (finite[i]) {\n          lightdir = (mvMatrix * vec4(lightdir, 1.)).xyz;\n        } else {\n          lightdir = (mvMatrix * vec4(lightdir, 0.)).xyz;\n        }\n      }\n      if (!finite[i]) {\n        halfVec = normalize(lightdir + eye);\n      } else {\n        lightdir = normalize(lightdir - vPosition.xyz/vPosition.w);\n        halfVec = normalize(lightdir + eye);\n      }\n      col = ambient[i];\n      nDotL = dot(n, lightdir);\n      col = col + max(nDotL, 0.) * colDiff.rgb;\n      col = col + pow(max(dot(halfVec, n), 0.), shininess) * specular[i];\n      lighteffect = lighteffect + vec4(col, colDiff.a);\n    }\n#endif\n    \n#else // not IS_LIT\n    vec4 colDiff = vCol;\n    vec4 lighteffect = colDiff;\n#endif\n    \n#ifdef IS_TEXT\n    vec4 textureColor = lighteffect*texture2D(uSampler, vTexcoord);\n#endif\n    \n#ifdef HAS_TEXTURE\n\n// These calculations use the definitions from \n// https://docs.gl/gl3/glTexEnv\n\n#ifdef USE_ENVMAP\n    float m = 2.0 * sqrt(dot(vReflection, vReflection) + 2.0*vReflection.z + 1.0);\n    vec4 textureColor = texture2D(uSampler, vReflection.xy / m + vec2(0.5, 0.5));\n#else\n    vec4 textureColor = texture2D(uSampler, vTexcoord);\n#endif\n\n#ifdef TEXTURE_rgb\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(textureColor.rgb, lighteffect.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = lighteffect*vec4(textureColor.rgb, 1.);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - textureColor.rgb) * lighteffect.rgb, lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(lighteffect.rgb + textureColor.rgb, lighteffect.a);\n#endif\n\n#endif //TEXTURE_rgb\n        \n#ifdef TEXTURE_rgba\n\n#ifdef TEXMODE_replace\n// already done\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = lighteffect*textureColor;\n#endif\n\n#ifdef TEXMODE_decal\n    textureColor = vec4((1. - textureColor.a)*lighteffect.rgb) +\n                     textureColor.a*textureColor.rgb, \n                     lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - textureColor.rgb) * lighteffect.rgb,\n                    lighteffect.a*textureColor.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(lighteffect.rgb + textureColor.rgb,\n                    lighteffect.a*textureColor.a);\n#endif\n    \n#endif //TEXTURE_rgba\n    \n#ifdef TEXTURE_alpha\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(lighteffect.rgb, luminance);\n#endif \n\n#if defined(TEXMODE_modulate) || defined(TEXMODE_blend) || defined(TEXMODE_add)\n    textureColor = vec4(lighteffect.rgb, lighteffect.a*luminance);\n#endif\n \n#endif // TEXTURE_alpha\n    \n// The TEXTURE_luminance values are not from that reference    \n#ifdef TEXTURE_luminance\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(luminance, luminance, luminance, lighteffect.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = vec4(luminance*lighteffect.rgb, lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - luminance)*lighteffect.rgb,\n                        lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(luminance + lighteffect.rgb, lighteffect.a);\n#endif\n\n#endif // TEXTURE_luminance\n \n    \n#ifdef TEXTURE_luminance_alpha\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(luminance, luminance, luminance, textureColor.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = vec4(luminance*lighteffect.rgb, \n                        textureColor.a*lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - luminance)*lighteffect.rgb,\n                        textureColor.a*lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(luminance + lighteffect.rgb, \n                        textureColor.a*lighteffect.a);\n\n#endif\n\n#endif // TEXTURE_luminance_alpha\n    \n    fragColor = textureColor;\n\n#elif defined(IS_TEXT)\n    if (textureColor.a < 0.1)\n      discard;\n    else\n      fragColor = textureColor;\n#else\n    fragColor = lighteffect;\n#endif // HAS_TEXTURE\n    \n#ifdef HAS_FOG\n    // uFogParms elements: x = near, y = far, z = fogscale, w = (1-sin(FOV/2))/(1+sin(FOV/2))\n    // In Exp and Exp2: use density = density/far\n    // fogF will be the proportion of fog\n    // Initialize it to the linear value\n    float fogF;\n    if (uFogMode > 0) {\n      fogF = (uFogParms.y - vPosition.z/vPosition.w)/(uFogParms.y - uFogParms.x);\n      if (uFogMode > 1)\n        fogF = mix(uFogParms.w, 1.0, fogF);\n      fogF = fogF*uFogParms.z;\n      if (uFogMode == 2)\n        fogF = 1.0 - exp(-fogF);\n      // Docs are wrong: use (density*c)^2, not density*c^2\n      // https://gitlab.freedesktop.org/mesa/mesa/-/blob/master/src/mesa/swrast/s_fog.c#L58\n      else if (uFogMode == 3)\n        fogF = 1.0 - exp(-fogF*fogF);\n      fogF = clamp(fogF, 0.0, 1.0);\n      gl_FragColor = vec4(mix(fragColor.rgb, uFogColor, fogF), fragColor.a);\n    } else gl_FragColor = fragColor;\n#else\n    gl_FragColor = fragColor;\n#endif // HAS_FOG\n    \n}","players":[],"webGLoptions":{"preserveDrawingBuffer":true},"fastTransparency":true},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mds3d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Three-dimensional Multidimensional Scaling of the RESCA-E Subtests. Blue = Receptive, Red = Expressive, Green = Social Communication
</figcaption>
</figure>
</div>
</div>
</section>
<section id="confirmatory-factor-analysis-to-the-rescue" class="level2">
<h2 class="anchored" data-anchor-id="confirmatory-factor-analysis-to-the-rescue">Confirmatory Factor Analysis to the rescue?</h2>
<p>These previous analyses were exploratory analyses. Would confirmatory factor analysis (CFA) have supported the hypothesis that the three domains are cohesive? No, but it might have given the illusion of such a finding.</p>
<p>If we conduct a one-factor CFA (Figure&nbsp;5) and compare it to a three-factor CFA (Figure&nbsp;6), the model fit improves significantly (<em>p</em> &lt; .001). The loadings all look healthy in Figure&nbsp;6. What is the problem? The problem is that the factors are almost perfectly correlated, meaning that if the latent variables could be measured without error, there would be little point in distinguishing among them. Had Figure 5.1 of the <em>RESCA-E Technical Manual</em> shown the correlations among the latent factors, this would have been plainly visible (Compare with Figure&nbsp;7). In contrast, the correlations among the three-factor EFA latent variables are between .62, and .84, which means that they do not yield redundant information.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-genfactor" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-genfactor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE_files/figure-html/fig-genfactor-1.svg" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-genfactor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: General-factor CFA of RESCA-E Subtests
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-factor3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-factor3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE_files/figure-html/fig-factor3-1.svg" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-factor3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Three-factor CFA of RESCA-E Subtests
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-factorcore" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-factorcore-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE_files/figure-html/fig-factorcore-1.svg" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-factorcore-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Three-factor CFA of RESCA-E Core Subtests
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="conclusion-the-three-resca-e-language-domains-are-descriptive-categories-not-distinct-abilities" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-the-three-resca-e-language-domains-are-descriptive-categories-not-distinct-abilities">Conclusion: The Three RESCA-E Language Domains Are Descriptive Categories, Not Distinct Abilities</h2>
<p>The available evidence suggests that the distinction between receptive, expressive, and social communication abilities is mostly descriptive. There are language abilities that are legitimately classified as <em>receptive</em> or <em>expressive</em>, or <em>social</em>, but no cohesive ability constructs we could call <em>receptive language ability</em>, <em>expressive language ability</em>, or <em>social communication ability</em>. If Carroll could not find them with 400+ data sets, we should not be surprised to not find them here in this one. The three RESCA-E composites should be interpreted in this light.</p>
</section>
<section id="alternative-structure" class="level2">
<h2 class="anchored" data-anchor-id="alternative-structure">Alternative Structure</h2>
<p>A cluster analysis can sometimes detect patterns that exploratory factor analyses miss. First, we see the correlation plot (Figure&nbsp;8), with rectangles around 4 clusters (Ward’s method applied to the correlations subtracted from 1). Again, the pattern is not consistent with the 3 groupings.</p>
<div class="cell" data-fig.fullwidth="true">
<div class="cell-output-display">
<div id="fig-cor" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE_files/figure-html/fig-cor-1.svg" class="img-fluid figure-img" width="960">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Correlation plot of the RESCA-E Subtests. Blue = Receptive, Red = Expressive, Green = Social Communication
</figcaption>
</figure>
</div>
</div>
</div>
<p>Instead, in the dendrogram in Figure&nbsp;9, four clusters are highlighted plus a very narrow vocabulary cluster is singled out.</p>
<div class="cell" data-fig.fullwidth="true">
<div class="cell-output-display">
<div id="fig-hierarchical" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hierarchical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE_files/figure-html/fig-hierarchical-1.svg" class="img-fluid figure-img" width="960">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hierarchical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Hierarchical Cluster Analysis of the RESCA-E Subtest Correlation Matrix (Ward’s Method). Suggested intepretations of clusters in blue.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Instead of a three-part division between receptive, expressive, and social communication, this analysis suggests a 2 × 2 matrix (See Figure&nbsp;10). There are two expressive clusters, one of which emphasizes social communication whereas the other emphasizes narrative communication (not that narrative is non-social). There are two “receptive” clusters, one of which is more social in that it is about understanding others’ intentions, sometimes via understanding English syntax. The other comprehension cluster consists of tests measuring semantic knowledge (e.g., vocabulary) and narratives.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-matrix" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE_files/figure-html/fig-matrix-1.svg" class="img-fluid figure-img" width="864">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Matrix of Concpetual Groupings
</figcaption>
</figure>
</div>
</div>
</div>
<p>Figure&nbsp;11 shows that the 2 × 2 structure suggested by hierarchical cluster analysis is also present in the the 3D MDS model. Grab the picture with your mouse and move it around to see the structure better.</p>
<div class="cell">
<div id="fig-regroup" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored no-overflow-x">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-regroup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="rgl31158" style="width:100%;height:650px;" class="rglWebGL html-widget" aria-labelledby="rgl31158-aria"></div>
<script type="application/json" data-for="rgl31158">{"x":{"material":{"color":"#000000","alpha":1,"lit":true,"ambient":"#000000","specular":"#FFFFFF","emission":"#000000","shininess":50,"smooth":true,"front":"filled","back":"filled","size":3,"lwd":1,"fog":true,"point_antialias":false,"line_antialias":false,"texture":null,"textype":"rgb","texmode":"modulate","texmipmap":false,"texminfilter":"linear","texmagfilter":"linear","texenvmap":false,"depth_mask":true,"depth_test":"less","isTransparent":false,"polygon_offset":[0,0],"margin":"","floating":false,"tag":"","blend":["src_alpha","one_minus_src_alpha"]},"rootSubscene":6,"objects":{"26":{"id":26,"type":"lines","material":{"lit":false},"vertices":"0","colors":"1","centers":"2","ignoreExtent":false,"flags":32832},"28":{"id":28,"type":"text","material":{"lit":false,"margin":0,"floating":true,"edge":[0,1,1]},"vertices":"3","colors":"4","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"5","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"29":{"id":29,"type":"text","material":{"lit":false,"margin":1,"floating":true,"edge":[1,1,1]},"vertices":"6","colors":"7","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"8","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"30":{"id":30,"type":"text","material":{"lit":false,"margin":2,"floating":true,"edge":[1,1,1]},"vertices":"9","colors":"10","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"11","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"31":{"id":31,"type":"text","material":{"lit":false},"vertices":"12","colors":"13","texts":[["Expressive Skills for Describing and Explaining"],["Narrative Skills"],["Elicited Body Language"],["Expressive Use of Basic Morphology and Syntax"],["Situational Language Use"],["Executing Oral Directions"],["Social and Language Inference"],["Comprehension of Oral Directions"],["Comprehension of Basic Morphology and Syntax"],["Comprehension of Body Language and Vocal Emotion"],["Comprehension of Stories and Questions"],["Expressive Labeling of Vocabulary"],["Comprehension of Vocabulary"]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"14","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"32":{"id":32,"type":"lines","material":{"lit":false},"vertices":"15","colors":"16","centers":"17","ignoreExtent":false,"flags":32832},"33":{"id":33,"type":"lines","material":{"lit":false},"vertices":"18","colors":"19","centers":"20","ignoreExtent":false,"flags":32832},"34":{"id":34,"type":"lines","material":{"lit":false},"vertices":"21","colors":"22","centers":"23","ignoreExtent":false,"flags":32832},"35":{"id":35,"type":"lines","material":{"lit":false},"vertices":"24","colors":"25","centers":"26","ignoreExtent":false,"flags":32832},"36":{"id":36,"type":"lines","material":{"lit":false},"vertices":"27","colors":"28","centers":"29","ignoreExtent":false,"flags":32832},"37":{"id":37,"type":"lines","material":{"lit":false},"vertices":"30","colors":"31","centers":"32","ignoreExtent":false,"flags":32832},"38":{"id":38,"type":"lines","material":{"lit":false},"vertices":"33","colors":"34","centers":"35","ignoreExtent":false,"flags":32832},"39":{"id":39,"type":"lines","material":{"lit":false},"vertices":"36","colors":"37","centers":"38","ignoreExtent":false,"flags":32832},"40":{"id":40,"type":"lines","material":{"lit":false},"vertices":"39","colors":"40","centers":"41","ignoreExtent":false,"flags":32832},"41":{"id":41,"type":"lines","material":{"lit":false},"vertices":"42","colors":"43","centers":"44","ignoreExtent":false,"flags":32832},"42":{"id":42,"type":"lines","material":{"lit":false},"vertices":"45","colors":"46","centers":"47","ignoreExtent":false,"flags":32832},"43":{"id":43,"type":"lines","material":{"lit":false},"vertices":"48","colors":"49","centers":"50","ignoreExtent":false,"flags":32832},"44":{"id":44,"type":"text","material":{"lit":false},"vertices":"51","colors":"52","texts":[["Narrative/Semantic Communication"]],"cex":[[1.5]],"adj":[[0.5,0.5,0.5]],"centers":"53","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"45":{"id":45,"type":"text","material":{"lit":false},"vertices":"54","colors":"55","texts":[["Social/Syntactic Communication"]],"cex":[[1.5]],"adj":[[0.5,0.5,0.5]],"centers":"56","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"46":{"id":46,"type":"text","material":{"lit":false},"vertices":"57","colors":"58","texts":[["Social/Syntactic Comprehension"]],"cex":[[1.5]],"adj":[[0.5,0.5,0.5]],"centers":"59","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"47":{"id":47,"type":"text","material":{"lit":false},"vertices":"60","colors":"61","texts":[["Narrative/Semantic Comprehension"]],"cex":[[1.5]],"adj":[[0.5,0.5,0.5]],"centers":"62","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"10":{"id":10,"type":"light","vertices":[[0,0,1]],"colors":[[1,1,1,1],[1,1,1,1],[1,1,1,1]],"viewpoint":true,"finite":false},"12":{"id":12,"type":"background","material":{"lit":false,"back":"lines"},"colors":"63","centers":"64","sphere":false,"fogtype":"none","fogscale":1,"flags":32768},"27":{"id":27,"type":"bboxdeco","material":{"front":"culled","back":"culled"},"colors":"65","axes":{"mode":["none","none","none"],"step":[-1,-1,-1],"nticks":[0,0,0],"marklen":[15,15,15],"expand":[1.029999971389771,1.029999971389771,1.029999971389771]},"draw_front":false,"flags":32769},"6":{"id":6,"type":"subscene","par3d":{"antialias":8,"FOV":30,"ignoreExtent":false,"listeners":6,"mouseMode":{"none":"none","left":"trackball","right":"zoom","middle":"fov","wheel":"pull"},"observer":[0,0,2.31765079498291],"modelMatrix":[[0.8736469745635986,0,0,-0.07076582312583923],[0,0.3524267971515656,1.086503148078918,0.05582863464951515],[0,-0.9682846069335938,0.3954548239707947,-2.364319324493408],[0,0,0,1]],"projMatrix":[[3.732050895690918,0,0,0],[0,3.732050895690918,0,0],[0,0,-3.863703727722168,-8.354864120483398],[0,0,-1,0]],"skipRedraw":false,"userMatrix":[[1,0,0,0],[0,0.3420201433256682,0.9396926207859085,0],[0,-0.9396926207859085,0.3420201433256682,0],[0,0,0,1]],"userProjection":[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],"scale":[0.8736469745635986,1.030426979064941,1.156232476234436],"viewport":{"x":0,"y":0,"width":1,"height":1},"zoom":1,"bbox":[-0.2319569736719131,0.3939579129219055,-0.3264305591583252,0.2042510360479355,-0.2680382430553436,0.2049018144607544],"windowRect":[0,0,256,256],"family":"serif","font":1,"cex":1,"useFreeType":false,"fontname":"NULL","maxClipPlanes":2147483647,"glVersion":"NA","activeSubscene":0},"embeddings":{"viewport":"replace","projection":"replace","model":"replace","mouse":"replace"},"objects":[12,27,26,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,10],"subscenes":[],"flags":34129}},"crosstalk":{"key":[],"group":[],"id":[],"options":[]},"width":768,"height":768,"buffer":{"accessors":[{"bufferView":0,"componentType":5126,"count":4,"type":"VEC3"},{"bufferView":1,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":2,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":3,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":4,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":5,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":6,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":7,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":8,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":9,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":10,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":11,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":12,"componentType":5126,"count":13,"type":"VEC3"},{"bufferView":13,"componentType":5121,"count":13,"type":"VEC4","normalized":true},{"bufferView":14,"componentType":5126,"count":13,"type":"VEC3"},{"bufferView":15,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":16,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":17,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":18,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":19,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":20,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":21,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":22,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":23,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":24,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":25,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":26,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":27,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":28,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":29,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":30,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":31,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":32,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":33,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":34,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":35,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":36,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":37,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":38,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":39,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":40,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":41,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":42,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":43,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":44,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":45,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":46,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":47,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":48,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":49,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":50,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":51,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":52,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":53,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":54,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":55,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":56,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":57,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":58,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":59,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":60,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":61,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":62,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":63,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":64,"componentType":5121,"count":1,"type":"VEC3"},{"bufferView":65,"componentType":5121,"count":1,"type":"VEC4"}],"bufferViews":[{"buffer":0,"byteLength":48,"byteOffset":0},{"buffer":0,"byteLength":4,"byteOffset":48},{"buffer":0,"byteLength":24,"byteOffset":52},{"buffer":0,"byteLength":12,"byteOffset":76},{"buffer":0,"byteLength":4,"byteOffset":88},{"buffer":0,"byteLength":12,"byteOffset":92},{"buffer":0,"byteLength":12,"byteOffset":104},{"buffer":0,"byteLength":4,"byteOffset":116},{"buffer":0,"byteLength":12,"byteOffset":120},{"buffer":0,"byteLength":12,"byteOffset":132},{"buffer":0,"byteLength":4,"byteOffset":144},{"buffer":0,"byteLength":12,"byteOffset":148},{"buffer":0,"byteLength":156,"byteOffset":160},{"buffer":0,"byteLength":52,"byteOffset":316},{"buffer":0,"byteLength":156,"byteOffset":368},{"buffer":0,"byteLength":24,"byteOffset":524},{"buffer":0,"byteLength":16,"byteOffset":548},{"buffer":0,"byteLength":12,"byteOffset":564},{"buffer":0,"byteLength":24,"byteOffset":576},{"buffer":0,"byteLength":16,"byteOffset":600},{"buffer":0,"byteLength":12,"byteOffset":616},{"buffer":0,"byteLength":24,"byteOffset":628},{"buffer":0,"byteLength":16,"byteOffset":652},{"buffer":0,"byteLength":12,"byteOffset":668},{"buffer":0,"byteLength":24,"byteOffset":680},{"buffer":0,"byteLength":16,"byteOffset":704},{"buffer":0,"byteLength":12,"byteOffset":720},{"buffer":0,"byteLength":24,"byteOffset":732},{"buffer":0,"byteLength":16,"byteOffset":756},{"buffer":0,"byteLength":12,"byteOffset":772},{"buffer":0,"byteLength":24,"byteOffset":784},{"buffer":0,"byteLength":16,"byteOffset":808},{"buffer":0,"byteLength":12,"byteOffset":824},{"buffer":0,"byteLength":24,"byteOffset":836},{"buffer":0,"byteLength":16,"byteOffset":860},{"buffer":0,"byteLength":12,"byteOffset":876},{"buffer":0,"byteLength":24,"byteOffset":888},{"buffer":0,"byteLength":16,"byteOffset":912},{"buffer":0,"byteLength":12,"byteOffset":928},{"buffer":0,"byteLength":24,"byteOffset":940},{"buffer":0,"byteLength":16,"byteOffset":964},{"buffer":0,"byteLength":12,"byteOffset":980},{"buffer":0,"byteLength":24,"byteOffset":992},{"buffer":0,"byteLength":16,"byteOffset":1016},{"buffer":0,"byteLength":12,"byteOffset":1032},{"buffer":0,"byteLength":24,"byteOffset":1044},{"buffer":0,"byteLength":16,"byteOffset":1068},{"buffer":0,"byteLength":12,"byteOffset":1084},{"buffer":0,"byteLength":24,"byteOffset":1096},{"buffer":0,"byteLength":16,"byteOffset":1120},{"buffer":0,"byteLength":12,"byteOffset":1136},{"buffer":0,"byteLength":12,"byteOffset":1148},{"buffer":0,"byteLength":16,"byteOffset":1160},{"buffer":0,"byteLength":12,"byteOffset":1176},{"buffer":0,"byteLength":12,"byteOffset":1188},{"buffer":0,"byteLength":16,"byteOffset":1200},{"buffer":0,"byteLength":12,"byteOffset":1216},{"buffer":0,"byteLength":12,"byteOffset":1228},{"buffer":0,"byteLength":16,"byteOffset":1240},{"buffer":0,"byteLength":12,"byteOffset":1256},{"buffer":0,"byteLength":12,"byteOffset":1268},{"buffer":0,"byteLength":16,"byteOffset":1280},{"buffer":0,"byteLength":12,"byteOffset":1296},{"buffer":0,"byteLength":4,"byteOffset":1308},{"buffer":0,"byteLength":3,"byteOffset":1312},{"buffer":0,"byteLength":4,"byteOffset":1315}],"buffers":[{"byteLength":1319,"bytes":"IYZtvughp75PPIm+IYZtvughp75PPIm+2rTJPi8nUT7I0VE+2rTJPi8nUT7I0VE+AAAAASGG\nbb7oIae+TzyJvtq0yT4vJ1E+yNFRPgAAwH8AAIBAAACAPwAAAAEAAMB/AACAQAAAgD8AAMB/\nAACAQAAAgD8AAAABAADAfwAAgEAAAIA/AADAfwAAgEAAAIA/AAAAAQAAwH8AAIBAAACAP9q0\nyT7BKUM+FQLMPQVamj6ogD0970G7PVeeQT7oIae+kLkPvqI0SL2bHrS9W/wIvnj3tD3XbCW+\ntwwIvpf+DL6F022+yNFRPlZdQ76GovU8NelnO2ZVtL1MVGC89fpNPiGGbb6swRs9oumyPfvS\n1b0vJ1E+TzyJvngDQr2y+pQ9RaaxPBiTRrxAXyA+EcMfPLSU5L2gzKo9u+M1vSdAi/8nQIv/\nSHb//0h2//9Idv///zAw//8wMP//MDD//zAw/4saGv+LGhr/ixoa/4saGv/atMk+wSlDPhUC\nzD0FWpo+qIA9Pe9Buz1XnkE+6CGnvpC5D76iNEi9mx60vVv8CL5497Q912wlvrcMCL6X/gy+\nhdNtvsjRUT5WXUO+hqL1PDXpZztmVbS9TFRgvPX6TT4hhm2+rMEbPaLpsj370tW9LydRPk88\nib54A0K9svqUPUWmsTwYk0a8QF8gPhHDHzy0lOS9oMyqPbvjNb2fbcE+8lMpPnUUyT1AoaI+\n82uSPY8vvj2dnBw+gYCAPoyLCz8AAIA/cAeyPuyJ8j0CosM9l+wrPu9CnL73Hw++Q9vivIGa\n3731lQm+kZCQPu3s7D4AAIA/AACAPy+Rjz2PKVS+9loMvkPVt7ztJ9G9Mc4IvvCkfT0u6Ba+\n4ToIvpGQkD7t7Ow+AACAPwAAgD9OuqE8JHz/vYmECL5s+NQ9EZ8/vpE9Cb7enTE+ywiavraI\nDr6RkJA+7ezsPgAAgD8AAIA/Cg0OPlTYeb4k4wu+JjEGvpDfT74/TlE+SPDBverkL71+fk4+\nAACAP8HAQD7BwEA+AACAP0op573K2Pu9XuZPPv234r2E7bW7/aM7PtVUVr6T1PQ8k5fXPQAA\ngD/BwEA+wcBAPgAAgD9q2CO+MllHPOO3Ez7GB2C+yTYRPTrwdz2x21C+JlwFPTzD+DwAAIA/\nwcBAPsHAQD4AAIA/vHFYvnhJCz3sKDo9YX4+vle11DtZxbA8jd0Rvt/EVb7CWD8+AACAP8HA\nQD7BwEA+AACAP/ctKL40H8+9bXHVPYu0wr3yN0w+SLJ1vk7Dr7x+TiU+IlGWvIyLCz/R0NA9\n0dDQPQAAgD9epW69OMM4PjY+BL6UscG8vUoEPtuxXzx0zxK9tyPNPd+ukTyMiws/0dDQPdHQ\n0D0AAIA/PqjzvJjc6j3mw4A8U4yLvcYInD1c2aU5Hgq6vYy+oz2YuLy8jIsLP9HQ0D3R0NA9\nAACAPzjLor2p4589MyE6vAvX4r15/8c9pvmQvaSQ173DjUI+uXR3voyLCz/R0NA90dDQPQAA\ngD/YM929wEYTPsb4H75vB7I+64nyPQKiwz2dnBw+gYCAPoyLCz8AAIA/bweyPuuJ8j0CosM9\nnQicPVKVRL6L6wq+kZCQPu3s7D4AAIA/AACAP50InD1SlUS+i+sKvjADJr4ONDa9mnD+PQAA\ngD/BwEA+wcBAPgAAgD8wAya+DjQ2vZpw/j30Do29hloEPkngj72Miws/0dDQPdHQ0D0AAIA/\n9A6NvYZaBD5J4I+9AQEBAQAAAAAAAAE="}]},"context":{"shiny":false,"rmarkdown":null},"vertexShader":"#line 2 1\n// File 1 is the vertex shader\n#ifdef GL_ES\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n#endif\n\nattribute vec3 aPos;\nattribute vec4 aCol;\nuniform mat4 mvMatrix;\nuniform mat4 prMatrix;\nvarying vec4 vCol;\nvarying vec4 vPosition;\n\n#ifdef NEEDS_VNORMAL\nattribute vec3 aNorm;\nuniform mat4 normMatrix;\nvarying vec4 vNormal;\n#endif\n\n#if defined(HAS_TEXTURE) || defined (IS_TEXT)\nattribute vec2 aTexcoord;\nvarying vec2 vTexcoord;\n#endif\n\n#ifdef FIXED_SIZE\nuniform vec3 textScale;\n#endif\n\n#ifdef FIXED_QUADS\nattribute vec3 aOfs;\n#endif\n\n#ifdef IS_TWOSIDED\n#ifdef HAS_NORMALS\nvarying float normz;\nuniform mat4 invPrMatrix;\n#else\nattribute vec3 aPos1;\nattribute vec3 aPos2;\nvarying float normz;\n#endif\n#endif // IS_TWOSIDED\n\n#ifdef FAT_LINES\nattribute vec3 aNext;\nattribute vec2 aPoint;\nvarying vec2 vPoint;\nvarying float vLength;\nuniform float uAspect;\nuniform float uLwd;\n#endif\n\n#ifdef USE_ENVMAP\nvarying vec3 vReflection;\n#endif\n\nvoid main(void) {\n  \n#ifndef IS_BRUSH\n#if defined(NCLIPPLANES) || !defined(FIXED_QUADS) || defined(HAS_FOG) || defined(USE_ENVMAP)\n  vPosition = mvMatrix * vec4(aPos, 1.);\n#endif\n  \n#ifndef FIXED_QUADS\n  gl_Position = prMatrix * vPosition;\n#endif\n#endif // !IS_BRUSH\n  \n#ifdef IS_POINTS\n  gl_PointSize = POINTSIZE;\n#endif\n  \n  vCol = aCol;\n  \n// USE_ENVMAP implies NEEDS_VNORMAL\n\n#ifdef NEEDS_VNORMAL\n  vNormal = normMatrix * vec4(-aNorm, dot(aNorm, aPos));\n#endif\n\n#ifdef USE_ENVMAP\n  vReflection = normalize(reflect(vPosition.xyz/vPosition.w, \n                        normalize(vNormal.xyz/vNormal.w)));\n#endif\n  \n#ifdef IS_TWOSIDED\n#ifdef HAS_NORMALS\n  /* normz should be calculated *after* projection */\n  normz = (invPrMatrix*vNormal).z;\n#else\n  vec4 pos1 = prMatrix*(mvMatrix*vec4(aPos1, 1.));\n  pos1 = pos1/pos1.w - gl_Position/gl_Position.w;\n  vec4 pos2 = prMatrix*(mvMatrix*vec4(aPos2, 1.));\n  pos2 = pos2/pos2.w - gl_Position/gl_Position.w;\n  normz = pos1.x*pos2.y - pos1.y*pos2.x;\n#endif\n#endif // IS_TWOSIDED\n  \n#ifdef NEEDS_VNORMAL\n  vNormal = vec4(normalize(vNormal.xyz), 1);\n#endif\n  \n#if defined(HAS_TEXTURE) || defined(IS_TEXT)\n  vTexcoord = aTexcoord;\n#endif\n  \n#if defined(FIXED_SIZE) && !defined(ROTATING)\n  vec4 pos = prMatrix * mvMatrix * vec4(aPos, 1.);\n  pos = pos/pos.w;\n  gl_Position = pos + vec4(aOfs*textScale, 0.);\n#endif\n  \n#if defined(IS_SPRITES) && !defined(FIXED_SIZE)\n  vec4 pos = mvMatrix * vec4(aPos, 1.);\n  pos = pos/pos.w + vec4(aOfs,  0.);\n  gl_Position = prMatrix*pos;\n#endif\n  \n#ifdef FAT_LINES\n  /* This code was inspired by Matt Deslauriers' code in \n   https://mattdesl.svbtle.com/drawing-lines-is-hard */\n  vec2 aspectVec = vec2(uAspect, 1.0);\n  mat4 projViewModel = prMatrix * mvMatrix;\n  vec4 currentProjected = projViewModel * vec4(aPos, 1.0);\n  currentProjected = currentProjected/currentProjected.w;\n  vec4 nextProjected = projViewModel * vec4(aNext, 1.0);\n  vec2 currentScreen = currentProjected.xy * aspectVec;\n  vec2 nextScreen = (nextProjected.xy / nextProjected.w) * aspectVec;\n  float len = uLwd;\n  vec2 dir = vec2(1.0, 0.0);\n  vPoint = aPoint;\n  vLength = length(nextScreen - currentScreen)/2.0;\n  vLength = vLength/(vLength + len);\n  if (vLength > 0.0) {\n    dir = normalize(nextScreen - currentScreen);\n  }\n  vec2 normal = vec2(-dir.y, dir.x);\n  dir.x /= uAspect;\n  normal.x /= uAspect;\n  vec4 offset = vec4(len*(normal*aPoint.x*aPoint.y - dir), 0.0, 0.0);\n  gl_Position = currentProjected + offset;\n#endif\n  \n#ifdef IS_BRUSH\n  gl_Position = vec4(aPos, 1.);\n#endif\n}","fragmentShader":"#line 2 2\n// File 2 is the fragment shader\n#ifdef GL_ES\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n#endif\nvarying vec4 vCol; // carries alpha\nvarying vec4 vPosition;\n#if defined(HAS_TEXTURE) || defined (IS_TEXT)\nvarying vec2 vTexcoord;\nuniform sampler2D uSampler;\n#endif\n\n#ifdef HAS_FOG\nuniform int uFogMode;\nuniform vec3 uFogColor;\nuniform vec4 uFogParms;\n#endif\n\n#if defined(IS_LIT) && !defined(FIXED_QUADS)\nvarying vec4 vNormal;\n#endif\n\n#if NCLIPPLANES > 0\nuniform vec4 vClipplane[NCLIPPLANES];\n#endif\n\n#if NLIGHTS > 0\nuniform mat4 mvMatrix;\n#endif\n\n#ifdef IS_LIT\nuniform vec3 emission;\nuniform float shininess;\n#if NLIGHTS > 0\nuniform vec3 ambient[NLIGHTS];\nuniform vec3 specular[NLIGHTS]; // light*material\nuniform vec3 diffuse[NLIGHTS];\nuniform vec3 lightDir[NLIGHTS];\nuniform bool viewpoint[NLIGHTS];\nuniform bool finite[NLIGHTS];\n#endif\n#endif // IS_LIT\n\n#ifdef IS_TWOSIDED\nuniform bool front;\nvarying float normz;\n#endif\n\n#ifdef FAT_LINES\nvarying vec2 vPoint;\nvarying float vLength;\n#endif\n\n#ifdef USE_ENVMAP\nvarying vec3 vReflection;\n#endif\n\nvoid main(void) {\n  vec4 fragColor;\n#ifdef FAT_LINES\n  vec2 point = vPoint;\n  bool neg = point.y < 0.0;\n  point.y = neg ? (point.y + vLength)/(1.0 - vLength) :\n                 -(point.y - vLength)/(1.0 - vLength);\n#if defined(IS_TRANSPARENT) && defined(IS_LINESTRIP)\n  if (neg && length(point) <= 1.0) discard;\n#endif\n  point.y = min(point.y, 0.0);\n  if (length(point) > 1.0) discard;\n#endif // FAT_LINES\n  \n#ifdef ROUND_POINTS\n  vec2 coord = gl_PointCoord - vec2(0.5);\n  if (length(coord) > 0.5) discard;\n#endif\n  \n#if NCLIPPLANES > 0\n  for (int i = 0; i < NCLIPPLANES; i++)\n    if (dot(vPosition, vClipplane[i]) < 0.0) discard;\n#endif\n    \n#ifdef FIXED_QUADS\n    vec3 n = vec3(0., 0., 1.);\n#elif defined(IS_LIT)\n    vec3 n = normalize(vNormal.xyz);\n#endif\n    \n#ifdef IS_TWOSIDED\n    if ((normz <= 0.) != front) discard;\n#endif\n\n#ifdef IS_LIT\n    vec3 eye = normalize(-vPosition.xyz/vPosition.w);\n    vec3 lightdir;\n    vec4 colDiff;\n    vec3 halfVec;\n    vec4 lighteffect = vec4(emission, 0.);\n    vec3 col;\n    float nDotL;\n#ifdef FIXED_QUADS\n    n = -faceforward(n, n, eye);\n#endif\n    \n#if NLIGHTS > 0\n    // Simulate two-sided lighting\n    if (n.z < 0.0)\n      n = -n;\n    for (int i=0;i<NLIGHTS;i++) {\n      colDiff = vec4(vCol.rgb * diffuse[i], vCol.a);\n      lightdir = lightDir[i];\n      if (!viewpoint[i]) {\n        if (finite[i]) {\n          lightdir = (mvMatrix * vec4(lightdir, 1.)).xyz;\n        } else {\n          lightdir = (mvMatrix * vec4(lightdir, 0.)).xyz;\n        }\n      }\n      if (!finite[i]) {\n        halfVec = normalize(lightdir + eye);\n      } else {\n        lightdir = normalize(lightdir - vPosition.xyz/vPosition.w);\n        halfVec = normalize(lightdir + eye);\n      }\n      col = ambient[i];\n      nDotL = dot(n, lightdir);\n      col = col + max(nDotL, 0.) * colDiff.rgb;\n      col = col + pow(max(dot(halfVec, n), 0.), shininess) * specular[i];\n      lighteffect = lighteffect + vec4(col, colDiff.a);\n    }\n#endif\n    \n#else // not IS_LIT\n    vec4 colDiff = vCol;\n    vec4 lighteffect = colDiff;\n#endif\n    \n#ifdef IS_TEXT\n    vec4 textureColor = lighteffect*texture2D(uSampler, vTexcoord);\n#endif\n    \n#ifdef HAS_TEXTURE\n\n// These calculations use the definitions from \n// https://docs.gl/gl3/glTexEnv\n\n#ifdef USE_ENVMAP\n    float m = 2.0 * sqrt(dot(vReflection, vReflection) + 2.0*vReflection.z + 1.0);\n    vec4 textureColor = texture2D(uSampler, vReflection.xy / m + vec2(0.5, 0.5));\n#else\n    vec4 textureColor = texture2D(uSampler, vTexcoord);\n#endif\n\n#ifdef TEXTURE_rgb\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(textureColor.rgb, lighteffect.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = lighteffect*vec4(textureColor.rgb, 1.);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - textureColor.rgb) * lighteffect.rgb, lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(lighteffect.rgb + textureColor.rgb, lighteffect.a);\n#endif\n\n#endif //TEXTURE_rgb\n        \n#ifdef TEXTURE_rgba\n\n#ifdef TEXMODE_replace\n// already done\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = lighteffect*textureColor;\n#endif\n\n#ifdef TEXMODE_decal\n    textureColor = vec4((1. - textureColor.a)*lighteffect.rgb) +\n                     textureColor.a*textureColor.rgb, \n                     lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - textureColor.rgb) * lighteffect.rgb,\n                    lighteffect.a*textureColor.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(lighteffect.rgb + textureColor.rgb,\n                    lighteffect.a*textureColor.a);\n#endif\n    \n#endif //TEXTURE_rgba\n    \n#ifdef TEXTURE_alpha\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(lighteffect.rgb, luminance);\n#endif \n\n#if defined(TEXMODE_modulate) || defined(TEXMODE_blend) || defined(TEXMODE_add)\n    textureColor = vec4(lighteffect.rgb, lighteffect.a*luminance);\n#endif\n \n#endif // TEXTURE_alpha\n    \n// The TEXTURE_luminance values are not from that reference    \n#ifdef TEXTURE_luminance\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(luminance, luminance, luminance, lighteffect.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = vec4(luminance*lighteffect.rgb, lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - luminance)*lighteffect.rgb,\n                        lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(luminance + lighteffect.rgb, lighteffect.a);\n#endif\n\n#endif // TEXTURE_luminance\n \n    \n#ifdef TEXTURE_luminance_alpha\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(luminance, luminance, luminance, textureColor.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = vec4(luminance*lighteffect.rgb, \n                        textureColor.a*lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - luminance)*lighteffect.rgb,\n                        textureColor.a*lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(luminance + lighteffect.rgb, \n                        textureColor.a*lighteffect.a);\n\n#endif\n\n#endif // TEXTURE_luminance_alpha\n    \n    fragColor = textureColor;\n\n#elif defined(IS_TEXT)\n    if (textureColor.a < 0.1)\n      discard;\n    else\n      fragColor = textureColor;\n#else\n    fragColor = lighteffect;\n#endif // HAS_TEXTURE\n    \n#ifdef HAS_FOG\n    // uFogParms elements: x = near, y = far, z = fogscale, w = (1-sin(FOV/2))/(1+sin(FOV/2))\n    // In Exp and Exp2: use density = density/far\n    // fogF will be the proportion of fog\n    // Initialize it to the linear value\n    float fogF;\n    if (uFogMode > 0) {\n      fogF = (uFogParms.y - vPosition.z/vPosition.w)/(uFogParms.y - uFogParms.x);\n      if (uFogMode > 1)\n        fogF = mix(uFogParms.w, 1.0, fogF);\n      fogF = fogF*uFogParms.z;\n      if (uFogMode == 2)\n        fogF = 1.0 - exp(-fogF);\n      // Docs are wrong: use (density*c)^2, not density*c^2\n      // https://gitlab.freedesktop.org/mesa/mesa/-/blob/master/src/mesa/swrast/s_fog.c#L58\n      else if (uFogMode == 3)\n        fogF = 1.0 - exp(-fogF*fogF);\n      fogF = clamp(fogF, 0.0, 1.0);\n      gl_FragColor = vec4(mix(fragColor.rgb, uFogColor, fogF), fragColor.a);\n    } else gl_FragColor = fragColor;\n#else\n    gl_FragColor = fragColor;\n#endif // HAS_FOG\n    \n}","players":[],"webGLoptions":{"preserveDrawingBuffer":true},"fastTransparency":true},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-regroup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: A suggested regrouping of the RESCA-E Subtests.
</figcaption>
</figure>
</div>
</div>
<p>Why might there be a division between narrative/semantic vs.&nbsp;social/syntactic abilities? I can only speculate. The clumping of narrative and semantic abilities evokes the classic division of declarative memory into episodic memory and semantic memory. Why would social and syntactic subtests clump together? This is deeply speculative on my part, but there is a developing body of evidence that Broca’s Area not only is vital for the comprehension of syntax, but also the intentions of others <span class="citation" data-cites="hamzei2003human gentilucci2006repetitive">(Gentilucci et al., 2006; Hamzei et al., 2003)</span>. To oversimplify, perhaps the narrative/semantic vs.&nbsp;social/syntactic abilities distinction reflects to some degree the relative health and functioning of Wernicke’s and Broca’s area, respectively.</p>
</section>
</section>
<section id="overall-evaluation-of-the-resca-e" class="level1">
<h1>Overall Evaluation of the RESCA-E</h1>
<p>I have nothing but admiration for the scholarship, artistry, and craft so clearly evident in every aspect of the RESCA-E. Of course, one’s judgment of a test is never final; validity evidence for the RESCA-E, though so far encouraging, is still quite sparse. Nevertheless, I expect that future validation research will justify the painstaking effort that went into developing the RESCA-E, and that it will show the RESCA-E to be a sensitive and powerful tool in the assessment of language abilities</p>
</section>
<section id="references" class="level1 unnumbered invisible">
<h1 class="unnumbered invisible">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-Carroll1993" class="csl-entry">
Carroll, J. B. (1993). <em>Human cognitive abilities: A survey of factor-analytic studies</em>. Cambridge University Press.
</div>
<div id="ref-Carroll1998" class="csl-entry">
Carroll, J. B. (1998). Human cognitive abilities: A critique. In J. J. McArdle &amp; R. W. Woodcock (Eds.), <em>Human cognitive abilities in theory and practice</em> (pp. 5–24). Erlbaum.
</div>
<div id="ref-Carroll2003" class="csl-entry">
Carroll, J. B. (2003). The higher-stratum structure of cognitive abilities: Current evidence supports <em>g</em> and about ten broad factors. In H. Nyborg (Ed.), <em>The scientific study of general intelligence: Tribute to <span>A</span>rthur <span>R</span>. <span>J</span>ensen</em> (pp. 5–22). Pergamon.
</div>
<div id="ref-crawford2010evaluation" class="csl-entry">
Crawford, A. V., Green, S. B., Levy, R., Lo, W.-J., Scott, L., Svetina, D., &amp; Thompson, M. S. (2010). Evaluation of parallel analysis methods for determining the number of factors. <em>Educational and Psychological Measurement</em>, <em>70</em>(6), 885–901. <a href="https://doi.org/10.1177/0013164410379332">https://doi.org/10.1177/0013164410379332</a>
</div>
<div id="ref-gentilucci2006repetitive" class="csl-entry">
Gentilucci, M., Bernardis, P., Crisi, G., &amp; Dalla Volta, R. (2006). Repetitive transcranial magnetic stimulation of <span>B</span>roca’s area affects verbal responses to gesture observation. <em>Journal of Cognitive Neuroscience</em>, <em>18</em>(7), 1059–1074.
</div>
<div id="ref-grodzinsky2000neurology" class="csl-entry">
Grodzinsky, Y. (2000). The neurology of syntax: Language use without <span>B</span>roca’s area. <em>Behavioral and Brain Sciences</em>, <em>23</em>(1), 1–21.
</div>
<div id="ref-Guilford1967" class="csl-entry">
Guilford, J. P. (1967). <em>The nature of human intelligence.</em> McGraw-Hill.
</div>
<div id="ref-hamzei2003human" class="csl-entry">
Hamzei, F., Rijntjes, M., Dettmers, C., Glauche, V., Weiller, C., &amp; Büchel, C. (2003). The human action recognition system and its relationship to <span>B</span>roca’s area: An fMRI study. <em>Neuroimage</em>, <em>19</em>(3), 637–644.
</div>
<div id="ref-MacCann2014" class="csl-entry">
MacCann, C., Joseph, D. L., Newman, D. A., &amp; Roberts, R. D. (2014). Emotional intelligence is a second-stratum factor of intelligence: Evidence from hierarchical and bifactor models. <em>Emotion</em>, <em>14</em>(2), 358–374.
</div>
<div id="ref-Mayer2008a" class="csl-entry">
Mayer, J. D., Roberts, R. D., &amp; Barsade, S. G. (2008). Human abilities: Emotional intelligence. <em>Annual Review of Psychology</em>, <em>59</em>, 507–536.
</div>
<div id="ref-Mayer2002" class="csl-entry">
Mayer, J. D., Salovey, P., &amp; Caruso, D. R. (2002). <em><span class="nocase">Mayer-Salovey-Caruso Emotional Intelligence Test (MSCEIT) user’s manual</span></em>. Multi-Health Systems.
</div>
<div id="ref-McGrew2005" class="csl-entry">
McGrew, K. S. (2005). The <span>C</span>attell-<span>H</span>orn-<span>C</span>arroll <span>T</span>heory of <span>C</span>ognitive <span>A</span>bilities: Past, present, and future. In D. P. Flanagan &amp; P. L. Harrison (Eds.), <em>Contemporary intellectual assessment. Theories, tests, and issues</em> (2nd ed., pp. 136–181). Guilford Press.
</div>
<div id="ref-revelle2016psych" class="csl-entry">
Revelle, W. (2016). <em><span class="nocase">psych</span>: Procedures for psychological, psychometric, and personality research</em>. Northwestern University.
</div>
<div id="ref-schneider2013principles" class="csl-entry">
Schneider, W. J. (2013). Principles of assessment of aptitude and achievement. In D. Saklofske, C. Reynolds, &amp; V. Schwean (Eds.), <em>The <span>O</span>xford handbook of child psychological assessment</em> (pp. 286–330). Oxford University Press. <a href="https://doi.org/10.1093/oxfordhb/9780199796304.013.0013">https://doi.org/10.1093/oxfordhb/9780199796304.013.0013</a>
</div>
<div id="ref-Schneider2015a" class="csl-entry">
Schneider, W. J., &amp; Flanagan, D. P. (2015). The relationship between theories of intelligence and intelligence tests. In S. Goldstein, D. Princiotta, &amp; J. A. Naglieri (Eds.), <em>Handbook of intelligence: Evolutionary theory, historical perspective, and current concepts</em> (pp. 317–340). Springer.
</div>
<div id="ref-schneider2016integrating" class="csl-entry">
Schneider, W. J., Mayer, J. D., &amp; Newman, D. A. (2016). Integrating hot and cool intelligences: Thinking broadly about broad abilities. <em>Journal of Intelligence</em>, <em>4</em>(1), 1:1–25. <a href="https://doi.org/10.3390/jintelligence4010001">https://doi.org/10.3390/jintelligence4010001</a>
</div>
<div id="ref-Schneider2012" class="csl-entry">
Schneider, W. J., &amp; McGrew, K. S. (2012). The <span>C</span>attell-<span>H</span>orn-<span>C</span>arroll model of intelligence. In D. P. Flanagan &amp; P. L. Harrison (Eds.), <em>Contemporary intellectual assessment: Theories, tests and issues</em> (3rd ed., pp. 99–144). Guilford Press.
</div>
<div id="ref-Wechsler1958" class="csl-entry">
Wechsler, D. (1958). <em>The measurement and appraisal of adult intelligence</em> (4th ed.). Williams &amp; Wilkins.
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{schneider2016,
  author = {Schneider, W. Joel and Joel Schneider, W.},
  title = {The {RESCA-E} {Subtests} {Are} {Thoughtfully} {Designed} and
    {Highly} {Refined} {Measures} of {CHC} {Constructs}},
  date = {2016-10-26},
  url = {https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-schneider2016" class="csl-entry quarto-appendix-citeas">
Schneider, W. J., &amp; Joel Schneider, W. (2016, October 26). The
RESCA-E Subtests Are Thoughtfully Designed and Highly Refined Measures
of CHC Constructs. <em>AssessingPsyche</em>. <a href="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE.html">https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE.html</a>
</div></div></section></div> ]]></description>
  <guid>https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE.html</guid>
  <pubDate>Wed, 26 Oct 2016 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Difference scores, the absolute deviation, and the half-normal distribution</title>
  <dc:creator>W. Joel Schneider</dc:creator>
  <link>https://wjschne.github.io/AssessingPsyche/2014-05-05-difference-scores-absolute-deviation-half-normal-distribution/</link>
  <description><![CDATA[ 





<p>In psychological assessment, sometimes we want to contrast two scores. For example, suppose we give two tests of visual-spatial ability to an individual. On Test A the score was 95, and on Test B the score was 75.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-gv" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-gv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2014-05-05-difference-scores-absolute-deviation-half-normal-distribution/index_files/figure-html/fig-gv-1.png" class="img-fluid figure-img" width="395">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-gv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Two tests of visual-spatial ability differ by 20 points.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Both tests are measured with the standard score metric (mean = 100, SD = 15). Because these tests are intended to measure the same ability, we are surprised to see that they differ by 20 points (20 standard score points = 1⅓ standard deviations). How common is it for tests that allegedly measure the same thing to differ by 20 points or more?</p>
<p>The answer, of course, depends on the distributions of both variables and the form of the relationship between the two variables. In this case, let’s assume that the tests are multivariate normal, meaning that both variables have normal distributions and any linear combination of the two scores (including subtracting the scores) is also normal.</p>
<div id="fig-bivariatenormal" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-bivariatenormal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2014-05-05-difference-scores-absolute-deviation-half-normal-distribution/bvnormal.gif" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-bivariatenormal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: A Bivariate Normal Distribution with a correlation of .64
</figcaption>
</figure>
</div>
<p>The relationship between the two variables is linear. Linear relationships are fully described by correlation coefficients. In this case, suppose that the correlation coefficient is 0.64.</p>
<p>Few variables found in nature have a true multivariate normal distribution. However, multivariate normal distributions describe cognitive ability data reasonably well.</p>
<section id="the-mean-of-a-difference-score" class="level2">
<h2 class="anchored" data-anchor-id="the-mean-of-a-difference-score">The mean of a difference score</h2>
<p>The mean of the sum of two variables is the sum of the two means. That is,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_%7BA%20+%20B%7D%20=%20%5Cmu_A%20+%20%5Cmu_B=100+100=200%0A"></p>
<p>It works the same way with subtraction:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_%7BA%20-%20B%7D%20=%20%5Cmu_A%20-%20%5Cmu_B=100-100=0%0A"></p>
</section>
<section id="the-standard-deviation-of-a-difference-score" class="level2">
<h2 class="anchored" data-anchor-id="the-standard-deviation-of-a-difference-score">The standard deviation of a difference score</h2>
<p>The standard deviation of the sum of two variables is the square root of the sum of the two variables’ covariance matrix. The covariance matrix is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5CSigma_%7BAB%7D=%5Cbegin%7Bbmatrix%7D%0A%5Csigma_A%5E2%20&amp;%20%5Csigma_%7BAB%7D%20%5C%5C%0A%5Csigma_%7BAB%7D%20&amp;%20%5Csigma_B%5E2%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>The sum of the covariance matrix is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csigma_%7BA+B%7D=%5Csqrt%7B%20%5Csigma_%7BA%7D%5E2%20+%202%5Csigma_%7BAB%7D%20+%20%5Csigma_%7BB%7D%5E2%7D%0A"></p>
<p>The covariance is the product of the two standard deviations and the correlation <img src="https://latex.codecogs.com/png.latex?(%5Crho)">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csigma_%7BAB%7D=%5Csigma_A%20%5Csigma_B%20%5Crho_%7BAB%7D%0A"></p>
<p>Thus,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Csigma_%7BA+B%7D&amp;=%5Csqrt%7B%20%5Csigma_%7BA%7D%5E2%20+%202%5Csigma_%7BAB%7D%20+%20%5Csigma_%7BB%7D%5E2%7D%5C%5C%0A&amp;=%5Csqrt%7B%20%5Csigma_%7BA%7D%5E2%20+%202%5Csigma_A%20%5Csigma_B%20%5Crho_%7BAB%7D%20+%20%5Csigma_%7BB%7D%5E2%7D%5C%5C%0A&amp;=%5Csqrt%7B15%5E2+2*15*15*0.64+15%5E2%7D%5C%5C%0A&amp;%5Capprox%2027.1662%0A%5Cend%7Baligned%7D%0A"></p>
<p>The standard deviation of the difference of two variables is the same except that the covariance is negative.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Csigma_%7BA-B%7D&amp;=%5Csqrt%7B%20%5Csigma_%7BA%7D%5E2%20-%202%5Csigma_%7BAB%7D%20+%20%5Csigma_%7BB%7D%5E2%7D%5C%5C%0A&amp;=%5Csqrt%7B%20%5Csigma_%7BA%7D%5E2%20-%202%5Csigma_A%20%5Csigma_B%20%5Crho_%7BAB%7D%20+%20%5Csigma_%7BB%7D%5E2%7D%5C%5C%0A&amp;=%5Csqrt%7B15%5E2-2*15*15*0.64+15%5E2%7D%5C%5C%0A&amp;%5Capprox12.7279%0A%5Cend%7Baligned%7D%0A"></p>
<p>If <img src="https://latex.codecogs.com/png.latex?%5Csigma_A=%5Csigma_B"> then this formula reduces to</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Csigma_%7BA-B%7D&amp;=%5Csigma_A%5Csqrt%7B2-2r_%7BAB%7D%7D%5C%5C%0A&amp;=15%5Csqrt%7B2-2%5Ctimes.64%7D%5C%5C%0A&amp;%5Capprox12.7279%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="the-prevalence-of-a-difference-score" class="level2">
<h2 class="anchored" data-anchor-id="the-prevalence-of-a-difference-score">The prevalence of a difference score</h2>
<p>If the two variables are multivariate normal, then the difference score is also normally distributed. The difference of A and B in this example is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Baligned%7DA-B&amp;=95-75%5C%5C&amp;=20%5Cend%7Baligned%7D"></p>
<p>The population mean of the difference scores is 0 and the standard deviation is 13.24.</p>
<p>Using the z-score formula,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Az&amp;=%5Cdfrac%7BX-%5Cmu%7D%7B%5Csigma%7D%5C%5C%0A&amp;=%5Cdfrac%7B20-0%7D%7B12.7279%7D%5C%5C%0A&amp;%5Capprox%201.5713%0A%5Cend%7Baligned%7D%0A"></p>
<p>The cumulative distribution function of the standard normal distribution (Φ) is the proportion of scores to the left of a particular z-score.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" aria-controls="tabset-1-1" aria-selected="true">R</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" aria-controls="tabset-1-2" aria-selected="false">Python</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" aria-controls="tabset-1-3" aria-selected="false">Julia</a></li><li class="nav-item"><a class="nav-link" id="tabset-1-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-4" aria-controls="tabset-1-4" aria-selected="false">Excel</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" aria-labelledby="tabset-1-1-tab">
<p>In R the Φ function is the <code>pnorm</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pnorm</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5713</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9419435</code></pre>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" aria-labelledby="tabset-1-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.stats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> norm</span>
<span id="cb3-2">norm.cdf(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5713</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9419435093908327</code></pre>
</div>
</div>
</div>
<div id="tabset-1-3" class="tab-pane" aria-labelledby="tabset-1-3-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Distributions</span></span>
<span id="cb5-2">N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Normal</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Normal{Float64}(μ=0.0, σ=1.0)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cdf</span>(N, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5713</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9419435093908327</code></pre>
</div>
</div>
</div>
<div id="tabset-1-4" class="tab-pane" aria-labelledby="tabset-1-4-tab">
<p>In Excel, the Φ function is the <code>NORM.S.DIST</code> function.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5CPhi(1.5713)&amp;=%5Ctexttt%7BNORM.S.DIST%7D(1.5713)%5C%5C&amp;%5Capprox%200.9419%0A%5Cend%7Baligned%7D"></p>
</div>
</div>
</div>
<p>Thus about 5.8% (1 − .9419 = .0581) of people have a difference score of 20 or more in this particular direction and about 11.6% have a difference score of 20 or more in either direction. Thus, in this case, a difference of 20 points or more is only somewhat unusual.</p>
</section>
<section id="the-absolute-deviation" class="level2">
<h2 class="anchored" data-anchor-id="the-absolute-deviation">The absolute deviation</h2>
<p>The standard deviation is a sort of average deviation but it is not the arithmetic mean of the deviations. If you really want to know the average (unsigned) deviation, then you want the absolute deviation. Technically, the absolute deviation is the expected value of the absolute value of the deviation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BAbsolute%20Deviation%7D=E(%7CX-%5Cmu%7C)"></p>
<p>Sometimes the absolute deviation is calculated as the average deviation from the median instead of from the mean. In the case of the normal distribution, this difference does not matter because the mean and median are the same.</p>
<p>In the normal distribution, the absolute deviation is about 80% as large as the standard deviation. Specifically,</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BAbsolute%20Deviation%7D=%5Csqrt%7B%5Cdfrac%7B2%7D%7B%5Cpi%7D%7D%5Csigma"></p>
</section>
<section id="the-absolute-deviation-of-a-difference-score" class="level2">
<h2 class="anchored" data-anchor-id="the-absolute-deviation-of-a-difference-score">The absolute deviation of a difference score</h2>
<p>If the two variables are multivariate normal, the difference score is also normal. We calculate the standard deviation of the difference score and multiply it by the square root of 2 over pi. In this case, the standard deviation of the difference score was about 13.42. Thus, the average difference score is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csqrt%7B%5Cdfrac%7B2%7D%7B%5Cpi%7D%7D12.7279%5Capprox%2010.1554"></p>
</section>
<section id="why-use-the-absolute-deviation" class="level2">
<h2 class="anchored" data-anchor-id="why-use-the-absolute-deviation">Why use the absolute deviation?</h2>
<p>The standard deviation is the standard way of describing variability. Why would we use this obscure type of deviation then? Well, most people have not heard of either kind of deviation. For people who have never taken a statistics course, it is very easy to talk about the average difference score (i.e., the absolute deviation). For example, “On average, these two scores differ by 11 points.” See how easy that was?</p>
<p>By contrast, imagine saying to statistically untrained people, “We can measure variability with a statistic called the <em>standard deviation</em>. To calculate it, we take the square root of the average squared difference of every score in the population from the population mean. In this case, the standard deviation is 13 points.” Sure, this explanation can be made simpler…but at the expense of accuracy.</p>
<p>The absolute deviation can be explained easily AND accurately.</p>
</section>
<section id="the-half-normal-distribution" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-half-normal-distribution">The half-normal distribution</h2>
<p>Related to the idea of the absolute deviation is the half-normal distribution. The half-normal distribution occurs when we take a normally distributed variable and take the absolute value of all the deviations.</p>
<p><img src="https://latex.codecogs.com/png.latex?Y=%7CX-%5Cmu_X%7C"></p>
<p>To visualize the half-normal distribution, we divide the normal distribution in half at the mean and then stack the left side of the distribution on top of the right side (see Figure&nbsp;3).</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-half" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-half-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2014-05-05-difference-scores-absolute-deviation-half-normal-distribution/index_files/figure-html/fig-half-1.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-half-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: The half-normal disribution is both halves of the standard normal distribution stacked on the right side of the distribution
</figcaption>
</figure>
</div>
</div>
</div>
<p>What is the mean of the half-normal distribution? Yes, you guessed it—the absolute deviation of the normal distribution!</p>
<p>The cumulative distribution function of the half-normal distribution is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Acdf_%7B%5Ctext%7Bhalf-normal%7D%7D=2%5CPhi%5Cleft(%5Cfrac%7BX%7D%7B%5Csigma%7D%5Cright)-1%0A"></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs"><li class="nav-item"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" aria-controls="tabset-2-1" aria-selected="true">R</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" aria-controls="tabset-2-2" aria-selected="false">Python</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" aria-controls="tabset-2-3" aria-selected="false">Julia</a></li><li class="nav-item"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" aria-controls="tabset-2-4" aria-selected="false">Excel</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" aria-labelledby="tabset-2-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1">A <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">95</span></span>
<span id="cb9-2">B <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span></span>
<span id="cb9-3">sigma <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span></span>
<span id="cb9-4">r <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> .<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span></span>
<span id="cb9-5"></span>
<span id="cb9-6">AB_difference <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> A <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> B</span>
<span id="cb9-7">sigma_difference <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> sigma <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqrt</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> r)</span>
<span id="cb9-8"></span>
<span id="cb9-9"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pnorm</span>(AB_difference<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>sigma_difference) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8838983</code></pre>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" aria-labelledby="tabset-2-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.stats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> norm</span>
<span id="cb11-2">A <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">95</span></span>
<span id="cb11-3">B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span></span>
<span id="cb11-4">sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span></span>
<span id="cb11-5">r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.64</span></span>
<span id="cb11-6"></span>
<span id="cb11-7">AB_difference <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> A <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> B</span>
<span id="cb11-8">sigma_difference <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> r) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.5</span></span>
<span id="cb11-9"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> norm.cdf(AB_difference<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>sigma_difference) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.8838982560194513</code></pre>
</div>
</div>
</div>
<div id="tabset-2-3" class="tab-pane" aria-labelledby="tabset-2-3-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Distributions</span></span>
<span id="cb13-2">N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Normal</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Normal{Float64}(μ=0.0, σ=1.0)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb15-1">A <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">95</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>95</code></pre>
</div>
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb17-1">B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>75</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb19-1">sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>15</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb21-1">r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.64</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.64</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb23-1"></span>
<span id="cb23-2">AB_difference <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> A <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> B</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>20</code></pre>
</div>
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb25-1">sigma_difference <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqrt</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> r)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>12.727922061357855</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb27-1"><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cdf</span>(N, AB_difference<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>sigma_difference) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.8838982560194513</code></pre>
</div>
</div>
</div>
<div id="tabset-2-4" class="tab-pane" aria-labelledby="tabset-2-4-tab">
<p>In Excel, the Φ function is the <code>NORM.S.DIST</code> function.</p>
<p><code>=2*NORM.S.DIST((95-75)/(15*SQRT(2-2*.64)))-1</code></p>
</div>
</div>
</div>
<p>This means that about 88.4% of people have a difference score (in either direction) of 20 or less. About 11.6% have a difference score of 20 or more. Note that this is the same answer we found before using the standard deviation of the difference score.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Repost from AssessingPsyche">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Repost from AssessingPsyche
</div>
</div>
<div class="callout-body-container callout-body">
<p>This post was originally posted on 2014-05-05 <a href="https://assessingpsyche.wordpress.com/2014/05/05/difference-scores-the-absolute-deviation-and-the-half-normal-distribution/">here</a>. The figures and computations have been updated.</p>
</div>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{schneider2014,
  author = {Schneider, W. Joel},
  title = {Difference Scores, the Absolute Deviation, and the
    Half-Normal Distribution},
  date = {2014-05-05},
  url = {https://wjschne.github.io/AssessingPsyche/2014-05-05-difference-scores-absolute-deviation-half-normal-distribution/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-schneider2014" class="csl-entry quarto-appendix-citeas">
Schneider, W. J. (2014, May 5). Difference scores, the absolute
deviation, and the half-normal distribution. <em>AssessingPsyche</em>.
<a href="https://wjschne.github.io/AssessingPsyche/2014-05-05-difference-scores-absolute-deviation-half-normal-distribution/">https://wjschne.github.io/AssessingPsyche/2014-05-05-difference-scores-absolute-deviation-half-normal-distribution/</a>
</div></div></section></div> ]]></description>
  <guid>https://wjschne.github.io/AssessingPsyche/2014-05-05-difference-scores-absolute-deviation-half-normal-distribution/</guid>
  <pubDate>Mon, 05 May 2014 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Reliability coefficients are for squares</title>
  <dc:creator>W. Joel Schneider</dc:creator>
  <link>https://wjschne.github.io/AssessingPsyche/2014-01-16-rereliability-is-for-squares/</link>
  <description><![CDATA[ 





<p>The more reliable a score is, the more certain we can be about what it means (provided its validity is close to its reliability). Certain rules-of-thumb about score reliability are sometimes proposed:</p>
<ul>
<li>Base high-stakes decisions only on scores with reliability coefficients of 0.98 or better.</li>
<li>Base substantive interpretations on scores with reliability coefficients of 0.90 or better.</li>
<li>Base decisions to give more tests or not on scores with reliability coefficients of 0.80 or more.</li>
</ul>
<p>Such guidelines seem reasonable to me, but I do not find reliability coefficients to be intuitively easy to understand. How much uncertainty is associated with a reliability coefficient of .80? The value of the coefficient (.80) is not directly informative about individual scores. Instead, it refers to the correlation the scores have with a repeated measurement.</p>
<p>Another way to think about the reliability coefficient is that it is a ratio of true score variance to observed score variance. In classical test theory, an observed score (<em>X</em>) is influenced by a reliable component, the true score (<em>T</em>), and also by measurement error (<em>e</em>). That is</p>
<p><img src="https://latex.codecogs.com/png.latex?X=T+e"></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1">rxx <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> .<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span></span>
<span id="cb1-2">sigma <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span></span>
<span id="cb1-3">mu <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb1-4">sigma_ts <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> sigma <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> rxx</span>
<span id="cb1-5">sigma_e <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> sigma <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqrt</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> rxx)</span>
<span id="cb1-6"></span>
<span id="cb1-7">x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(mu <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> sigma, mu <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> sigma, sigma <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>)</span>
<span id="cb1-8">y <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dnorm</span>(x,mu, sigma_ts)</span>
<span id="cb1-9">ts <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">120</span></span>
<span id="cb1-10"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tibble</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ts =</span> ts) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb1-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb1-12">  ggnormalviolin<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_normalviolin</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> ts, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mu =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sigma =</span> sigma_ts))</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://wjschne.github.io/AssessingPsyche/2014-01-16-rereliability-is-for-squares/index_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The true score is static for each person, and the error fluctuates randomly.</p>
<p>Because the true score and error are uncorrelated, the variance of <em>X</em> is the sum of the variance of <em>T</em> and the variance fo <em>e</em>:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2_X=%5Csigma%5E2_T+%5Csigma%5E2_e"></p>
<p>Therefore, the reliability coefficient of an observed score is the ratio of the true score variance over the total variance:</p>
<p><img src="https://latex.codecogs.com/png.latex?r_%7BXX%7D=%5Cfrac%7B%5Csigma%5E2_T%7D%7B%5Csigma%5E2_X%7D"></p>
<p>In other words, what proportion of the observed score’s variability is consistent?</p>
<p>Okay, so what is <em>variance</em>? Variance is the average squared deviation from the mean. Squared quantities are not easy to think about for most of us. For this reason, I prefer to convert reliability coefficients into confidence interval widths. Confidence interval widths and reliability coefficients have a non-linear relationship:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCI%20Width%7D=2z%5Csigma_%7Bx%7D%5Csqrt%7Br_%7Bxx%7D-r%5E2_%7Bxx%7D%7D"></p>
<p>Where:</p>
<p><img src="https://latex.codecogs.com/png.latex?z"> is the z-score associated with the level of confidence you want (e.g., 1.96 for a 95% confidence interval)</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma_%7Bx%7D"> is the standard deviation of <img src="https://latex.codecogs.com/png.latex?X"></p>
<p><img src="https://latex.codecogs.com/png.latex?r_%7Bxx%7D"> is the classical test theory reliability coefficient for <img src="https://latex.codecogs.com/png.latex?X"></p>
<p>For index scores (μ = 100, σ = 15), a reliability coefficient of .80 is associated with a 95% confidence interval that is 24 points wide. That to me is much more informative than knowing that 80% of the variance is reliable.</p>
<p>Calculating a lower and upper bounds of a confidence interval for a score looks complex with all the symbols and subscripts, but after doing it a few times, it is not so bad. Basically, compute the estimated true score <img src="https://latex.codecogs.com/png.latex?(%5Chat%7BT%7D)"> and then add (or subtract) the margin of error.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Chat%7BT%7D=%5Cmu_x+r_%7Bxx%7D%5Cleft(X-%5Cmu_x%5Cright)"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCI%7D%20=%20%5Chat%7BT%7D%20%5Cpm%20z%5Csigma_x%5Csqrt%7Br_%7Bxx%7D-r%5E2_%7Bxx%7D%7D"></p>
<p>The interactive app in Figure&nbsp;1 graph below shows the non-linear relationship between reliability and 95% confidence interval widths for different observed index scores. The confidence interval width is widest when the reliability coefficient is .5 and tapers to 0 when the reliability coefficient is 0 or 1.</p>
<p>The idea that the confidence interval width is zero when reliability is perfect makes sense. However, it might be counterintuitive that the confidence interval width is also zero when the reliability coefficient is zero.</p>
<p>How is this possible? To make sense of this, we have to remember what the true score is. It is the long term average score after repeated measurements (assuming no carryover effects). If a score has no reliable component, it is pure error. When <img src="https://latex.codecogs.com/png.latex?r_%7BXX%7D=0">, the score is <img src="https://latex.codecogs.com/png.latex?X=T+e">, where <img src="https://latex.codecogs.com/png.latex?%5Csigma_T%5E2=0"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma_e%5E2=%5Csigma_X%5E2">. So the true has no variance, meaning that its mean is exactly the mean of <img src="https://latex.codecogs.com/png.latex?X"> for everyone.</p>
<p>The reason that this is true is that the true score for a variable with no reliability is a constant.</p>
<div id="fig-ci" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<pre id="fig-ci" class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 650
library(shiny)
library(dplyr)
library(ggplot2)
library(ggtext)
library(tibble)
library(ragg)
library(scales)


ui &lt;- fluidPage(
  sidebarLayout(
      mainPanel(
      plotOutput(outputId = "distPlot",width = "400px", height = "400px")
    ),
    
    sidebarPanel(
      div(style="display: inline-block; width: 200px;",
      sliderInput(
        inputId = "x",
        label = HTML("Score (&lt;i&gt;X&lt;/i&gt;)"),
        min = 40,
        max = 160,
        value = 120,
        step = 1
      )),
      div(style="display: inline-block; width: 200px;",
          sliderInput(
        inputId = "my_rxx",
        label = shiny::HTML("Reliability (&lt;i&gt;r&lt;sub&gt;XX&lt;/sub&gt;&lt;/i&gt;)"),
        min = 0,
        max = 1,
        value = .9,
        step = .01
      )),
      shiny::tags$br(),
      div(style="display: inline-block; width: 75px;",
      numericInput(
        inputId = "mu",
        label = "Mean",
        min = 0,
        max = 100,
        value = 100,
        step = 1
      )),
      div(style="display: inline-block; width: 75px;",
      numericInput(
        inputId = "sigma",
        label = "SD",
        min = 1,
        max = 15,
        value = 15, 
        step = 1
      ))
    )
    
  )
)
server &lt;- function(input, output, session) {
  output$distPlot &lt;- renderPlot({
    mu &lt;- input$mu
    sigma &lt;- input$sigma
    my_rxx &lt;- input$my_rxx
    x &lt;- input$x
    observe(updateSliderInput(session, "x", max = input$mu + input$sigma * 4, min = input$mu - input$sigma * 4))
    # mu = 100
    # sigma = 15
    # my_rxx  = .9
    # x = 120

p &lt;- .95
z &lt;- (x - mu)  / sigma
z_ci &lt;- qnorm(1 - (1 - p) / 2)
rxx = c(seq(0,.019,.001),seq(.02,.98,.01), seq(.981,1,.001))
rxx_rev &lt;- rev(rxx)
lb &lt;- sigma * (z * rxx - z_ci * sqrt(rxx - rxx ^ 2)) + mu
ub &lt;- sigma * (z * rxx_rev + z_ci * sqrt(rxx_rev - rxx_rev ^ 2)) + mu


my_see &lt;- sigma * sqrt(my_rxx - my_rxx ^ 2)
my_moe &lt;- z_ci * my_see
my_tau &lt;- sigma * z * my_rxx  + mu
my_lb &lt;- sigma * z * my_rxx - my_moe + mu
my_ub &lt;- sigma * z * my_rxx + my_moe + mu

my_xhat &lt;- (x - mu) * sqrt(my_rxx) + mu
my_see2 &lt;- sqrt(1 - my_rxx) 
my_moe2 &lt;- z_ci * my_see2
my_lb2 &lt;- my_xhat - my_moe2
my_ub2 &lt;- my_xhat + my_moe2

lb2 &lt;- sigma * (z * sqrt(rxx) - z_ci * sqrt(1 - rxx )) + mu
ub2 &lt;- sigma * (z * sqrt(rxx_rev) + z_ci * sqrt(1 - rxx_rev)) + mu


d_arrow &lt;- tibble(Reliability = my_rxx, 
                  ci = c(my_lb, my_ub))



tibble(Reliability = c(rxx, rxx_rev),
       ci = c(lb, ub),
       ci2 = c(lb2, ub2)) %&gt;% 
  ggplot(aes(Reliability, ci)) +
  geom_polygon(fill = "dodgerblue4", alpha = .2, aes(y = ci2)) +
  geom_polygon(fill = "dodgerblue3", alpha = .5) + 
  ggnormalviolin::geom_normalviolin(data = tibble(mu = my_tau, x = my_rxx, sigma = my_see), fill = "black", p_tail = .05, aes(x = x, mu = mu, sigma = sigma, width = .15, face_left = F), inherit.aes = F, color = NA, alpha = .3) +
  scale_x_continuous("Reliability Coefficient", breaks = seq(0,1,.2), labels = c("0", ".20", ".40", ".60", ".80", "1"), expand = expansion(add = .09)) + 
  scale_y_continuous("Score", breaks = -4:4 * sigma + mu, 
                     minor_breaks = seq(-4 * sigma + mu, 
                                        4 * sigma + mu,
                                        ifelse((sigma %% 3) == 0, 
                                               sigma / 3, 
                                               sigma / 2)) ) + 
  coord_fixed(ratio = 1 / (sigma * 8),
              ylim = c(-4 * sigma + mu, 4 * sigma + mu),
              clip = "off") +
  theme_minimal(16, "sans") +
  theme(panel.spacing.x = unit(5, "mm")) +
  geom_line(data = d_arrow) +
  geom_text(data = d_arrow,
            aes(label = scales::number(ci, .1), x = Reliability - .02),
            hjust = 1,
            family = "sans") +
  annotate(
    "richtext",
    x = my_rxx + .02,
    y = x,
    hjust = 0,
    label = paste0("*X* = ", x),
    color = "firebrick",
    family = "sans"
  ) +
  annotate(
    "text",
    x = my_rxx - .02,
    y = my_tau,
    hjust = 1,
    label = scales::number(my_tau, .1),
    family = "sans"
  ) +
  annotate("point", x = my_rxx, y = my_tau) +
  annotate("point", x = my_rxx, y = x, size = 3, color = "firebrick") + 
  ggtitle(paste0("Confidence Interval Width = ", scales::number(my_ub - my_lb, .1)))
  
    
  })
}
shinyApp(ui = ui, server = server)
</code></pre>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The relationship of reliability coefficients and confidence interval widths.
</figcaption>
</figure>
</div>
<p>Paying close attention to confidence intervals allows you to do away with rough rules-of-thumb about reliability and make more direct and accurate interpretations about individual scores.</p>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{schneider2014,
  author = {Schneider, W. Joel},
  title = {Reliability Coefficients Are for Squares},
  date = {2014-01-16},
  url = {https://wjschne.github.io/AssessingPsyche/2014-01-16-rereliability-is-for-squares/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-schneider2014" class="csl-entry quarto-appendix-citeas">
Schneider, W. J. (2014, January 16). Reliability coefficients are for
squares. <em>AssessingPsyche</em>. <a href="https://wjschne.github.io/AssessingPsyche/2014-01-16-rereliability-is-for-squares/">https://wjschne.github.io/AssessingPsyche/2014-01-16-rereliability-is-for-squares/</a>
</div></div></section></div> ]]></description>
  <category>psychometrics</category>
  <category>reliability</category>
  <category>confidence intervals</category>
  <guid>https://wjschne.github.io/AssessingPsyche/2014-01-16-rereliability-is-for-squares/</guid>
  <pubDate>Thu, 16 Jan 2014 05:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle, Non-Technical Introduction to Factor Analysis</title>
  <dc:creator>W. Joel Schneider</dc:creator>
  <link>https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/</link>
  <description><![CDATA[ 





<p>When measuring characteristics of physical objects, there may be some disagreement about the best methods to use but there is little disagreement about which dimensions are being measured. We know that we are measuring length when we use a ruler and we know that we are measuring temperature when we use a thermometer. It is true that heating some materials makes them expand but we are virtually never confused about whether heat and length represent distinct dimensions that are independent of each other. That is, they are independent of each other in the sense that things can be cold and long, cold and short, hot and long, or hot and short.</p>
<p>Unfortunately, we are not nearly as clear about what we are measuring when we attempt to measure psychological dimensions such as personality traits, motivations, beliefs, attitudes, and cognitive abilities. Psychologists often disagree not only about what to name these dimensions but also about how many dimensions there are to measure. For example, you might think that there exists a personality trait called niceness. Another person might disagree with you, arguing that niceness is a vague term that lumps together 2 related but distinguishable traits called friendliness and kindness. Another person could claim that kindness is too general and that we must separate kindness with friends from kindness with strangers.</p>
<p>As you might imagine, these kinds of arguments can quickly lead to hypothesizing the existence of as many different traits as our imaginations can generate. The result would be a hopeless confusion among psychological researchers because they would have no way to agree on what to measure so that they can build upon one another’s findings. Fortunately, there are ways to put some limits on the number of psychological dimensions and come to some degree of consensus about what should be measured. One of the most commonly used of such methods is called factor analysis.</p>
<p>Although the mathematics of factor analysis is complicated, the logic behind it is not difficult to understand. The assumption behind factor analysis is that things that co-occur tend to have a common cause. For example, fevers, sore throats, stuffy noses, coughs, and sneezes tend to occur at roughly the same time in the same person. Often, they are caused by the same thing, namely, the virus that causes the common cold. Note that although the virus is one thing, its manifestations are quite diverse. In psychological assessment research, we measure a diverse set of abilities, behaviors and symptoms and attempt to deduce which underlying dimensions cause or account for the variations in behavior and symptoms we observe in large groups of people. We measure the relations between various behaviors, symptoms, and test scores with correlation coefficients and use factor analysis to discover patterns of correlation coefficients that suggest the existence of underlying psychological dimensions.</p>
<p>All else being equal, a simple theory is better than a complicated theory. Therefore, factor analysis helps us discover the smallest number of psychological dimensions (i.e., factors) that can account for the correlation patterns in the various behaviors, symptoms, and test scores we observe. For example, imagine that we create 4 different tests that would measure people’s knowledge of vocabulary, grammar, arithmetic, and geometry. If the correlations between all of these tests were 0 (i.e., high scorers on one test are no more likely to score high on the other tests than low scorers), then the factor analysis would suggest to us that we have measured 4 distinct abilities and no simplification of the data is possible. The correlations between all the tests are displayed in Table&nbsp;1.</p>
<div class="cell">
<div id="tbl-independent" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-independent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Correlation Matrix of Academic Tests
</figcaption>
<div aria-describedby="tbl-independent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/tbl-independent-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>In Figure&nbsp;1, the theoretical model that would be implied is that there are 4 abilities (shown as circles) that influence performance on 4 tests (shown as squares). The numbers beside the arrows imply that the abilities and the tests have high but imperfect correlations of 0.9.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-independent" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-independent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/fig-independent-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-independent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Four Independent Tests
</figcaption>
</figure>
</div>
</div>
</div>
<p>Of course, you probably recognize that it is very unlikely that the correlations between these tests would be 0. Therefore, imagine that the correlation between the vocabulary and grammar tests is quite high: .81. This means that high scorers on vocabulary are likely to also score high on grammar and low scorers on vocabulary are likely to score low on grammar. The correlation between arithmetic and geometry is .81 also. Furthermore, the correlations between the language tests and the mathematics tests is 0. The new correlation matrix is in Table&nbsp;2.</p>
<div class="cell">
<div id="tbl-independent2" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-independent2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Correlation Matrix of Academic Tests
</figcaption>
<div aria-describedby="tbl-independent2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/tbl-independent2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>Factor analysis would suggest that we have measured not 4 distinct abilities but rather 2 abilities. Researchers interpreting the results of the factor analysis would have to use their best judgment to decide what to call these 2 abilities. In this case, it would seem reasonable to call them language ability and mathematical ability. These 2 abilities (shown below as circles in Figure&nbsp;2) influence performance on 4 tests (shown as squares).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-independent2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-independent2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/fig-independent2-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-independent2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Two Independent Academic Abilities
</figcaption>
</figure>
</div>
</div>
</div>
<p>Now imagine that the correlations between all 4 tests is equally high, as shown in Table&nbsp;3. That is, for example, vocabulary is just as strongly correlated with geometry as it is with grammar.</p>
<div class="cell">
<div id="tbl-general" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-general-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: Correlation Matrix of Academic Tests
</figcaption>
<div aria-describedby="tbl-general-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/tbl-general-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>In this case, factor analysis would suggest that the simplest explanation for this pattern of correlations is that there is just 1 factor that causes all of these tests to be equally correlated. We might call this factor <em>general academic ability</em>, as shown in Figure&nbsp;3.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-general" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-general-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/fig-general-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-general-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: General Academic Ability
</figcaption>
</figure>
</div>
</div>
</div>
<p>In reality, if you were to actually measure these 4 abilities, the results would not be so clear. It is likely that all of the correlations would be positive and substantially above 0. It is also likely that the language subtests would correlate more strongly with each other than with the mathematical subtests. The new correlation matrix is in Table&nbsp;4.</p>
<div class="cell">
<div id="tbl-hierarchical" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-hierarchical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: Correlation Matrix of Academic Tests
</figcaption>
<div aria-describedby="tbl-hierarchical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/tbl-hierarchical-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>Given the correlations in Table&nbsp;4, factor analysis would suggest that language and mathematical abilities are distinct but not entirely independent from each other. That is, language abilities and mathematics abilities are substantially correlated with each other. Factors can be correlated for a variety of reasons, but one possibility is that there is a general academic (or intellectual) ability that influences performance in all academic areas. Figure&nbsp;4, abilities are arranged in hierarchies with general abilities influencing narrow abilities.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-hierarchical" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hierarchical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/fig-hierarchical-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hierarchical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: A Hierarchical Model of Academic Abilities
</figcaption>
</figure>
</div>
</div>
</div>
<section id="exploratory-factor-analysis" class="level1">
<h1>Exploratory Factor Analysis</h1>
<p>Factor analysis can help researchers decide how best to summarize large amounts of information about people using just a few scores. For example, when we ask parents to complete questionnaires about behavior problems their children might have, the questionnaires can have hundreds of items. It would take too long and would be too confusing to review every item. Factor analysis can simplify the information while minimizing the loss of detail. Here is an example of a short questionnaire that factor analysis can be used to summarize.</p>
<p>On a scale of 1 to 5, compared to other children his or her age, my child…</p>
<ol type="1">
<li>gets in fights frequently at school</li>
<li>is defiant to adults</li>
<li>is very impulsive</li>
<li>has stomachaches frequently</li>
<li>is anxious about many things</li>
<li>appears sad much of the time</li>
</ol>
<p>If we give this questionnaire to a large, representative sample of parents, we can calculate the correlations between the items (Table&nbsp;5).</p>
<div class="cell">
<div id="tbl-rating" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-rating-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5: Correleations Among Rating Scale Items
</figcaption>
<div aria-describedby="tbl-rating-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/tbl-rating-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>Using this set of correlation coefficients, factor analysis suggests that there are 2 factors being measured by this behavior rating scale. The logic of factor analysis suggests that the reason items 1-3 have high correlations with each other is that each of them has a high correlation with the first factor. Similarly, items 4-6 have high correlations with each other because they have high correlations with the second factor. The correlations that the items have with the hypothesized factors are called factor loadings. The factor loadings can be seen in Table&nbsp;6</p>
<div class="cell">
<div id="tbl-loadings" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-loadings-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;6: EFA Loadings for Behavioral Items
</figcaption>
<div aria-describedby="tbl-loadings-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/tbl-loadings-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>Factor analysis tells us which items “load” on which factors but it cannot interpret the meaning of the factors. Usually researchers look at all of the items that load on a factor and use their intuition or knowledge of theory to identify what the items have in common. In this case, Factor 1 could receive any number of names such as <em>Conduct Problems</em>, <em>Acting Out</em>, or <em>Externalizing Behaviors</em>. Likewise, Factor 2 could be called <em>Mood Problems</em>, <em>Negative Affectivity</em>, or <em>Internalizing Behaviors</em>. Thus, the problems on this behavior rating scale can be summarized fairly efficiently with just 2 scores.</p>
<p>In this example, a reduction of 6 scores to 2 scores may not seem terribly useful. In actual behavior rating scales, factor analysis can reduce the overwhelming complexity of hundreds of different behavior problems to a more manageable number of scores that help professionals more easily conceptualize individual cases.</p>
<p>It should be noted that factor analysis also calculates the correlation among factors. If a large number of factors are identified and there are substantial correlations (i.e., significantly larger than 0) among factors, this new correlation matrix can be factor analyzed also to obtain <em>second-order factors</em>. These factors, in turn, can be analyzed to obtain <em>third-order factors</em>. Theoretically, it is possible to have even higher order factors but most researchers rarely find it necessary to go beyond third-order factors. The <em>g</em>-factor from intelligence test data is an example of a third-order factor that emerges because all tests of cognitive abilities are positively correlated.</p>
<p>In Table&nbsp;6, the 2 factors have a correlation of .46, suggesting that children who have externalizing problems are also at risk of having internalizing problems. It is therefore reasonable to calculate a second-order factor score that measures the overall level of behavior problems.</p>
<p>This example illustrates the most commonly used type of factor analysis: <em>exploratory factor analysis</em>. Exploratory factor analysis is helpful when we wish to summarize data efficiently, we are not sure how many factors are present in our data, or we are not sure which items load on which factors.</p>
</section>
<section id="confirmatory-factor-analysis" class="level1">
<h1>Confirmatory Factor Analysis</h1>
<p><em>Confirmatory factor analysis</em> is a method that researchers can use to test highly specific hypotheses. For example, a researcher might want to know if the 2 different types of items on the WISC-IV Digit Span subtest measures the same ability or 2 different abilities. On the Digits Forward type of item, the child must repeat a string of digits in the same order in which they were heard. On the Digits Backward type of item, the child must repeat the string of digits in reverse order. Some researchers believe that repeating numbers verbatim measures auditory short-term memory storage capacity and that repeating numbers in reverse order measures executive control, the ability to allocate attentional resources efficiently to solve multi-step problems. Typically, clinicians add the raw scores of both types of items to produce a single score. If the 2 item types measure different abilities, adding the raw scores together is like adding apples and orangutans. If, however, they measure the same ability, adding the scores together is valid and will produce a more reliable score than using separate scores.</p>
<p>To test this hypothesis, we can use confirmatory factor analysis to see if the 2 item types measure different abilities. We would need to identify or invent several tests that are likely to measure the 2 separate abilities that we believe are measured by the 2 types of Digit Span items. Usually, using 3 tests per factor is sufficient.</p>
<p>Next, we specify the hypotheses, or models, we wish to test:</p>
<section id="all-of-the-tests-measure-the-same-ability" class="level2">
<h2 class="anchored" data-anchor-id="all-of-the-tests-measure-the-same-ability">All of the tests measure the same ability</h2>
<p>A graphical representation of a hypothesis in confirmatory factor analysis is called a path diagram. Tests are drawn with rectangles and hypothetical factors are drawn with ovals. The correlations between tests and factors are drawn with arrows. The path diagram for this hypothesis would look like Figure&nbsp;5.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-gwm" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gwm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/fig-gwm-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gwm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: General Working Memory
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="both-digits-forward-and-digits-backward-measure-short-term-memory-storage-capacity-and-are-distinct-from-executive-control." class="level2">
<h2 class="anchored" data-anchor-id="both-digits-forward-and-digits-backward-measure-short-term-memory-storage-capacity-and-are-distinct-from-executive-control.">Both Digits Forward and Digits Backward measure short-term memory storage capacity and are distinct from executive control.</h2>
<p>The path diagram would look like this (the curved arrow allows for the possibility that the 2 factors might be correlated)</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-gwm2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gwm2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/fig-gwm2-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gwm2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Two-Factors of Working Memory, Model 1
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="digits-forward-and-digits-backward-measure-different-abilities." class="level2">
<h2 class="anchored" data-anchor-id="digits-forward-and-digits-backward-measure-different-abilities.">Digits Forward and Digits Backward measure different abilities.</h2>
<p>If Digits Forward is primarily a measure of Short-Term Storage, and Digits Backward is primary a measure of Executive control, the path diagram would look like Figure&nbsp;7</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-gwm3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gwm3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/index_files/figure-html/fig-gwm3-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gwm3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Two-Factors of Working Memory, Model 2
</figcaption>
</figure>
</div>
</div>
</div>
<p>Confirmatory factor analysis produces a number of statistics, called fit statistics that tell us which of the models or hypotheses we tested are most in agreement with the data. Studying the results, we can select the best model or perhaps generate a new model if none of them provide a good “fit” with the data. With structural equation modeling, a procedure that is very similar to confirmatory factor analysis, we can test extremely complex hypotheses about the structure of psychological variables.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Originally <a href="https://assessingpsyche.wordpress.com/2014/01/13/a-gentle-non-technical-introduction-to-factor-analysis/">posted 2014-01-13 on AssessingPsyche</a>. The article has been revised several times since it was written originally for <em>Cohen &amp; Swerdlik’s Psychological Testing and Assessment: An Introduction To Tests and Measurement</em> (Ninth Edition)</p>
</div>
</div>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{schneider2014,
  author = {Schneider, W. Joel},
  title = {A {Gentle,} {Non-Technical} {Introduction} to {Factor}
    {Analysis}},
  date = {2014-01-13},
  url = {https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-schneider2014" class="csl-entry quarto-appendix-citeas">
Schneider, W. J. (2014, January 13). A Gentle, Non-Technical
Introduction to Factor Analysis. <em>AssessingPsyche</em>. <a href="https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/">https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/</a>
</div></div></section></div> ]]></description>
  <category>statistics</category>
  <guid>https://wjschne.github.io/AssessingPsyche/2014-01-13-gentle-introduction-to-factor-analysis/</guid>
  <pubDate>Mon, 13 Jan 2014 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Visualizing Covariance</title>
  <dc:creator>W. Joel Schneider</dc:creator>
  <link>https://wjschne.github.io/AssessingPsyche/2012-09-13-visualizing-covariance/</link>
  <description><![CDATA[ 





<p>Correlation? I get it. I have a gut-level sense of what it is. Covariance? Somehow it just eludes me. I mean, I know the formulas, and I can give you a conceptual definition of it—but its meaning never really sunk in.</p>
<p>One thing about covariance that always seemed counterintuitive to me is that covariance between two variables of unequal variance can sometimes be larger than the variance of the variable with less variance. For example, if X has a variance of 9, Y has a variance of 64 and the correlation between X and Y is 0.5, the covariance between X and Y is 12. How can X have a larger covariance with Y than its own variance (i.e., its covariance with itself)? Never made sense to me.</p>
<p>To figure it out, I created a little web app that allows the user to change the standard deviations of variables <em>x</em> and <em>y</em>, as well as the correlation between the two variables.</p>
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 650
library(shiny)
library(glue)
library(dplyr)
library(tibble)
library(ggplot2)
library(ggtext) 

prob_label &lt;- function (p, accuracy = 0.01, digits = NULL, max_digits = NULL, 
    remove_leading_zero = TRUE, round_zero_one = TRUE) 
{
    if (is.null(digits)) {
        l &lt;- scales::number(p, accuracy = accuracy)
    }
    else {
        sig_digits &lt;- abs(ceiling(log10(p + p/1e+09)) - digits)
        pgt99 &lt;- p &gt; 0.99
        sig_digits[pgt99] &lt;- abs(ceiling(log10(1 - p[pgt99])) - 
            digits + 1)
        sig_digits[ceiling(log10(p)) == log10(p) &amp; (-log10(p) &gt;= 
            digits)] &lt;- sig_digits[ceiling(log10(p)) == log10(p) &amp; 
            (-log10(p) &gt;= digits)] - 1
        sig_digits[is.infinite(sig_digits)] &lt;- 0
        l &lt;- purrr::map2_chr(p, sig_digits, formatC, format = "f", 
            flag = "#")
    }
    if (remove_leading_zero) 
        l &lt;- sub("^-0", "-", sub("^0", "", l))
    if (round_zero_one) {
        l[p == 0] &lt;- "0"
        l[p == 1] &lt;- "1"
        l[p == -1] &lt;- "-1"
    }
    if (!is.null(max_digits)) {
        if (round_zero_one) {
            l[round(p, digits = max_digits) == 0] &lt;- "0"
            l[round(p, digits = max_digits) == 1] &lt;- "1"
            l[round(p, digits = max_digits) == -1] &lt;- "-1"
        }
        else {
            l[round(p, digits = max_digits) == 0] &lt;- paste0(".", 
                paste0(rep("0", max_digits), collapse = ""))
            l[round(p, digits = max_digits) == 1] &lt;- paste0("1.", 
                paste0(rep("0", max_digits), collapse = ""))
            l[round(p, digits = max_digits) == -1] &lt;- paste0("-1.", 
                paste0(rep("0", max_digits), collapse = ""))
        }
    }
    l &lt;- sub(pattern = "-", replacement = "−", x = l)
    Encoding(l) &lt;- "UTF-8"
    dim(l) &lt;- dim(p)
    l
}
ui &lt;- fluidPage(
  sidebarLayout(
      mainPanel(
      plotOutput(outputId = "distPlot",width = "400px", height = "400px")
    ),
    sidebarPanel(
      div(style="display: inline-block; width: 200px;",
      sliderInput(
        inputId = "sd_blue",
        label = "SD for x:",
        min = 1,
        max = 10,
        value = 10
      )),
      div(style="display: inline-block; width: 200px;",
      sliderInput(
        inputId = "sd_red",
        label = "SD for y:",
        min = 1,
        max = 10,
        value = 10
      )),
      div(style="display: inline-block; width: 200px;",
      sliderInput(
        inputId = "r",
        label = "Correlation (r)",
        min = 0,
        max = 1,
        value = .5, step = .01
      ))
    )
    
  )
)
server &lt;- function(input, output) {
  output$distPlot &lt;- renderPlot({
    sd_blue &lt;- input$sd_blue
    sd_red &lt;- input$sd_red
    r &lt;- input$r
    x_red &lt;- sd_red / 2
    y_red &lt;- x_red + sd_blue
    x_blue &lt;- sd_red + sd_blue / 2
    y_blue &lt;- sd_blue / 2
    x_pink &lt;- x_blue
    y_pink &lt;- y_red
    x_purple &lt;- x_blue
    y_purple &lt;- sd_blue + r * sd_red / 2
    tibble(
      x = c(x_red, x_blue, x_pink, x_purple),
      y = c(y_red, y_blue, y_pink, y_purple),
      width =  c(sd_red, sd_blue, sd_blue, sd_blue),
      height = c(sd_red, sd_blue, sd_red, sd_red  * r),
      color = c("firebrick4", "dodgerblue4", "orchid", "orchid4"),
      label = c(
        glue("Var(*y*) = {sd_red ^ 2}"),
        glue("Var(*x*) = {sd_blue ^ 2}"),
        "",
        glue("Cov(*xy*) = {round(sd_blue * sd_red * r, 2)}")
      )
    ) %&gt;%
      ggplot(aes(x, y)) +
      geom_tile((aes(
        width = width,
        height = height,
        fill = I(color)
      ))) +
      geom_richtext(
        aes(label = label),
        color = "white",
        size = 4,
        fill = NA,
        label.color = NA
      ) +
      geom_segment(
        data = tibble(
          x = c(sd_red, sd_red, sd_red + sd_blue),
          y = c(sd_blue, sd_blue, sd_blue),
          xend = c(sd_red + sd_blue, sd_red, sd_red + sd_blue),
          yend = c(sd_blue, sd_red + sd_blue, r * sd_red + sd_blue)
        ),
        aes(xend = xend, yend = yend),
        color = "white",
        arrow = arrow(
          15,
          length = unit(10, "pt"),
          ends = "both",
          type = "closed"
        )
      ) +
      geom_richtext(
        data = tibble(
          x = c(x_blue, sd_red, sd_red + sd_blue),
          y = c(sd_blue, x_pink, y_purple),
          label = c(
            glue("SD~*x*~ = {sd_blue}"),
            glue("SD~*y*~ = {sd_red}"),
            glue("*r*~*xy*~ = {prob_label(r)}")
          ),
          angle = c(0, 90, 90),
          vjust = c(.5, .5, 1.1)
        ),
        aes(
          label = label,
          angle = angle,
          vjust = vjust
        )
      ) +
      scale_x_continuous(NULL, 
                         expand = expansion(add = 1), 
                         limits = c(0, 20)) +
      scale_y_continuous(NULL, 
                         expand = expansion(add = 1), 
                         limits = c(0, 20))+
      coord_equal(clip = "off") +
      theme_void() +
      theme(panel.background = element_rect("black"))
  })
}
shinyApp(ui = ui, server = server)</code></pre>
<p>The area of the blue square is equal to the variance of X. The area of the red square is equal to the variance of Y. The pink rectangle (which is partially occluded by the purple rectangle) is how large covariance could be if X and Y were perfectly correlated. The area of the purple square is equal to the covariance between X and Y. The ratio of the area of the purple rectangle to the area of the pink rectangle is equal to the correlation between X and Y.</p>
<p>I’m not sure why but this visualization has made me feel better about covariance. It’s like were friends now. 😉</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Originally <a href="https://assessingpsyche.wordpress.com/2012/09/13/visualizing-covariance/">posted 2012-09-13 on AssessingPsyche</a>. The original article had a web app created with Mathematica’s computatable document format. Because link to the app is now dead, I recreated the app in Shinylive.</p>
</div>
</div>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{schneider2012,
  author = {Schneider, W. Joel},
  title = {Visualizing {Covariance}},
  date = {2012-09-13},
  url = {https://wjschne.github.io/AssessingPsyche/2012-09-13-visualizing-covariance/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-schneider2012" class="csl-entry quarto-appendix-citeas">
Schneider, W. J. (2012, September 13). Visualizing Covariance.
<em>AssessingPsyche</em>. <a href="https://wjschne.github.io/AssessingPsyche/2012-09-13-visualizing-covariance/">https://wjschne.github.io/AssessingPsyche/2012-09-13-visualizing-covariance/</a>
</div></div></section></div> ]]></description>
  <category>statistics</category>
  <guid>https://wjschne.github.io/AssessingPsyche/2012-09-13-visualizing-covariance/</guid>
  <pubDate>Thu, 13 Sep 2012 04:00:00 GMT</pubDate>
</item>
</channel>
</rss>
