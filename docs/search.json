[
  {
    "objectID": "vita.html#w.-joel-schneider",
    "href": "vita.html#w.-joel-schneider",
    "title": "Curriculum Vitae",
    "section": "W. Joel Schneider",
    "text": "W. Joel Schneider\n\n\nTemple University\nCollege of Education & Human Development\nPsychological Studies in Education\n358 Ritter Hall\nPhiladelphia, PA 19122-6091\n\nOffice: (215) 204-8093\nEmail: schneider@temple.edu\nWeb: Faculty Profile\nBlog: AssessingPsyche"
  },
  {
    "objectID": "vita.html#current-grant-support",
    "href": "vita.html#current-grant-support",
    "title": "Curriculum Vitae",
    "section": "Current Grant Support",
    "text": "Current Grant Support\nNone"
  },
  {
    "objectID": "vita.html#past-grant-support",
    "href": "vita.html#past-grant-support",
    "title": "Curriculum Vitae",
    "section": "Past Grant Support",
    "text": "Past Grant Support\n\nVirtual Charter School Performance Reviews and Support [Extension] (PI), with Christopher McGinley, Sarah Cordes, and Beth Olanoff, $480,960, Pennsylvania Department of Education (2022–2023).\nStatistical Validation Analysis of the Functional Cattell Horn Carroll (F-CHC) Model with Measures of Intelligence (PI), $15,000, Woodcock Institute Research Grant Award (January 2021–July 2021).\nGeometryByExample: Developing an Effective Intervention for Varied Geometry Content and Learner Characteristics (Co-PI), with Julie Booth (PI), Kelly McGinn, Christina Barbieri, & M. Suzanne Donovan, $1,396,715, US Department of Education R305A190126 (July 2019–June 2022).\nVirtual Charter School Performance Reviews and Support (PI), with Christopher McGinley, Sarah Cordes, Beth Olanaff, and Annemarie Hindman, $511,560, Pennsylvania Department of Education (2020–2021).\nThe Roots and Fruits of Positive School Climate: A Multilevel Examination of School Climate’s Mediating Role in the Relations Among Student Risk Factors and Student Performance Outcomes (Co-PI), with Laura Pendergast (PI) and Armando Estrada, $3000, Pennsylvania Department of Education (2018–2019).\nDevelopment of the Compositator (PI), $11,000, Woodcock-Muñoz Foundation (2008–2010)\nExploring the Impact of Cognitive Abilities on Behavior Problems (PI), $2500, Illinois State University (2005)"
  },
  {
    "objectID": "vita.html#publication-indices",
    "href": "vita.html#publication-indices",
    "title": "Curriculum Vitae",
    "section": "Publication Indices",
    "text": "Publication Indices\n\nGoogle Scholar Citations: 3586\nh-index: 25\ni10-index: 37\n\n\n\n\n\n\nGoogle Scholar Citations of My Work"
  },
  {
    "objectID": "vita.html#books",
    "href": "vita.html#books",
    "title": "Curriculum Vitae",
    "section": "Books",
    "text": "Books\n\nCohen, R. J., Schneider, W. J., & Tobin, R. M. (2022). Psychological testing and assessment: An introduction to tests and measurement (10th ed.). McGraw Hill LLC.\n\n\nSchneider, W. J., Mather, N., Lichtenberger, E. O., & Kaufman, N. L. (2018). Essentials of assessment report writing (2nd ed.). Wiley."
  },
  {
    "objectID": "vita.html#journal-articles",
    "href": "vita.html#journal-articles",
    "title": "Curriculum Vitae",
    "section": "Journal Articles",
    "text": "Journal Articles\n\nMcGrew, K. S., Schneider, W. J., Decker, S. L., & Bulut, O. (2023). A psychometric network analysis of CHC intelligence measures: implications for research, theory, and interpretation of broad CHC scores “beyond g”. Journal of Intelligence, 11(1), 19. https://doi.org/10.3390/jintelligence11010019 \n\n\nSchneider, W. J., & Ji, F. (2023). Detecting unusual score patterns in the context of relevant predictors. Journal of Pediatric Neuropsychology, 9, 1–17. https://doi.org/10.1007/s40817-022-00137-x\n\n\nDowdy, A., Peltier, C., Tincani, M., Schneider, W. J., Hantula, D. A., & Travers, J. C. (2021). Meta‐analyses and effect sizes in applied behavior analysis: A review and discussion. Journal of Applied Behavior Analysis, 54(4), 1317–1340. https://doi.org/10.1002/jaba.862 \n\n\nDowdy, A., Tincani, M., & Schneider, W. J. (2020). Evaluation of publication bias in response interruption and redirection: A meta‐analysis. Journal of Applied Behavior Analysis, 53(4), 2151–2171. https://doi.org/10.1002/jaba.724 \n\n\nHajovsky, D. B., Villeneuve, E. F., Schneider, W. J., & Caemmerer, J. M. (2020). An alternative approach to cognitive and achievement relations research: An introduction to quantile regression. Journal of Pediatric Neuropsychology, 6, 83–95. https://doi.org/10.1007/s40817-020-00086-3 \n\n\nDombrowski, S. C., Beaujean, A. A., McGill, R. J., Benson, N. F., & Schneider, W. J. (2019). Using exploratory bifactor analysis to understand the latent structure of multidimensional psychological measures: An example featuring the WISC-V. Structural Equation Modeling: A Multidisciplinary Journal, 26(6), 847–860. https://doi.org/10.1080/10705511.2019.1622421 \n\n\nSchneider, W. J., & McGrew, K. S. (2019). Process Overlap Theory is a milestone achievement among intelligence theories. Journal of Applied Research in Memory and Cognition, 8(3), 273–276. https://doi.org/https://doi.org/10.1016/j.jarmac.2019.06.006 \n\n\nSchneider, W. J., & Roman, Z. (2018). Fine-tuning Cross-Battery Assessment procedures: After follow-up testing, use all valid scores, cohesive or not. Journal of Psychoeducational Assessment, 36(1), 34–54. https://doi.org/10.1177/0734282917722861 \n\n\nMagoon, M. A., Critchfield, T. S., Merrill, D., Newland, M. C., & Schneider, W. J. (2017). Are positive and negative reinforcement “different”? Insights from a free-operant differential outcomes effect. Journal of the Experimental Analysis of Behavior, 107(1), 39–64. https://doi.org/10.1002/jeab.243 \n\n\nSchneider, W. J., & Kaufman, A. S. (2017). Let’s not do away with comprehensive cognitive assessments just yet. Archives of Clinical Neuropsychology, 32(1), 8–20. https://doi.org/10.1093/arclin/acw104 \n\n\nFlanagan, D. P., & Schneider, W. J. (2016). Cross-Battery Assessment? XBA PSW? A case of mistaken identity: A commentary on Kranzler and colleagues’ “Classification agreement analysis of Cross-Battery Assessment in the identification of specific learning disorders in children and youth”. International Journal of School & Educational Psychology, 4(3), 137–145. https://doi.org/10.1080/21683603.2016.1192852 \n\n\nGadke, D. L., Tobin, R. M., & Schneider, W. J. (2016). Agreeableness, conflict resolution tactics, and school behavior in second graders. Journal of Individual Differences, 37, 145–151. https://doi.org/10.1027/1614-0001/a000199 \n\n\nSchneider, W. J., & Kaufman, A. S. (2016). Commentary on current practices and future directions for the assessment of child and adolescent intelligence in schools around the world. International Journal of School & Educational Psychology, 4(4), 283–288. https://doi.org/10.1080/21683603.2016.1206383 \n\n\nSchneider, W. J., Mayer, J. D., & Newman, D. A. (2016). Integrating hot and cool intelligences: Thinking broadly about broad abilities. Journal of Intelligence, 4(1), 1:1–25. https://doi.org/10.3390/jintelligence4010001\n\n\nSchneider, W. J., & Newman, D. A. (2015). Intelligence is multidimensional: Theoretical review and implications of specific cognitive abilities. Human Resource Management Review, 25(1), 12–27. https://doi.org/10.1016/j.hrmr.2014.09.004 \n\n\nAbney, D. H., Wagman, J. B., & Schneider, W. J. (2014). Changing grasp position on a wielded object provides self-training for the perception of length. Attention, Perception, & Psychophysics, 76(1), 247–254. https://doi.org/10.3758/s13414-013-0550-x \n\n\nPornprasertmanit, S., & Schneider, W. J. (2014). Accuracy in parameter estimation in cluster randomized designs. Psychological Methods, 19(3), 356–379. https://doi.org/10.1037/a0037036 \n\n\nHerbstrith, J. C., Tobin, R. M., Hesson-McInnis, M. S., & Schneider, W. J. (2013). Preservice teacher attitudes toward gay and lesbian parents. School Psychology Quarterly, 28(3), 183–194. https://doi.org/10.1037/spq0000022 \n\n\nKahn, J. H., & Schneider, W. J. (2013). It’s the destination and it’s the journey: Using multilevel modeling to assess patterns of change in psychotherapy. Journal of Clinical Psychology, 69(6), 543–570. https://doi.org/10.1002/jclp.21964\n\n\nSchneider, W. J. (2013). What if we took our models seriously? Estimating latent scores in individuals. Journal of Psychoeducational Assessment, 31(2), 186–201. https://doi.org/10.1177/0734282913478046 \n\n\nDecker, S. L., Schneider, W. J., & Hale, J. B. (2012). Estimating base rates of impairment in neuropsychological test batteries: A comparison of quantitative models. Archives of Clinical Neuropsychology, 7(1), 69–84. https://doi.org/10.1093/arclin/acr088 \n\n\nJones, G., & Schneider, W. J. (2010). IQ in the production function: Evidence from immigrant earnings. Economic Inquiry, 48(3), 743–755. https://doi.org/10.1111/j.1465-7295.2008.00206.x \n\n\nGuidry, J. A., Babin, B. J., Graziano, W. G., & Schneider, W. J. (2009). Pride and prejudice in the evaluation of wine? International Journal of Wine Business Research, 21(4), 298–311. https://doi.org/10.1108/17511060911004888 \n\n\nHoff, K. E., Reese-Weber, M., Schneider, W. J., & Stagg, J. W. (2009). The association between high status positions and aggressive behavior in early adolescence. Journal of School Psychology, 47(6), 395–426. https://doi.org/10.1016/j.jsp.2009.07.003 \n\n\nBarr, L. K., Kahn, J. H., & Schneider, W. J. (2008). Individual differences in emotion expression: Hierarchical structure and relations with psychological distress. Journal of Social and Clinical Psychology, 27(10), 1045–1077. https://doi.org/10.1521/jscp.2008.27.10.1045 \n\n\nKahn, J. H., Vogel, D. L., Schneider, W. J., Barr, L. K., & Herrell, K. (2008). The emotional content of client disclosures and session impact: An analogue study. Psychotherapy: Theory, Research, Practice, Training, 45(4), 539–545. https://doi.org/10.1037/a0014337 \n\n\nSchneider, W. J. (2008). Playing statistical Ouija board with commonality analysis: good questions, wrong assumptions. Applied Neuropsychology, 15(1), 44–53. https://doi.org/10.1080/09084280801917566 \n\n\nJones, G., & Schneider, W. J. (2006). Intelligence, human capital, and economic growth: A Bayesian Averaging of Classical Estimates (BACE) approach. Journal of Economic Growth, 11(1), 71–93. https://doi.org/10.2139/ssrn.552481 \n\n\nSchneider, W. J., Timothy Cavell, A., & Hughes, J. N. (2003). A sense of containment: Potential moderator of the relation between parenting practices and children’s externalizing behaviors. Development and Psychopathology, 15(1), 95–117. https://doi.org/10.1017/S0954579403000063"
  },
  {
    "objectID": "vita.html#chapters",
    "href": "vita.html#chapters",
    "title": "Curriculum Vitae",
    "section": "Chapters",
    "text": "Chapters\n\nSchneider, W. J. (2022). Statistical and clinical interpretation guidelines for school neuropsychological assessment. In D. Miller, D. Maricle, C. Bedford, & J. Gettman (Eds.) Best Practices in School Neuropsychology: Guidelines for Effective Practice, Assessment, and Evidence‐Based Intervention (1st ed., pp. 163–184). Wiley. https://doi.org/10.1002/9781119790563\n\n\nFloyd, R. G., Farmer, R. L., Schneider, W. J., & McGrew, K. S. (2021). Theories and measurement of intelligence. In L. Glidden, L. Abbeduto, L. L. McIntyre, & M. J. Tassé (Eds.) APA handbook of intellectual and developmental disabilities (Vol. 1, pp. 386–424). American Psychological Association. https://doi.org/10.1037/0000194-015 \n\n\nKaufman, A. S., Schneider, W. J., & Kaufman, J. C. (2019). Psychometric approaches to intelligence. In R. J. Sternberg (Ed.) Human intelligence: An introduction (pp. 67–103). Cambridge University Press. \n\n\nSchneider, W. J., & McGrew, K. S. (2018). The Cattell-Horn-Carroll theory of cognitive abilities. In D. P. Flanagan, & E. M. McDonough (Eds.) Contemporary intellectual assessment: Theories, tests, and issues (4th ed., pp. 73–130). Guilford Press. \n\n\nSchneider, W. J. (2016). Case 1—Liam, age 9: Emotionally intelligent testing with the WISC-V and CHC theory. In A. S. Kaufman, S. Raiford, & D. Coalson (Eds.) Intelligent testing with the WISC-V (pp. 265–282). Wiley.\n\n\nSchneider, W. J. (2016). Strengths and weaknesses of the Woodcock-Johnson IV Tests of Cognitive Abilities: Best practice from a scientist-practitioner perspective. In D. P. Flanagan, & V. C. Alfonso (Eds.) WJ IV Clinical Use and Interpretation (pp. 191–210). Academic Press. https://doi.org/10.1016/B978-0-12-802076-0.00007-4 \n\n\nSchneider, W. J., & Flanagan, D. P. (2015). The relationship between theories of intelligence and intelligence tests. In S. Goldstein, D. Princiotta, & J. A. Naglieri (Eds.) Handbook of intelligence: Evolutionary theory, historical perspective, and current concepts (pp. 317–340). Springer. \n\n\nTobin, R. M., Schneider, W. J., & Landau, S. (2014). Best practices in the assessment of youth with attention deficit hyperactivity disorder within a multitiered services framework. In A. Thomas, & P. Harrison (Eds.) Best practices in school psychology: Data-based and collaborative decision making (pp. 391–404). National Association of School Psychologists. \n\n\nSchneider, W. J. (2013). Principles of assessment of aptitude and achievement. In D. Saklofske, C. Reynolds, & V. Schwean (Eds.) The Oxford Handbook of Child Psychological Assessment (pp. 286–330). Oxford University Press. \n\n\nSchneider, W. J., & McGrew, K. S. (2013). Cognitive performance models: Individual differences in the ability to process information. In B. Irby, G. Brown, R. Laro-Alecio, & S. Jackson (Eds.) Handbook of educational theories (pp. 767–782). Information Age Publishing. \n\n\nSchneider, W. J., & McGrew, K. S. (2012). The Cattell-Horn-Carroll model of intelligence. In D. P. Flanagan, & P. L. Harrison (Eds.) Contemporary intellectual assessment: Theories, tests, and issues (3rd ed., pp. 99–144). Guilford Press. \n\n\nTobin, R. M., Schneider, W. J., Reck, S. G., & Landau, S. (2008). Best practices in the assessment of children with attention deficit hyperactivity disorder: Linking assessment to response to intervention. In P. Harrison, & A. Thomas (Eds.) Best Practices in School Psychology V (Vol. 2, pp. 617–631). National Association of School Psychologists. \n\n\nSnyder, D. K., Schneider, W. J., & Castellani, A. M. (2003). Tailoring couple therapy to individual differences: A conceptual approach. In D. K. Snyder (Ed.) Treating difficult couples: Helping clients with coexisting mental and relationship disorders (pp. 27–51). Guilford Press. \n\n\nSnyder, D. K., & Schneider, W. J. (2002). Affective reconstruction: A pluralistic, developmental approach. In N. S. Jacobson (Ed.) Clinical handbook of couple therapy (3rd ed., pp. 151–179). Guilford Press."
  },
  {
    "objectID": "vita.html#test-reviews",
    "href": "vita.html#test-reviews",
    "title": "Curriculum Vitae",
    "section": "Test Reviews",
    "text": "Test Reviews\n\nSwerdlik, M. E., & Schneider, W. J. (2010). Review of the PsychProfiler. In R. A. Spies, J. F. Carlson, B. S. Plake, & K. T. Geisinger (Eds.) The eighteenth mental measurements yearbook. Buros Institute.\n\n\nSchneider, W. J. (2007). Review of the Dean-Woodcock Neuropsychological Battery. In K. T. Geisinger, R. A. Spies, J. F. Carlson, & B. S. Plake (Eds.) The seventeenth mental measurements yearbook. Buros Institute.\n\n\nSchneider, W. J. (2007). Review of the Multiple Intelligence Developmental Assessment Scales (MIDAS). In K. T. Geisinger, R. A. Spies, J. F. Carlson, & B. S. Plake (Eds.) The seventeenth mental measurements yearbook. Buros Institute.\n\n\nSchneider, W. J., & Swerdlik, M. E. (2007). Review of the Youth Outcome Questionnaire 30.1. In K. T. Geisinger, R. A. Spies, J. F. Carlson, & B. S. Plake (Eds.) The seventeenth mental measurements yearbook. Buros Institute.\n\n\nSwerdlik, M. E., & Schneider, W. J. (2007). Review of the Behavior Evaluation Scale, Third Edition. In K. T. Geisinger, R. A. Spies, J. F. Carlson, & B. S. Plake (Eds.) The seventeenth mental measurements yearbook. Buros Institute.\n\n\nHoff, K. E., & Schneider, W. J. (2005). Review of the Child Symptom Inventory-4. In B. S. Plake, J. C. Impara, & R. A. Spies (Eds.) The sixteenth mental measurements yearbook. Buros Institute.\n\n\nSchneider, W. J., & Hoff, K. E. (2005). Review of the Word Identification and Spelling Test. In B. S. Plake, J. C. Impara, & R. A. Spies (Eds.) The sixteenth mental measurements yearbook. Buros Institute.\n\n\nSchneider, W. J., & Swerdlik, M. E. (2005). Review of the Memory Test for Older Adults. In B. S. Plake, J. C. Impara, & R. A. Spies (Eds.) The sixteenth mental measurements yearbook. Buros Institute.\n\n\nSwerdlik, M. E., & Schneider, W. J. (2005). Review of the Behavioral and Emotional Rating Scale-Second Edition. In B. S. Plake, J. C. Impara, & R. A. Spies (Eds.) The sixteenth mental measurements yearbook. Buros Institute."
  },
  {
    "objectID": "vita.html#scholarly-reports",
    "href": "vita.html#scholarly-reports",
    "title": "Curriculum Vitae",
    "section": "Scholarly Reports",
    "text": "Scholarly Reports\n\nGoldrick-Rab, S., Richardson, J., Schneider, W. J., Hernandez, A., & Cady, C. (2018). Still hungry and homeless in college. The Wisconsin HOPE Lab. \n\n\nSchneider, W. J. (2016). The RESCA-E subtests are thoughtfully designed and highly refined measures of CHC constructs: A review of the Receptive, Expressive & Social Communication Assessment–Elementary. Assessing Psyche, Engaging Gauss, Seeking Sophia.\n\n\nSchneider, W. J. (2016). Why are WJ IV cluster scores more extreme than the average of their parts? A gentle explanation of the composite score extremity effect. Houghton Mifflin HarcourtWoodcock-Johnson IV Assessment Service Bulletin.\n\n\nSchneider, W. J., & McGrew, K. (2011). “Just say no” to averaging IQ subtest scores. IAP Applied Psychometrics 101 Report."
  },
  {
    "objectID": "vita.html#software",
    "href": "vita.html#software",
    "title": "Curriculum Vitae",
    "section": "Software",
    "text": "Software\n\nSchneider, W. J. (2022). condppv: Conditional positive predictive value in the accuracy of specific learning disability identification. [Software] AssessingPsyche. Retrieved from https://github.com/wjschne/conditionalppv\n\n\nSchneider, W. J. (2021). Area under the normal curve. [Software] AssessingPsyche. Retrieved from https://github.com/wjschne/AreaUnderNormalCurve\n\n\nSchneider, W. J. (2021). psycheval: A psychological evaluation toolkit. [Software] AssessingPsyche.\n\n\nSchneider, W. J. (2021). Simple regression with standard scores. [Software] AssessingPsyche. Retrieved from https://github.com/wjschne/simple_regression\n\n\nSchneider, W. J. (2021). ztestvis: A Jamovi module for conducting a one-sample z-test. [Software] AssessingPsyche. Retrieved from https://github.com/wjschne/ztest\n\n\nSchneider, W. J., & Ji, F. (2021). unusualprofile. [Software] AssessingPsyche. Retrieved from https://cran.r-project.org/package=unusualprofile\n\n\nSchneider, W. J. (2018). ggnormalviolin. [Software] AssessingPsyche. Retrieved from https://cran.r-project.org/package=ggnormalviolin\n\n\nSchneider, W. J. (2018). simstandard. [Software] AssessingPsyche. Retrieved from https://cran.r-project.org/package=simstandard\n\n\nSchneider, W. J. (2012). TableMaker. [Software] AssessingPsyche.\n\n\nSchneider, W. J. (2010). The Compositator 1.0.. [Software] WMF Press."
  },
  {
    "objectID": "vita.html#lectures",
    "href": "vita.html#lectures",
    "title": "Curriculum Vitae",
    "section": "Lectures",
    "text": "Lectures\n\nSchneider, W. J. (2023, March 24). Assessments that restore hope, promote understanding and inspire change. [Invited Lecture]. 42nd Annual School Psychology, Counseling Psychology and Applied Behavior Analysis Conference, Philadelphia, PA. https://education.temple.edu/node/50031\n\n\nSchneider, W. J. (2022, November 15). Using imaginary data to conserve real resources: Study design planning with model-based simulations. [Lecture]. Pearson 4th Developers Conversation, NA.\n\n\nFlanagan, D. P., Koponen, T., Wagner, R. K., Colvin, M. K., & Schneider, W. J. D. (2022, November 4). How do we diagnose learning disabilities? [Virtual Summit]. Learning Disabilities Summit: A Three-Part Virtual Event Focused on Crticial Learning Disability Issues, Learning Disabilities Association of America. https://ldaamerica.org/lda-to-hold-learning-disabilities-summit/\n\n\nSchneider, W. J. (2022, July 27). What is the current state of affairs of IQ testing? [Keynote Address]. 2022 Knowledge, Innovation & Enterprise (KIE) Conference: Unpacking Creativity: Culture, Innovation, and Motivation in Global Contexts, NA.\n\n\nSchneider, W. J. (2022, March 29). How measurement error affects learning disability identification accuracy. [Lecture]. Pearson Scientific Advisory Council, NA.\n\n\nSchneider, W. J. (2022, March 28). Practical psychometrics: Robust interpretation for individuals. [Lecture]. Temple University School Psychology Owl Hour, Philadelphia, PA.\n\n\nSchneider, W. J. (2022, January 27). Life-and-death psychometrics: IQ and the death penalty. [Webinar]. Owl Hour, Temple University. https://events.temple.edu/owl-hour-life-and-death-psychometrics-iq-and-the-death-penalty\n\n\nHajovsky, D. B., & Schneider, W. J. (2021, September 24). Cognitive assessment in the evaluation of specific learning disabilities. [Webinar]. Missouri Association of School Psychologists 2021 Fall Conference, Weldon Spring, MO. https://maosp.wildapricot.org/resources/Documents/Fall%20Conference.pdf\n\n\nSchneider, W. J. (2021, July 29). Advances in test interpretation with the Cattell-Horn-Carroll Theory of Cognitive Abilities. [Webinar]. Training for Region 19 Evaluation Staff, Education Service Center, Region 19, El Paso, TX. https://wjschne.github.io/media/CHCTheoryWebinar.pdf\n\n\nSchneider, W. J. (2021, June 14). Using CHC theory to better understand student needs. [Webinar]. Hill Country Summer Institute, NA. https://esc13.net/events/hill-country-summer-institute-2021\n\n\nSchneider, W. J. (2021, February 5). The accuracy of PSW methods. In J. R. Engler (Chair), PSW for SLD identification: Does cognition matter? [Symposium]. National Association of School Psychologists Annual Convention, Salt Lake City, UT. https://apps.nasponline.org/professional-development/convention/session-detail.aspx?id=20263\n\n\nSchneider, W. J. (2021, January 22). Improving LD identification with fewer myths and more science. [Invited Lecture]. Science to Practice Virtual Conference, Learning Disability Association of America.\n\n\nSchneider, W. J. (2020, July 29). Curious about CHC Theory? Take your evaluations to the next level! [Webinar]. Riverside Insights, Rolling Meadows, IL. https://info.riversideinsights.com/chc-theory-webinar\n\n\nSchneider, W. J. (2019, April 3). The evolution of PSW methods of SLD identification: What I have learned from PSW proponents. [Keynote Address]. Annual School Neuropsychology Conference, Long Beach, CA.\n\n\nSchneider, W. J. (2019, April 1). The evolution of PSW methods of SLD identification: What I have learned from PSW critics. [Keynote Address]. Annual School Neuropsychology Conference, Long Beach, CA.\n\n\nFlanagan, D. P., Schneider, W. J., & Alfonso, V. C. (2019, February 26). PSW methods: Comparisons, research, and how to use them responsibly. [Mini-Skills Symposium]. National Association of School Psychologists Annual Convention, Atlanta, GA.\n\n\nSchneider, W. J. (2019, February 26). Consumer-oriented and legally defensible psychoeducational reports–Advanced workshop. [Invited Workshop]. National Association of School Psychologists Conference, Atlanta, GA.\n\n\nSchneider, W. J. (2019, February 26). Consumer-oriented and legally defensible psychoeducational reports–Introductory workshop. [Invited Workshop]. National Association of School Psychologists Conference, Atlanta, GA.\n\n\nSchneider, W. J. (2018, February 16). Re-evaluating the accuracy of the Dual Discrepancy/Consistency Model for SLD Identification. [Lecture]. National Association of School Psychologists Annual Convention, Chicago, IL.\n\n\nMcGrew, K. S., & Schneider, W. J. (2018, February 15). Revisions to the Cattell-Horn-Carroll (CHC) Theory of Intelligence. [Lecture]. National Association of School Psychologists Annual Convention, Chicago, IL.\n\n\nSchneider, W. J. (2016, October 24). How to write psychoeducational reports that people will want to read all the way through. [Webinar]. KIPP Austin Public Schools and Texas State University School Psychology Program, NA.\n\n\nMcGrew, K. S., & Schneider, W. J. (2016, October 19). Porque as habilidades cognitivas importam na educação [Why cognitive abilities matter in education]. [Invited Lecture]. Instituto Ayrton Senna, São Paulo, Brazil.\n\n\nSchneider, W. J., & McGrew, K. S. (2016, October 18). CHC theory, complex problem solving, critical thinking, and creativity. [Invited Lecture]. Instituto Ayrton Senna, São Paulo, Brazil.\n\n\nMcGrew, K. S., & Schneider, W. J. (2016, October 17). CHC theory and education in Brazil. [Invited Lecture]. Instituto Ayrton Senna, São Paulo, Brazil.\n\n\nSchneider, W. J. (2016, August 4). Writing reports worth reading all the way through. In R. Flanagan (Chair), Sophisticated simplicity: The art of writing reader-friendly assessment reports [Symposium]. Annual American Psychological Association Convention, Denver, CO.\n\n\nSchneider, W. J. (2016, July 29). How to write psychoeducational reports that people will want to read all the way through. [Webinar]. New Brunswick Department of Education and Early Childhood Development, Fredericton, NB.\n\n\nSchneider, W. J. (2016, April 12). How to write psychoeducational reports that people will want to read. [Webinar]. Region 10 Education Service Center, Richardson, TX.\n\n\nCormier, D. C., Bulut, O., Niileksela, C. J., Funamoto, A., & Schneider, W. J. D. (2016, February 12). Revisiting the relationship between CHC abilities and academic achievement. [Symposium]. National Association of School Psychologists Annual Convention, New Orleans, LA.\n\n\nSchneider, W. J. (2015, July 15). I didn’t know the WJ IV could do that! Answering practical assessment questions you didn’t know you could ask. [Invited Lecture]. School Neuropsychology Summer Institute, Grapevine, TX.\n\n\nSchneider, W. J. (2014, February 15). What if we took our models seriously? Estimating latent scores in individuals. [Lecture]. National Association of School Psychologists Convention, Washington, D.C..\n\n\nSchneider, W. J. (2013, July 15). Advances in CHC Theory and its application to individuals. [Invited Lecture]. School Neuropsychology Summer Institute, Grapevine, TX.\n\n\nSchneider, W. J. (2013, February 13). Holes in CHC Theory. [Lecture]. National Association of School Psychologists Conference, Seattle, WA.\n\n\nSchneider, W. J., & Taylor, S. J. (2008, October 1). Can the Implicit Association Test be used as a lie detector? Morality, implicit attitudes, and Big Brother’s help measuring illegal file-sharing behavior. [Invited Lecture]. Center for Study of Public Choice at George Mason University, Fairfax, VA.\n\n\nSchneider, W. J. (2006, November 15). We need to change (but I won’t do anything because I’m not the problem): Couples therapy outcomes and the transtheoretical model of change. [Invited Lecture]. Colloquium at Purdue Unversity, West Lafayette, IN.\n\n\nSchneider, W. J., & Huber, B. (2004, March 15). The interactive effects of fluid intelligence and executive functions on behavior disorders in children. [Lecture]. Annual Meeting of the Illinois School Psychology Association, Springfield, IL."
  },
  {
    "objectID": "vita.html#posters-and-papers",
    "href": "vita.html#posters-and-papers",
    "title": "Curriculum Vitae",
    "section": "Posters and Papers",
    "text": "Posters and Papers\n\nHajovsky, D. B., Niileksela, C. R., Flanagan, D. P., Alfonso, V. C., Schneider, W. J., & Zinkiewicz, C. J. (2022, August 4). Toward a Consensus Model of Cognitive-Achievement Relations Using Meta-SEM [Poster]. American Psychological Association Convention, Minneapolis, MN.\n\n\nSchneider, W. J., Flanagan, D. P., Niileksela, C. J., & Engler, J. R. (2020, February 20). Reevaluating the accuracy of PSW methods of SLD identification [Poster]. National Association of School Psychologists Convention, Baltimore, MD.\n\n\nSchneider, W. J., & Fiorello, C. A. (2019, August 8). Broad abilities are not doomed to be measured unreliably: A Monte Carlo study of omega statistics [Poster]. American Psychological Association Convention, Chicago, IL. https://github.com/wjschne/APA2019\n\n\nMulderink, T. D., Tobin, R. M., & Schneider, W. J. (2018, August 10). Personality, interactive history, and situational factors during children’s games [Poster]. Annual American Psychological Association Convention, San Francisco, CA.\n\n\nHowe, A. R., Curnock, A. D., Koppenhoefer, S. E., Schneider, W. J., & Tobin, R. M. (2016, August 4). Do vocabulary skills and instructor influence social-emotional learning? [Poster]. Annual American Psychological Association Convention, Denver, CO.\n\n\nNicholls, C. J., Ross, E., & Schneider, W. J. (2016, April 15). The neuropsychological profiles of twins discordant for Sotos Syndrome: A case study [NA]. American Academy of Pediatric Neuropsychology Annual Conference, Las Vegas, NV.\n\n\nCurnock, A. D., Pajor, K. E., Tobin, R. M., & Schneider, W. J. (2016, February 12). Preschoolers’ engagement during Second Step and their social-emotional knowledge [Poster]. National Association of School Psychologists Annual Convention, New Orleans, LA.\n\n\nEngelland, J. L., Tobin, R. M., Meyers, A., Huber, B., Schneider, W. J., Austen, J. H., & Corbin, A. L. (2014, August 12). Longitudinal effects of school climate on middle school students’ development [Poster]. Annual American Psychological Association Convention, Washington, D.C..\n\n\nAffrunti, C. L., Schneider, W. J., Tobin, R. M., & Collins, K. D. (2014, August 7). Predictors of academic outcomes in college students suspected of having learning disorders [Poster]. Annual American Psychological Association Convention, Washington, D.C..\n\n\nSondalle, A. A., Tobin, R. M., & Schneider, W. J. (2014, August 7). Behavioral engagement, Second Step edition, and children’s social-emotional functioning [Poster]. Annual American Psychological Association Convention, Washington, D.C..\n\n\nSondalle, A. A., Probst, K. G., Carreno, C., Tobin, R. M., Schneider, W. J., Moore, N. A., & Mulderink, T. D. (2014, February 15). Engagement during Second Step and kindergarteners’ social-emotional and academic outcomes [Poster]. National Association of School Psychologists Convention, Washington, D.C..\n\n\nSondalle, A. A., Probst, K. G., Tobin, R. M., Schneider, W. J., & Kestian, J. M. (2014, February 15). Second Step and teacher ratings of children’s social-emotional functioning [Poster]. National Association of School Psychologists Conference, Washington, D.C..\n\n\nTobin, R. M., Schneider, W. J., Moore, N. A., Sondalle, A. A., & Willis, M. (2013, August 15). Effortful control and knowledge gains after the Second Step intervention [Poster]. Annual American Psychological Association Convention, Honolulu, HI.\n\n\nMoore, N. A., Sondalle, A. A., Mulderink, T. D., Tobin, R. M., Schneider, W. J., Willis, M., & Probst, K. G. (2013, February 15). Effortful control, Second Step, and behavior in kindergartners [Poster]. National Association of School Psychologists Convention, Seattle, WA.\n\n\nSondalle, A. A., Mulderink, T. D., Moore, N. A., Tobin, R. M., & Schneider, W. J. (2012, August 15). Engagement, dosage, and effectiveness of the kindergarten Second Step curriculum [Poster]. Annual American Psychological Association Convention, Orlando FL.\n\n\nMulderink, T. D., Sondalle, A. A., Moore, N. A., Tobin, R. M., Schneider, W. J., & Sheese, B. E. (2012, February 15). Influences of executive functioning and Second Step on behavior [Poster]. National Association of School Psychologists Conference, Philadelphia, PA.\n\n\nMulderink, T. D., Moore, N. A., Sondalle, A. A., Tobin, R. M., & Schneider, W. J. (2011, August 15). Executive functioning and responsiveness to Second Step [Poster]. Annual American Psychological Association Convention, Washington, D.C..\n\n\nTobin, R. M., Mackin, J. M., Babcock, E. A., Mulderink, T. D., Moore, N. A., Carlson, L. A., Gioia, K. A., & Schneider, W. J. (2011, February 15). Intervention frequency and behavior in response to Second Step [Poster]. National Association of School Psychologists Convention, San Francisco, CA.\n\n\nTobin, R. M., Gioia, K. A., Mulderink, T. D., Carlson, L. A., Moore, N. A., & Schneider, W. J. (2010, August 15). Personality, Second Step dosage, and kindergartners’ social skills improvements [Poster]. Annual American Psychological Association Convention, San Diego CA.\n\n\nMoore, N. A., Gioia, K. A., Tobin, R. M., & Schneider, W. J. (2010, March 1). Effortful control and emotion regulation in kindergartners [Poster]. National Association of School Psychologists Convention, Chicago, IL.\n\n\nObilade, M. H., Gioia, K. A., Tobin, R. M., & Schneider, W. J. (2010, March 1). Verbal ability and responsiveness to the Second Step curriculum [Poster]. National Association of School Psychologists Convention, Chicago, IL.\n\n\nSchneider, W. J., & Tobin, R. M. (2010, March 1). Previously impossible feats of interpretation and explanation with cognitive and achievement data [Poster]. National Association of School Psychologists Conference, Chicago, IL.\n\n\nGioia, K. A., Tobin, R. M., & Schneider, W. J. (2010, January 15). Children’s knowledge gains in response to a social skills intervention [Poster]. Annual Illinois School Psychologist Association Convention, East Peoria, IL.\n\n\nTaylor, S. A., & Schneider, W. J. (2009, October 15). Implicit attitudes in folk explanations of digital piracy [Paper]. Frontiers in Service Conference, Honolulu, HI.\n\n\nBooth, B., Lederer, S., Dick, S., Linnell, J., Meyers, A., Schneider, W. J., Swerdlik, M. E., & Anweiler, J. (2009, August 15). Reintegration experiences of returning National Guard war veterans and implications for reintegration programming: Results from two states [Poster]. Annual American Psychological Association Convention, Toronto, ON.\n\n\nGadke, D. L., Tobin, R. M., & Schneider, W. J. (2009, August 15). Agreeableness and prejudice towards overweight men and women [Poster]. Annual American Psychological Association Convention, Toronto, ON.\n\n\nGioia, K. A., Tobin, R. M., & Schneider, W. J. (2009, August 15). Individual differences in children’s responsiveness to a social skills intervention [Poster]. Annual American Psychological Association Convention, Toronto, ON.\n\n\nGioia, K. A., Miller, K. A., Tobin, R. M., & Schneider, W. J. (2009, February 15). Children’s responsiveness to a social skills intervention [Poster]. National Association of School Psychologists Convention, Boston, MA.\n\n\nBaird, S. A., Schneider, W. J., & Tobin, R. M. (2008, August 15). Implicit agreeableness predicts laboratory measures of aggression [Poster]. Annual American Psychological Association Convention, Boston, MA.\n\n\nBarr, L. K., Kahn, J. H., & Schneider, W. J. (2008, March 15). Emotion expression tendencies and mood/anxiety symptoms [Poster]. International Counseling Psychology Conference, Chicago, IL.\n\n\nTobin, R. M., Schneider, W. J., & Landau, S. E. (2008, February 15). Assessing attention-deficit/hyperactivity disorder using an RTI approach [Poster]. National Association of School Psychologists Convention, New Orleans, LA.\n\n\nStagg, J. W., & Schneider, W. J. (2007, November 15). So you flunked the Stroop Test, so what? The utility of single vs. multiple indicators in predicting behavioral outcomes related to executive functioning among non-referred individuals [Poster]. Annual National Academy of Neuropsychology Conference, Scottsdale, AZ.\n\n\nSchneider, W. J. (2007, August 15). Is the TAT helpful in assessing complex aspects of attention and executive functions? An extremely labor-intensive celebration of the null hypothesis [Poster]. Annual American Psychological Association Convention, San Francisco, CA.\n\n\nSchneider, W. J., & Kasson, D. M. (2007, March 1). Do narrow abilities matter more for people with higher IQ? Implications of Spearman’s Law of Diminishing Returns for the discrepancy model of LD [Poster]. National Association of School Psychologists Convention, New York, NY.\n\n\nSchneider, W. J., & McKenna, T. L. (2006, August 15). Using the Implicit Association Test to measure early maladaptive schemas [Poster]. Annual American Psychological Association Convention, New Orleans, LA.\n\n\nKahn, J. H., Vogel, D. L., Schneider, W. J., Barr, L. K., & Henning, K. (2006, April 15). Emotional self-disclosures of college-student clients and counseling session outcome [Poster]. Great Lakes Conference, West Lafayette, IN.\n\n\nJones, G. B., & Schneider, W. J. (2005, August 15). Intelligence, human capital, and economic growth [Paper]. Econometric Society World Congress, London, UK.\n\n\nTobin, R. M., Bodner, A. C., & Schneider, W. J. (2005, August 15). Executive function and emotion regulation in children [Poster]. Annual American Psychological Association Convention, Washington, D.C..\n\n\nMarch, A., Funk, K., Schneider, W. J., & Landau, S. E. (2005, March 1). Student and teacher attributions of school shootings [Poster]. National Association of School Psychologists Convention, Atlanta, GA.\n\n\nTobin, R. M., Schneider, W. J., Graziano, W. G., & Pizzitola, K. M. (2002, February 15). Nice kids in competitive situations [Poster]. Annual Society for Personality and Social Psychology Meeting, Savannah, GA.\n\n\nSnyder, D. K., Schneider, W. J., Oxford, M. C., & Quinn, T. (2001, July 15). Secondary prevention group intervention for couples [Paper]. World Congress of Behavioral and Cognitive Therapies, Vancouver, BC.\n\n\nTobin, R. M., Pizzitola, K. M., Schneider, W. J., & Graziano, W. G. (2001, April 15). Goal structures and competitiveness in children’s games [Poster]. Biennial Meeting of the Society for Research in Child Development, Minneapolis, MN.\n\n\nSchneider, W. J., Loss, R. M., Cavell, T. A., & Oxford, M. C. (2000, November 15). Parenting and children with callous-unemotional traits: Relationship quality as a potential socialization mechanism [Poster]. Annual Convention of the Association for the Advancement Behavior Therapy, New Orleans, LA.\n\n\nSnyder, D. K., Schneider, W. J., Oxford, M. C., & Quinn, T. (2000, November 15). SUCCESS: The efficacy of a relationship enhancement group [Poster]. Annual Convention of the Association for the Advancement Behavior Therapy, New Orleans, LA.\n\n\nSchneider, W. J., Cavell, T. A., Hughes, J. N., & Oxford, M. C. (1999, August 15). The development of the Perceived Containment Questionnaire [Poster]. Annual American Psychological Association Convention, Boston, MA."
  },
  {
    "objectID": "vita.html#courses",
    "href": "vita.html#courses",
    "title": "Curriculum Vitae",
    "section": "Courses",
    "text": "Courses\n\nTemple University\n\nCPSY 5519—Group Counseling (Spring 2018–2019)\nCPSY 5694—Introduction to Assessment (Fall 2017–2019)\nEDUC 5101—Critical Understanding of Social Science Research (Fall 2018)\nEDUC 5325—Introduction to Statistics and Research (Fall 2017, 2021)\nEPSY 5529—Tests and Measurements (Spring 2019–2020, 2022)\nEPSY 8825—Advanced Data Analysis (Spring 2020, 2022)\nSPSY 9687/8—Seminar in School Psychology/Psychoeducational Clinic (Fall 2019, Spring 2020–2021)\n\n\n\nIllinois State University\n\nPSY 110—Explaining Human Behavior/Fundamentals of Psychology (Fall 2002–2006, Spring 2003–2004, 2006–2007)\nPSY 138—Social Science Reasoning Using Statistics/Reasoning in Psychology Using Statistics (Spring 2004, 2008–2012, 2014; Fall 2007–2014, 2016)\nPSY 340—Statistics for the Social Sciences (Spring 2005)\nPSY 432—Psychodiagnostics I: Cognitive Assessment/ Theory and Practice of Cognitive Assessment (Fall 2004–2016)\nPSY 436—Clinical/Counseling Practicum (Spring 2004)\nPSY 442—Test Theory (Spring 2015, 2017)\nPSY 443—Regression Analysis (Spring 2016)\nPSY 444—Multivariate Analysis (Fall 2015){.smalldate}\nPSY 464—Theories and Techniques of Counseling: Adults (Spring 2005–2012, 2014–2016)\nPSY 480—Advanced Practicum in Dialectical Behavior Therapy Skills (Fall 2015–2017)\nPSY 480.31—Practicum in Dialectical Behavior Therapy Skills Training (Fall 2014, Spring 2105–2017)\nPSY 480.33—Seminar in Psychology: Supervision of a Dialectical Behavior Therapy Group (Fall 2014, Spring 2105, 2017)"
  },
  {
    "objectID": "vita.html#mentoring",
    "href": "vita.html#mentoring",
    "title": "Curriculum Vitae",
    "section": "Mentoring",
    "text": "Mentoring\n\nDoctoral Dissertation Chair\n\nTemple University\n\nMegan Barone\nTiffany Thompson\nRandy Taylor\nBernard Dillard\nStephanie Iaccarino (co-chair)\nJustin Harper (2022)\n\n\n\nIllinois State University\n\nC. Lee Affrunti (2013)\nDaniel L. Gadke (co-chair, 2012)\nJonathan W. Stagg (2008)\n\n\n\n\nDoctoral Dissertation Committee Member\n\nTemple University\n\nValerie Woxholt\nEmunah Mager-Garfield\nDenae Sisco\nCodie Kane (2023)\nPatrick Clancy (2023)\nShana Levi-Nielsen (2022)\nKaiyla Darmer (2022)\nKathryn DeVries (2022)\nTera Gibbs (2022)\nMariah Davis (2022)\nLinda Ruan (2020)\n\n\n\nIllinois State University\n\nJennifer Engelland-Schultz (2015)\nMandi Martinez-Dick (2015)\nThomas Mulderink (2015)\nAlyssa A. Sondalle (2015)\nRachelle Cantin (2013)\nJennifer Wallace (2013)\nSilas Dick (2013)\nTrisha Mann (2012)\nKatherine A. Gioia (2009)\nSarah Reck (2008)\nAnna C. Bodner (2005)\n\n\n\nExternal Reviewer\n\nBrianna Paul (2022) Texas Women’s University\nJake Blair Kraska (2021) Monash University\nPaul Jewsbury (2014) University of Melbourne\n\n\n\n\nMaster’s Thesis Chair\n\nIllinois State University\n\nFeng Ji (2018)\nKatrin Klieme (2016)\nZachary Roman (2016)\nKiera Dymit (2015)\nMeera Afzal (2012)\nRachelle Bauer (2010)\nSunthud Pornprasertmanit (2010)\nDavid Kasson (2006)\nKristina Taylor (2006)\nRobin Van Herrmann (2010)\nMelissa Zygmun (2006)\n\n\n\n\nMaster’s Thesis Committee Member\n\nIllinois State University\n\nRyan Willard (2017)\nRachel Workman (2017)\nHayley Love (2016)\nAnges Strojewska (2016)\nDanielle Freund (2015)\nAmanda Fisher (2015)\nDaniel Nuccio (2014)\nKevin Wallpe (2014)\nNicole Moore (2013)\nDrew Abney (2012)\nThomas Mulderink (2012)\nJames Clinton (2011)\nJamie Hansen (2010)\nYin Ying Ong (2010)\nMelanie Hewett (2010)\nKaty Adler (2008)\nPoonam Joshi (2008)\nRebecca Hoerr (2008)\nArusha Sethi (2008)\nLeah Barr (2008)\nSara Byczek (2007)"
  },
  {
    "objectID": "vita.html#university-service",
    "href": "vita.html#university-service",
    "title": "Curriculum Vitae",
    "section": "University Service",
    "text": "University Service\n\nIllinois State University\n\n\n\n\n\n\n2007–2017\n\n\nCoordinator and Supervisor, College Learning Assessment Service (CLAS), Psychological Services Center"
  },
  {
    "objectID": "vita.html#college-service",
    "href": "vita.html#college-service",
    "title": "Curriculum Vitae",
    "section": "College Service",
    "text": "College Service\n\nTemple University\n\n\n\n\n\n\n2019–\n\n\nCo-Chair, Data and Assessment Working Group\n\n\n\n\n2020\n\n\nMember, Higher Education Non-Tenure-Track Faculty Search Committee\n\n\n\n\n2019–2021\n\n\nChair, Faculty Merit Committee\n\n\n\n\n2019\n\n\nMember, Higher Education Tenure-Track Faculty Search Committee\n\n\n\n\n2019\n\n\nTraining presenter: Make Your Data POP! How to interpret and present data visually to maximize its impact\n\n\n\n\n2018–2019\n\n\nMember, Faculty Resource and Development Committee\n\n\n\n\n2018\n\n\nMember, Special Education Faculty Search committee\n\n\n\n\n2018\n\n\nTraining presenter: Introduction to Statistical Analysis with R Workshop"
  },
  {
    "objectID": "vita.html#departmental-service",
    "href": "vita.html#departmental-service",
    "title": "Curriculum Vitae",
    "section": "Departmental Service",
    "text": "Departmental Service\n\nTemple University\n\n\n\n\n\n\n2018–\n\n\nMember, School Psychology Program Committee\n\n\n\n\n2017–\n\n\nMember, Counseling Psychology Program Committee\n\n\n\n\n2018–2020\n\n\nMember, Departmental Promotion and Tenure Committee\n\n\n\n\n\n\nIllinois State University\n\n\n\n\n\n\n2004–2017\n\n\nMember, Clinical/Counseling Psychology Coordinating committee\n\n\n\n\n2004–2017\n\n\nMember, IRB Committee\n\n\n\n\n2004–2017\n\n\nMember, Psychological Services Center Administrative Team\n\n\n\n\n2004–2017\n\n\nMember, Quantitative Psychology Sequence committee\n\n\n\n\n2004–2017\n\n\nMember, Research Committee\n\n\n\n\n2015–2017\n\n\nMember, Department Faculty Status Committee (Evaluates annual merit, tenure, and promotion)\n\n\n\n\n2017\n\n\nChair, Salary Compression Review Team\n\n\n\n\n2015\n\n\nProgram Coordinator, Quantitative Sequence (Fall only)\n\n\n\n\n2014\n\n\nMember, Clinical/Counseling Faculty Search committee\n\n\n\n\n2004–2005\n\n\nMember, Clinical/Counseling Faculty Search committee"
  },
  {
    "objectID": "vita.html#consulting",
    "href": "vita.html#consulting",
    "title": "Curriculum Vitae",
    "section": "Consulting",
    "text": "Consulting\n\n\n\n\n\n\n2019–\n\n\nAcademic Consultant, Empass Learning, developing an online test of cognitive abilities based on CHC Theory, Gurgaon, India\n\n\n\n\n2014–\n\n\nExpert Consultant, providing expert evaluations of death penalty and medical cases for various legal firms, US\n\n\n\n\n2017–2020\n\n\nAcademic Consultant, PT Melintas Cakrawala, developing AJT CogTest?a comprehensive test of cognitive abilities based on CHC Theory, Jakarta, Indonesia\n\n\n\n\n2015–2017\n\n\nAcademic Consultant, Ayrton Senna Institute, developing a comprehensive assessment of 21st century skills, Sao Paulo, Brazil\n\n\n\n\n2016\n\n\nAcademic Consultant, Academic Therapy Publications, developing and reviewing cognitive and oral language assessment batteries, Novato, CA\n\n\n\n\n2007–2010\n\n\nResearch Consultant, Illinois Army National Guard, conducting research examining reintegration of service personnel"
  },
  {
    "objectID": "vita.html#media-appearances",
    "href": "vita.html#media-appearances",
    "title": "Curriculum Vitae",
    "section": "Media Appearances",
    "text": "Media Appearances\n\n\n\n\n\n\n02/03/2014\n\n\nInterviewed in Scientific American Blog Beautiful Minds by Scott Barry Kaufman\n\n\n\n\n08/05/2016\n\n\nQuoted in the Wall Street Journal about IQ tests\n\n\n\n\n10/13/2016\n\n\nQuoted in ScienceNews for Students about IQ tests\n\n\n\n\n10/11/2017\n\n\nOpined in the Guardian about our president?s IQ\n\n\n\n\n04/09/2018\n\n\nAppeared as a guest of Knowledge@Wharton Radio to discuss hunger and homelessness among college students.\n\n\n\n\n04/03/2018\n\n\nAppeared on CNN Headline News (HLN) with MichaeLA to discuss hunger and homelessness among college students.\n\n\n\n\n10/20/2019\n\n\nPresented on Writing Assessment Reports People Will Read, Understand, and Remember on the School Psyched Podcast\n\n\n\n\n03/01/2020\n\n\nQuoted in APA Monitor on writing assessment reports\n\n\n\n\n03/29/2021\n\n\nPresented on the evolution of cognitive assessment on the Testing Psychologist Podcasts"
  },
  {
    "objectID": "vita.html#editorial-positions",
    "href": "vita.html#editorial-positions",
    "title": "Curriculum Vitae",
    "section": "Editorial Positions",
    "text": "Editorial Positions\n\n\n\n\n\n\n\n\n\n\n2019⁠–⁠2020\n*Journal of Psychoeducational Assessment*\nAssociate Editor\n\n\n2015\n*Journal of School Psychology*\nGuest Action Editor"
  },
  {
    "objectID": "vita.html#editorial-boards",
    "href": "vita.html#editorial-boards",
    "title": "Curriculum Vitae",
    "section": "Editorial Boards",
    "text": "Editorial Boards\n\n\n\n\n\n\n\n\n\n\n2018⁠–⁠\n*Journal of Intelligence*\nEditorial Board\n\n\n2011⁠–⁠\n*Journal of School Psychology*\nEditorial Board\n\n\n2010⁠–⁠\n*Journal of Psychoeducational Assessment*\nEditorial Board\n\n\n2017⁠–⁠\n*Archives of Scientific Psychology*\nConsulting Editor\n\n\n2009⁠–⁠2018\n*Psychological Assessment*\nConsulting Editor\n\n\n1997⁠–⁠2000\n*Clinician's Research Digest*\nEditorial Associate"
  },
  {
    "objectID": "vita.html#ad-hoc-reviewing",
    "href": "vita.html#ad-hoc-reviewing",
    "title": "Curriculum Vitae",
    "section": "Ad Hoc Reviewing",
    "text": "Ad Hoc Reviewing\n\nApplied Neuropsychology\nEuropean Journal of Psychological Assessment\nFrontiers in Human Neuroscience\nJournal of Family Psychology\nJournal of Psychoeducational Assessment\nNASP Communiqué\nPsychological Assessment\nPsychology in the Schools"
  },
  {
    "objectID": "vita.html#professional-memberships",
    "href": "vita.html#professional-memberships",
    "title": "Curriculum Vitae",
    "section": "Professional Memberships",
    "text": "Professional Memberships\n\nMember, American Psychological Association\nMember, National Association of School Psychologists"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "A free online book about psychometric tools for psychological assessment\n\nI have been working on a book project off and on since 2012. I have ambitious goals for this book, but it is not nearly complete. The preliminary, unfinished version is here.\n\n\n\n\n\nAn introduction to tests and measurements\nRenée Tobin and I helped update Ronald Cohen’s Psychological Testing and Assessment: An Introduction to Tests and Measurements. It is a comprehensive textbook suitable for introductory psychological assessment courses.\n\n\n\n\n\n\n\n\n\n\n\n\n\nA book about making reader-friendly assessment reports that instill hope and promote change.\nMy co-authors and I worked hard to fill the second edition of Essentials of Assessment Report Writing with non-obvious guidance about how to write reports so that the meet the needs of the reports’ readers."
  },
  {
    "objectID": "projects.html#individual-psychometrics-an-assessment-toolkit-with-applications-in-r",
    "href": "projects.html#individual-psychometrics-an-assessment-toolkit-with-applications-in-r",
    "title": "Projects",
    "section": "",
    "text": "A free online book about psychometric tools for psychological assessment\n\nI have been working on a book project off and on since 2012. I have ambitious goals for this book, but it is not nearly complete. The preliminary, unfinished version is here."
  },
  {
    "objectID": "projects.html#psychological-testing-and-assessment",
    "href": "projects.html#psychological-testing-and-assessment",
    "title": "Projects",
    "section": "",
    "text": "An introduction to tests and measurements\nRenée Tobin and I helped update Ronald Cohen’s Psychological Testing and Assessment: An Introduction to Tests and Measurements. It is a comprehensive textbook suitable for introductory psychological assessment courses."
  },
  {
    "objectID": "projects.html#essentials-of-assessment-report-writing",
    "href": "projects.html#essentials-of-assessment-report-writing",
    "title": "Projects",
    "section": "",
    "text": "A book about making reader-friendly assessment reports that instill hope and promote change.\nMy co-authors and I worked hard to fill the second edition of Essentials of Assessment Report Writing with non-obvious guidance about how to write reports so that the meet the needs of the reports’ readers."
  },
  {
    "objectID": "posts/splitting-sentence-texts-into-roughly-equal-segments/index.html",
    "href": "posts/splitting-sentence-texts-into-roughly-equal-segments/index.html",
    "title": "Splitting sentence texts into roughly equal segments",
    "section": "",
    "text": "When analyzing questionnaire data, I sometimes put the text of several questions on the y-axis of a plot. Longer text strings will usually make the plot too narrow.\nSuppose we give an admittedly silly questionnaire about preference for darker food. We want to display the percentages of people answering “Yes” to each question.\nHere are the questions and the (completely made-up) percentages:\n# To install the WJSmisc package:\n# remotes::install_github(\"wjschne/WJSmisc\")\nlibrary(WJSmisc)\nlibrary(tidyverse)\nd &lt;- tibble(Item = c(\"When you drink coffee, do you prefer darker roasts?\",\n                     \"Is pumpernickel the best bread?\",\n                     \"Do you like dark chocolate more than you like milk chocolate?\",\n                     \"Are black olives better than green olives?\",\n                     \"Do you enjoy the taste of prunes more than can be prudently admitted aloud?\",\n                     \"Is black licorice the secret to a happly life?\"),\n            Percentage = c(45,4,37, 84,2, 3)) |&gt; \n  mutate(Item = fct_reorder(Item, Percentage))\nA preliminary plot might look like this:\nmyfont &lt;- \"Roboto Condensed\"\nmycolors &lt;- viridis::viridis(n = nrow(d), begin = .2, end = .8) |&gt; tinter::lighten(.5)\nmytextsize &lt;- 17\nmytext &lt;- \"gray60\"\np &lt;- ggplot(d, aes(Percentage, Item)) + \n  geom_col(aes(fill = factor(Percentage))) + \n  geom_richlabel(aes(label = paste0(Percentage, \"%\"), \n                     color = factor(Percentage)), \n                 hjust = 0, fill = \"black\",\n                 text_size = mytextsize,\n                 family = myfont) +\n  labs(y = NULL,\n       caption = \"Note: These numbers were made up for illustrative purposes.\") +\n  theme_minimal(base_size = mytextsize, base_family = myfont) +\n  scale_x_continuous(\"Percent Yes\", \n                     limits = c(0,100), \n                     breaks = NULL,\n                     expand = expansion(mult = c(0,.2))) +\n  scale_fill_manual(values = mycolors) +\n  scale_color_manual(values = mycolors) +\n  theme(plot.title.position = \"plot\", \n        plot.background = element_rect(\"black\"),\n        plot.title = element_text(colour = mytext),\n        plot.caption = element_text(color = \"gray40\"),\n        legend.position = \"none\",\n        axis.title = element_text(color = mytext),\n        panel.grid.major.y = element_blank(),\n        axis.text = element_text(color = mycolors))\np + ggtitle(\"Y-axis labels with no text wrapping\")\nThe questions are taking up a lot of space. We can fix this by using stringr::str_wrap to make the text lines no longer than a specified width:\np + \n  scale_y_discrete(labels = \\(x) str_wrap(x, width = 30)) + \n  ggtitle(\"Splitting Y-axis labels with str_wrap\")\nThis is a definite improvement, but I wish the lines of text were wrapped more evenly. For example, I do not like the fact that “chocolate” and “bread” are by themselves on their own lines. I have spent a fair amount of time breaking lines up by hand and hoped to create a function to automate the process. To achieve a more balanced style of text splitting, I made the str_wrap_equal function.\np + scale_y_discrete(labels = \\(x) str_wrap_equal(x, max_width = 30)) + \n  ggtitle(\"Splitting Y-axis labels with str_wrap_equal\")\nTo each their own, but this style of text wrapping feels better to me here. It is the sort of thing no one but the analyst will notice if it is right but will feel a bit off if not.\nFor your convenience and mine, I put the str_wrap_equal function in the WJSmisc package."
  },
  {
    "objectID": "posts/splitting-sentence-texts-into-roughly-equal-segments/index.html#technical-details",
    "href": "posts/splitting-sentence-texts-into-roughly-equal-segments/index.html#technical-details",
    "title": "Splitting sentence texts into roughly equal segments",
    "section": "Technical Details",
    "text": "Technical Details\nI hesitate to post a new function because the odds are quite high that someone has already done what I did. However, my initial search did not locate a function that does exactly what I needed. If you know of a function have I duplicated unnecessarily, let me know.\nIn deciding whether to break the line, the function does the following:\n\nCalculate the overall length of the text (i.e., number of characters).\nFind k (the number of lines likely needed) by dividing the overall text length by max_width and round up to the nearest integers.\nCalculate the preferred width of the line by dividing the overall text length by the number of lines likely needed.\nAdd to the line one word at a time as long as doing so makes the current line width closer to the preferred width. If not, a new line is started.\nThe function will not make a line longer than what is specified by max_width unless it has to place a single, lonely word that is longer than max_width.\n\nHere is the code for the function. Any suggestions to improve it are welcome.\n\nstr_wrap_equal &lt;- function(x, max_width = 30L, sep = \"\\n\") {\n  purrr::map_chr(x, \\(xi) {\n    # Find overall text length\n    xlen &lt;- stringr::str_length(xi)\n    # Remove any line breaks and allow lines to break at forward slashes\n    xi &lt;- stringr::str_replace(xi, \"\\n\", \" \") |&gt; \n      stringr::str_replace(\"/\", \"/ \")\n    # Number of lines likely needed\n    k &lt;- ceiling(xlen / max_width)\n    # Optimal line length\n    preferred_width &lt;- xlen / k\n    # Split text into words\n    words &lt;- stringr::str_split(xi, pattern = \" \", simplify = F)[[1]]\n    # Number of words in text\n    k_words &lt;- length(words)\n    # Length of each word in text\n    word_len &lt;- stringr::str_length(words)\n    # Create empty text lines with a few extra, if needed\n    textlines &lt;- rep(\"\", k + 10)\n    # Current text line\n    i &lt;- 1\n    # Decide whether to add a word to the current line or to start a new line\n    for (w in seq(k_words)) {\n      # Width of current line before adding a new word\n      current_width &lt;- stringr::str_length(textlines[i])\n      # Width of current line if a new word is added\n      proposed_width &lt;- current_width + word_len[w] + 1\n      # Difference between current width and preferred width\n      current_difference &lt;- abs(current_width - preferred_width)\n      # Difference between proposed width and preferred width\n      proposed_difference &lt;- abs(proposed_width - preferred_width)\n      # Should we start a new line?\n      if (current_difference &lt; proposed_difference | proposed_width &gt; max_width) {\n        i &lt;- i + 1\n      }\n      # Add word to current line, remove spaces, and rejoin words divided by forward slashes\n      textlines[i] &lt;- stringr::str_trim(paste(textlines[i], words[w])) |&gt;\n        stringr::str_replace(\"/ \", \"/\")\n    }\n    # Collapse non-empty lines by separation character\n    paste0(textlines[stringr::str_length(textlines) &gt; 0], collapse = sep)\n  })\n\n}"
  },
  {
    "objectID": "posts/making-text-labels-the-same-size-as-axis-labels-in-ggplot2/index.html",
    "href": "posts/making-text-labels-the-same-size-as-axis-labels-in-ggplot2/index.html",
    "title": "Making text labels the same size as axis labels in ggplot2",
    "section": "",
    "text": "As explained in this ggplot2 vignette, the size parameter in geom_text and geom_label is in millimeters, and the size parameter in all other text elements in ggplot2 is in points.\nIf I specify the base_size of the plot and the size of a label to 16, you can see that the text label is much bigger than 16.\n\nlibrary(tidyverse)\ntextsize &lt;- 16\nggplot() +\n  stat_function(\n    fun = dnorm,\n    xlim = c(-4, 4),\n    geom = \"area\",\n    alpha = .3\n  ) +\n  theme_minimal(base_size = textsize) +\n  annotate(\n    geom = \"text\",\n    x = 0,\n    y = 0,\n    label = \"Mean = 0\",\n    size = textsize,\n    vjust = -.1\n  )\n\n\n\n\nIf you do not mind a little trial and error, you can fiddle with the size parameter until you find a value that looks good to you. However, what if we want the axis text labels and the output of geom_text to be exactly the same size?\nWe are in luck because ggplot2 has a .pt constant that will help us convert point sizes to millimeters.\n\nggplot2::.pt\n\n[1] 2.845276\n\n\nWe know that, by default, axis text is .8 times as large as the base_size of the theme.\nLet’s make a function to automate the conversion:\n\nggtext_size &lt;- function(base_size, ratio = 0.8) {\n  ratio * base_size / ggplot2::.pt\n}\n\nNow we can make the label and axis text exactly the same size:\n\nggplot() + \n  stat_function(fun = dnorm, xlim = c(-4,4), geom = \"area\", alpha = .3) +\n  theme_minimal(base_size = textsize) + \n  annotate(\n    geom = \"text\",\n    x = 0,\n    y = 0,\n    label = \"Mean = 0\",\n    size = ggtext_size(textsize),\n    vjust = -.3\n  )\n\n\n\n\nFor my own convenience (and possibly yours), I put the ggtext_size function in the WJSmisc package.\nFor more on ggplot font size matters, I found this post by Christophe Nicault to be informative.\n\n\n\nCitationBibTeX citation:@online{schneider2021,\n  author = {Schneider, W. Joel},\n  title = {Making Text Labels the Same Size as Axis Labels in Ggplot2},\n  date = {2021-08-10},\n  url = {https://wjschne.github.io/posts/making-text-labels-the-same-size-as-axis-labels-in-ggplot2},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSchneider, W. J. (2021, August 10). Making text labels the same size\nas axis labels in ggplot2. https://wjschne.github.io/posts/making-text-labels-the-same-size-as-axis-labels-in-ggplot2"
  },
  {
    "objectID": "posts/creating-collapsible-output-with-knitr-chunk-hooks/index.html",
    "href": "posts/creating-collapsible-output-with-knitr-chunk-hooks/index.html",
    "title": "Creating collapsible output with knitr chunk hooks",
    "section": "",
    "text": "I am writing a (still very much unfinished) psychometrics book with suggested exercises using R. I wanted to provide solutions to the questions, but I wanted to hide the answers until the reader clicks them.\nAn easy way to create collapsible content is with html’s &lt;details&gt; tag. For example:\nCreate a variable `x`, and assign it a value of 5.\n\n&lt;details&gt;\n  &lt;summary&gt;Suggested Solution&lt;/summary&gt;\n\n```{r}\nx &lt;- 5\n```\n\n&lt;/details&gt;\nCreate a variable x, and assign it a value of 5.\n\n\nSuggested Solution\n\n\nx &lt;- 5\n\n\n\nHowever, I did not want to worry about all the &lt;details&gt; every time I wrote a question. To automate this process, I used two knitr hooks: a chunk hook and an option hook.\nChunk hooks are for customizing the output of a chunk.\nHere I create a new chunk hook that is run before and after the chunk. When it is run before the chunk, it adds the &lt;details&gt; and &lt;summary&gt; tags. After the chunk, it closes the &lt;details&gt; tag.\n\n# Add the details tag before running the chunk \n# and close the tag after running the chunk.\nknitr::knit_hooks$set(\n  solutionsetter = function(before,options) {\n  \n  if (before) {\n    \n    \"\\n\\n&lt;details&gt;&lt;summary&gt;Suggested Solution&lt;/summary&gt;\\n\\n\"\n    \n  } else {\n    \n    \"\\n\\n&lt;/details&gt;\\n\\n\"\n    \n  }\n})\n\nIf all we needed to do was to enclose the output into a &lt;details&gt; tag, then just the solutionsetter hook would be needed. However, I also wanted to set echo=TRUE so that the output would be visible even if the default for echo was FALSE.\nOption hooks are great for when you have a kind of chunk you will use often, and it requires setting many chunk options at once (e.g., a plot variant with different dimensions than your default plot has).\nHere I create a new option hook called solution. It sets the current chunk’s echo option to TRUE and also triggers the new solutionsetter code chunk below. The updated options list needs to be returned explicitly, or the hook will not work.\n\nknitr::opts_hooks$set(solution = function(options) {\n  options$echo &lt;- TRUE\n  options$solutionsetter &lt;- TRUE\n  return(options)\n})\n\nNow all need to do is to set my chunk option to solution = TRUE and the output will be collapsible:\n\nCreate a variable `x`, and assign it a value of 5.\n\n```{r, solution = TRUE}\nx &lt;- 5\n```\nCreate a variable x, and assign it a value of 5.\n\n\n\nSuggested Solution\n\nx &lt;- 5\n\n\n\n\nThe details package\nIf you want a function to enclose the output of a chunk or inline code in &lt;details&gt; tags, use the details package by Jonathan Sidi. For example, an inline chunk like this:\n`r details::details(\"Answer\", summary = \"Question\")`\nWill output like so:\n\n\n Question \n\n\nAnswer\n\n\nThe package has many other uses, which are explained in the package’s vignettes.\n\n\n\n\nCitationBibTeX citation:@online{schneider2023,\n  author = {Schneider, W. Joel},\n  title = {Creating Collapsible Output with Knitr Chunk Hooks},\n  date = {2023-06-30},\n  url = {https://wjschne.github.io/posts/creating-collapsible-output-with-knitr-chunk-hooks},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSchneider, W. J. (2023, June 30). Creating collapsible output with\nknitr chunk hooks. https://wjschne.github.io/posts/creating-collapsible-output-with-knitr-chunk-hooks"
  },
  {
    "objectID": "posts/caption-on-same-line-as-axis-title-in-ggplot2/index.html",
    "href": "posts/caption-on-same-line-as-axis-title-in-ggplot2/index.html",
    "title": "Caption on same line as axis title in ggplot2",
    "section": "",
    "text": "Sometimes I want to put a plot caption in the lower right corner of the plot.\n\nlibrary(tidyverse)\np &lt;- ggplot() +\n  stat_function(xlim = c(-4,4), fun = dnorm, n = 801) + \n  labs(x = \"z-scores\", caption = \"Note: Mean = 0, SD = 1\")\n\np\n\n\n\n\nHowever, I want the caption to be a little higher, on the same line as the x-axis title. To do so, set a a negative top margin:\n\np + theme(plot.caption = element_text(margin = margin(t = -10, unit = \"pt\")))\n\n\n\n\nHere is a more finished example.\n\nlibrary(ggnormalviolin)\nlibrary(ggtext)\nmy_font_size = 16\nmy_font &lt;- \"Roboto Condensed\"\nupdate_geom_defaults(geom = \"text\",new = list(family = my_font) )\nupdate_geom_defaults(geom = \"label\",new = list(family = my_font) )\nupdate_geom_defaults(\"richtext\", list(family = my_font))\ntheme_set(theme_minimal(base_size = my_font_size, base_family = my_font))\n\nd_rect &lt;- tibble(SS = 100, \n                 width = c(20, 40, 60, 80, 122), \n                 fill = paste0(\"gray\", c(95, 90, 80, 70, 65) - 25)) %&gt;% \n  arrange(-width)\n\ntibble(\n  Scale = c(\n    \"Fluid Reasoning\",\n    \"Verbal Comprehension\",\n    \"Visual-Spatial Processing\",\n    \"Working Memory\",\n    \"Processing Speed\",\n    \"Population\"),\n  y = c(5:1 - 0.5, 0),\n  SS = c(115, 111, 109, 86, 79, 100),\n  rxx = c(.93, .92, .92, .92, .88, 0),\n  width = c(rep(1.4, 5), 10.4),\n  alpha = c(rep(1, 5), .3)\n) %&gt;% \n  mutate(true_hat = rxx * (SS - 100) + 100, \n         see = ifelse(rxx == 0, 15, 15 * sqrt(rxx - rxx ^ 2)),\n         Scale = fct_inorder(Scale) %&gt;% fct_rev()) %&gt;% \n  ggplot(aes(y, SS)) + \n  geom_tile(data = d_rect, aes(width = 5.8, x = 2.9, \n                               fill = fill, \n                               height = width, \n                               y = SS)) + \n  geom_normalviolin(aes(mu = true_hat, \n                                        sigma = see, \n                                        width = width,\n                                        alpha = alpha), \n                                    face_left = F, \n                    fill = \"white\") + \n  geom_richtext(aes(label = ifelse(\n    Scale == \"Population\", \n    \"Population Mean\", \n    paste0(\"&lt;span style='font-size:8.5pt;color:white'&gt;(\", \n           round(100 * pnorm(SS, 100, 15),0),\n           \") &lt;/span&gt;\",\n           SS, \n           \"&lt;span style='font-size:9pt;color:#666666'&gt; (\", \n           round(100 * pnorm(SS, 100, 15),0),\n           \")&lt;/span&gt;\"))), \n    vjust = -0.2, \n    lineheight = .8, \n    fill = NA, \n    color = \"gray20\",\n    label.color = NA,\n    label.padding = unit(0,\"mm\")) +\n  geom_text(aes(y = true_hat, \n                label = ifelse(Scale == \"Population\", \n                               \"\", \n                               as.character(Scale))), \n            vjust = 1.5, \n            color = \"gray15\",\n            lineheight = .8) +\n  geom_linerange(aes(ymin = true_hat - 1.96 * see,\n                      ymax = true_hat + 1.96 * see), \n                 linewidth = .5) +\n  geom_pointrange(aes(ymin = true_hat - see,\n                      ymax = true_hat + see), \n                  size = 1.2, \n                  fatten = 1.5) +\n  geom_text(aes(x = x, y = y, label = label), \n            data = tibble(\n              y = c(49.5, 65, 75, 85, 100, 115, 125, 135, 150.5), \n              x = 5.5, \n              label = c(\"Extremely\\nLow Range\", \n                                  \"Very\\nLow\", \n                                  \"Low\\nRange\", \n                                  \"Low\\nAverage\", \n                                  \"Average\\nRange\", \n                                  \"High\\nAverage\", \n                                  \"High\\nRange\", \n                                  \"Very\\nHigh\", \n                                  \"Extremely\\nHigh Range\")), \n            color = \"white\", lineheight = .8, size = 4.25) +\n  scale_y_continuous(\n    \"Standard Scores &lt;span style='font-size:11.7pt;color:#656565'&gt;&lt;br&gt;\n    (and Percentile Ranks)&lt;/span&gt;\", \n    breaks = seq(40, 160, 10), \n    limits = c(37, 163),\n    labels = \\(x) paste0(x,\n                         \"&lt;br&gt;&lt;span style='font-size:10pt;color:#656565'&gt;(\", \n                         pnorm(x,100, 15) %&gt;% \n                           WJSmisc::proportion2percentile(digits = 2) %&gt;%\n                           str_trim(), \n                         \")&lt;/span&gt;\"),\n    expand = expansion()) +\n  scale_x_continuous(NULL, expand = expansion(), breaks = NULL) +\n  scale_alpha_identity() +\n  scale_fill_identity() +\n  coord_flip(clip = \"off\") + \n  theme(axis.title.x = element_markdown(hjust = 0, \n                                        margin = margin(t = 1.25, \n                                                        l = 2,\n                                                        unit = \"mm\")),\n        axis.text.x = element_markdown(colour = \"gray20\"),\n        plot.caption = element_markdown(hjust = 0, \n                                        size = 10, \n                                        margin = margin(t = -10.25, \n                                                        l = 100, \n                                                        unit = \"mm\"), \n                                        color = \"gray40\"),\n        plot.title = element_text(hjust = .025)) +\n  labs(\n    title = \"Display of Cognitive Test Scores\",\n    caption = \"**Notes:** The white normal curves represent the expected \n       true&lt;br&gt;score distributions for each observed score. The black lines&lt;br&gt;\n       underneath span the 68% and 95% confidence intervals.\")\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{schneider2021,\n  author = {Schneider, W. Joel},\n  title = {Caption on Same Line as Axis Title in Ggplot2},\n  date = {2021-07-21},\n  url = {https://wjschne.github.io/posts/caption-on-same-line-as-axis-title-in-ggplot2},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSchneider, W. J. (2021, July 21). Caption on same line as axis title\nin ggplot2. https://wjschne.github.io/posts/caption-on-same-line-as-axis-title-in-ggplot2"
  },
  {
    "objectID": "posts/2023-07-23-latex-equation-in-ggplot2/index.html",
    "href": "posts/2023-07-23-latex-equation-in-ggplot2/index.html",
    "title": "Annotated equations in ggplot2",
    "section": "",
    "text": "R has a mathematical annotation system via plotmath, but I like the look of true \\LaTeX equations better.\nGetting \\LaTeX equations into ggplot2 plots has never been easy. The tikzdevice package is great if you are generating a .pdf document. If you are not, then you might want to consider other options.\nThe easiest, hassle-free option that I know of is to create the equation in a \\TeX editor and then import the resulting .pdf using ggimage. If I need the best possible image quality, I convert the .pdf to .svg using dvisvgm (see example below).\nFor annotated equations, I like using the aptly-named annotate-equations \\LaTeX package. It uses tikz to remember where parts of equations are on the page. The \\eqnmark and \\eqnmarkbox functions work like so:\n\\eqnmark[color]{node_name}{latex equation terms}\nThen use the \\annotate function like so:\n\\annotate[color]{above,left}{node_name}{annotation text}\n\nMy Annotated Equation\nI am going to refer to the same file name with various endings (e.g., .tex, .pdf, .svg), so I will define it here.\n\nmyfile &lt;- \"annotatedequationsimple\"\n\nHere is the code for the annotated equation. It is saved in annotatedequationsimple.tex.\n\n\nLaTeX code\n```{tikz zscorecode}\n#| code-fold: show\n#| code-summary: \"LaTeX code\"\n#| eval: false\n\n\\documentclass[border={25pt 50pt -35pt 52pt}]{standalone}\n%\\documentclass{article}\n\\usepackage{annotate-equations}\n\\usepackage{xcolor}\n\\definecolor{myviolet}{HTML}{440154}\n\\definecolor{myblue}{HTML}{3B528B}\n\\definecolor{myindigo}{HTML}{21908C}\n\\definecolor{mygreen}{HTML}{5DC863}\n\\usepackage[sfdefault,condensed]{roboto}\n\\begin{document}\n    \n\\renewcommand{\\eqnhighlightheight}{\\mathstrut}\n    \n\\huge$\n\\eqnmark[myviolet]{z}{z} = \n\\frac{\n    \\eqnmark[myblue]{x}{X}-\n    \\eqnmark[myindigo]{mu}{\\mu}}{\n    \\eqnmark[mygreen]{sigma}{\\sigma}}\n$\n\n\n\\annotate[\n    yshift=1em, \n    myviolet,\n    align=right]\n    {above, left}\n    {z}\n    {$z$-score}\n    \n\\annotate[\n    yshift=1em, \n    myblue, \n    align=right]\n    {above,left}\n    {x}\n    {Observed\\\\ Score}\n    \n\n\\annotate[\n    yshift=1em, \n    myindigo]\n    {above,right}\n    {mu}\n    {Population\\\\ Mean\\\\ $\\mu = 100$}\n    \n\n    \n\\annotate[\n    yshift=-.4em, \n    mygreen, \n    align=right]\n    {below,left}\n    {sigma}\n    {Population\\\\ Standard\\\\ Deviation\\\\ $\\sigma = 15$}\n    \n\\end{document}\n\n```\n\n\nNow convert the .tex file to .pdf:\n\npaste0('pdflatex -interaction=nonstopmode ', myfile,'.tex') |&gt; \n  shell()\n\nNow we can convert the .pdf to .svg:\n\npaste0(\"dvisvgm --pdf --output=\", myfile,\".svg \", myfile,\".pdf\") |&gt; \n  shell()\n\nFor best image quality, import the .svg file with svgparser. The read_svg function will create a grid grob that can plotted directly using ggplot2::annotation_custom. If you want fine control of the imported grob, you can plot it using the gggrid package. See here for an example.\nIn the simplest case, we can do this:\n\nlibrary(svgparser)\nmy_svg &lt;- svgparser::read_svg(paste0(myfile, \".svg\"))\nggplot() +\n  theme_void() +\n  annotation_custom(my_svg, xmin = 0, xmax = 1, ymin = 0, ymax = 1) \n\n\n\n\nFigure 1: A simple plot with an annotated equation.\n\n\n\n\nHowever, this is no better than just displaying the .svg directly. You probably want to embed the equation in a plot. For example:\n\n\nCode\nmu &lt;- 100\nsigma &lt;- 15\nplot_height &lt;- dnorm(mu, mu, sigma)\nlb &lt;- -4 * sigma + mu\nub &lt;- 4 * sigma + mu\n\nggplot() +\n  annotation_custom(my_svg,\n                    xmin = 112,\n                    xmax = 164,\n                    ymin = .33 * plot_height) +\n  stat_function(\n    fun = \\(x) dnorm(x, mean = mu, sd = sigma),\n    geom = \"area\",\n    n = 1000,\n    fill = \"dodgerblue\",\n    alpha = .5\n  ) +\n  theme_classic(base_family = \"Roboto Condensed\",\n                base_size = 18) +\n  theme(\n    axis.text.x = element_markdown(),\n    axis.title.x = element_markdown(),\n    axis.line = element_blank()\n  )  +\n  scale_x_continuous(\n    \"Observed Score *X*&lt;br&gt;*z*\",\n    breaks = seq(lb, ub, sigma),\n    limits = c(lb, ub),\n    labels = \\(x) paste0(\n      signs::signs(x),\n      \"&lt;br&gt;\",\n      ifelse(\n        x == mu,\n        \"&lt;em&gt;&mu;&lt;/em&gt;\",\n        paste0(\n          signs::signs((x - mu) / sigma,\n                       add_plusses = T,\n                       label_at_zero = \"none\"\n          ),\n          \"&lt;em&gt;&sigma;&lt;/em&gt;\"\n        )\n      )\n    )\n  ) +\n  scale_y_continuous(\n    NULL,\n    limits = c(0, plot_height),\n    expand = expansion(),\n    breaks = NULL\n  ) \n\n\n\n\n\nFigure 2: Importing an .svg file via svgparser and annotation_custom.\n\n\n\n\nIf you can live with just a little pixelation, the ggimage package can import a .pdf directly with good results and less hassle, provided you render the plot with the ragg package.\n\n\nCode\nggplot() +\n  geom_image(\n    data = tibble(\n      x = 140,\n      y = .65 * plot_height,\n      image = \"annotatedequationsimple.pdf\"\n    ),\n    aes(x, y, image = image),\n    size = .70\n  ) +\n  stat_function(\n    fun = \\(x) dnorm(x, mean = mu, sd = sigma),\n    geom = \"area\",\n    n = 1000,\n    fill = \"dodgerblue\",\n    alpha = .5\n  ) +\n  theme_classic(base_family = \"Roboto Condensed\", \n                base_size = 18) +\n  theme(\n    axis.text.x = element_markdown(),\n    axis.title.x = element_markdown(),\n    axis.line = element_blank()\n  )  +\n  scale_x_continuous(\n    \"Observed Score *X*&lt;br&gt;*z*\",\n    breaks = seq(lb, ub, sigma),\n    limits = c(lb, ub),\n    labels = \\(x) paste0(\n      signs::signs(x),\n      \"&lt;br&gt;\",\n      ifelse(\n        x == mu,\n        \"&lt;em&gt;&mu;&lt;/em&gt;\",\n        paste0(\n          signs::signs((x - mu) / sigma,\n                       add_plusses = T,\n                       label_at_zero = \"none\"\n          ),\n          \"&lt;em&gt;&sigma;&lt;/em&gt;\"\n        )\n      )\n    )\n  ) +\n  scale_y_continuous(\n    NULL,\n    limits = c(0, plot_height),\n    expand = expansion(),\n    breaks = NULL\n  )\n\n\n\n\n\nFigure 3: Importing a .pdf file via ggimage::geom_image.\n\n\n\n\n\n\nA more complex example\nIn this example, I used the \\eqnmarkbox function for greater clarity. The .tex file is saved in a file called annotatedequation.tex.\n\n\nLaTeX code\n\\documentclass[border={10pt 48pt -45pt 62pt}]{standalone}\n%\\documentclass{article}\n\\usepackage{annotate-equations}\n\\usepackage{xcolor}\n\\definecolor{myviolet}{HTML}{414487}\n\\definecolor{myblue}{HTML}{2F6C8E}\n\\definecolor{myblue2}{HTML}{21908C}\n\\definecolor{mygreen}{HTML}{2FB47C}\n\\definecolor{mygreen2}{HTML}{7AD151}\n\\usepackage[sfdefault,condensed]{roboto}\n\\begin{document}\n    \n\\renewcommand{\\eqnhighlightheight}{\\mathstrut}\n    \n$\\LARGE\n\\eqnmarkbox[myviolet]{nodeP}{P\\left(T \\le \\tau \\right)} = \n\\eqnmarkbox[myblue]{phi}{\\Phi}\n\\left(\\frac{\n    \\eqnmarkbox[myblue2]{tau}{\\tau}-\n    \\eqnmarkbox[mygreen]{esttrue}{\\hat{T}}}{\n    \\eqnmarkbox[mygreen2]{sigma}{\\sigma_{T - \\hat{T}}}}\n\\right)$\n\n\n\\annotate[\n    yshift=1em, \n    xshift=11mm, \n    myviolet]\n    {above, left}\n    {nodeP}\n    {Probability true score $T$\\\\ is less than threshold $\\tau$ }\n    \n\\annotate[\n    yshift=-.6em,\n    myblue]\n    {below,left}\n    {phi}\n    {Standard Normal Cumulative\\\\ Distribution Function $\\Phi()$}\n    \n\\annotate[\n    yshift=1.4em, \n    xshift=4mm, \n    myblue2]\n    {above,left}\n    {tau}\n    {Threshold $\\tau=85$}\n    \n\\annotate[\n    yshift=3em, \n    xshift=7mm, \n    mygreen]\n    {above,left}\n    {esttrue}\n    {Estimated True Score $\\hat{T}=r_{XX}(X-\\mu)+\\mu$\\\\ \n    Observed Score $X\\sim \\mathcal{N}\\left(\\mu = 100, \\sigma=15\\right)$\\\\ \n    Reliability Coefficient $r_{XX}=\\{.80,.85,.90,.95,.98\\}$}\n    \n\\annotate[\n    yshift=-2em, \n    mygreen2]\n    {below,left}\n    {sigma}\n    {Standard Error of the Estimate\\\\ \n    $\\sigma_{T-\\hat{T}}=\\sigma\\sqrt{r_{XX}-r_{XX}^2}$}\n    \n\\end{document}\n\n\nNow convert .tex to .pdf:\n\n\nCode\nmyfile &lt;- \"annotatedequation\"\n\npaste0('pdflatex -interaction=nonstopmode ', myfile,'.tex') |&gt; \n  shell()\n\n\nAnd we are ready to plot. This plot shows the probability that an observed score will have a true score less than a specific threshold, given a reliability coefficient.\n\n\nCode\nviridis_start &lt;- .2\nviridis_end &lt;- .8\nthreshold &lt;- 70\n\n# Find where a line intersects with the normal cdf\nfind_x &lt;- function(rxx = .8,\n                   slope = 0.0048,\n                   intercept = .66,\n                   mu = 100,\n                   sigma = 15,\n                   start_x = 60,\n                   threshold = 70) {\n  x &lt;- start_x\n  precision &lt;- .00001\n  diff_y &lt;- precision * 10\n  reps &lt;- 0\n  while (abs(diff_y) &gt; precision) {\n    x &lt;- x - diff_y \n    line_y &lt;- x * slope + intercept\n    curve_y &lt;- pnorm(threshold,\n                     mean = rxx * (x - mu) + mu,\n                     sd = sigma * sqrt(rxx - rxx ^ 2))\n    \n    line_y &lt;- x * slope + intercept\n    curve_y &lt;- pnorm(threshold,\n                     mean = rxx * (x - mu) + mu,\n                     sd = sigma * sqrt(rxx - rxx ^ 2))\n    diff_y &lt;- line_y - curve_y\n    reps &lt;- reps + 1\n  }\n  tibble(x = x, p = line_y, mu = mu, sigma = sigma, threshold = threshold, reps = reps)\n}\n\n\n\n\ndimage = data.frame(x = 115, \n                    y = .62, \n                    image = paste0(myfile, \".pdf\"))\nv_rxx &lt;- round(c(seq(0.80, 0.95, 0.05), 0.98), 2)\n\nd_threshold &lt;-\n  crossing(x = round(seq(40, 160, 0.1), 1),\n           rxx = v_rxx,\n           threshold = 70) %&gt;%\n  mutate(\n    see = 15 * sqrt(rxx - rxx ^ 2),\n    mu = (x - 100) * rxx + 100,\n    p = pnorm(threshold, mu, see)\n  ) %&gt;%\n  group_by(rxx) %&gt;%\n  mutate(acceleration = p - lag(p)) %&gt;%\n  ungroup\n\n\n\nd_labels &lt;- tibble(rxx = v_rxx) %&gt;%\n  mutate(x = map_df(rxx, find_x)) |&gt; \n  unnest(x)\n\nd_threshold %&gt;%\n  ggplot(aes(x, p)) +\n  geom_line(aes(color = factor(rxx)), lwd = 1) +\n  geom_vline(\n    aes(xintercept = threshold),\n    lty = 2,\n    lwd = 1,\n    color = \"gray30\"\n  ) +\n  geom_image(data = dimage,\n             aes(x = x,\n                 y = y,\n                 image = image),\n             size = .87) +\n  geom_richtext(\n    aes(label = rxx_label,\n        color = factor(rxx)),\n    data = d_labels %&gt;%\n      mutate(rxx_label = prob_label(rxx)),\n    angle = -67,\n    size = WJSmisc::ggtext_size(13),\n    label.colour = NA,\n    fill = \"#FFFFFF\",\n    family = \"Roboto Condensed\",\n    label.margin = unit(0, \"mm\"),\n    label.r = unit(2, \"mm\"),\n    label.padding = unit(c(0, 0.75, 0, .5), \"mm\")\n  ) +\n  scale_x_continuous(\n    \"Observed Score\",\n    breaks = seq(40, 160, 15),\n    minor_breaks = seq(40, 160, 5),\n    expand = expansion()\n  ) +\n  scale_y_continuous(\n    paste0(\"Probability True Score &lt; \", threshold),\n    expand = expansion(),\n    breaks = seq(0, 1, 0.1),\n    labels = prob_label,\n    limits = c(0, 1)\n  ) +\n  scale_color_viridis_d(begin = viridis_start,\n                        end = viridis_end) +\n  theme_minimal(base_family = \"Roboto Condensed\", \n                base_size = 16) +\n  theme(legend.position = \"none\", \n        plot.margin = unit(c(3, 5, 2, 2), \"mm\")) +\n  coord_fixed(ratio = 100,\n              clip = \"off\",\n              xlim = c(40, 160)) \n\n\n\n\n\nFigure 4: The probability that a true score is less than 70 depends on the observed score’s position and reliability coefficient.\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{schneider2023,\n  author = {Schneider, W. Joel},\n  title = {Annotated Equations in Ggplot2},\n  date = {2023-07-24},\n  url = {https://wjschne.github.io/posts/2023-07-23-latex-equation-in-ggplot2},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSchneider, W. J. (2023, July 24). Annotated equations in\nggplot2. https://wjschne.github.io/posts/2023-07-23-latex-equation-in-ggplot2"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "W. Joel Schneider’s Blog",
    "section": "",
    "text": "Making a custom arrowhead for ggplot2 using ggarrow\n\n\n\n\n\nThe ggarrow package allows any polygon to be an arrowhead.\n\n\n\n\n\n\nJul 31, 2023\n\n\nW. Joel Schneider\n\n\n\n\n\n\n  \n\n\n\n\nAnnotated equations in ggplot2\n\n\n\n\n\n\n\nggplot2\n\n\n\n\nImporting latex into ggplot2\n\n\n\n\n\n\nJul 24, 2023\n\n\nW. Joel Schneider\n\n\n\n\n\n\n  \n\n\n\n\nCreating collapsible output with knitr chunk hooks\n\n\n\n\n\n\n\nknitr\n\n\nmarkdown\n\n\n\n\nHow to make the output of a knitr code chunk collapsible using knitr hooks.\n\n\n\n\n\n\nJun 30, 2023\n\n\nW. Joel Schneider\n\n\n\n\n\n\n  \n\n\n\n\nSplitting sentence texts into roughly equal segments\n\n\n\n\n\n\n\nggplot2\n\n\n\n\nFor long text labels on the y-axis, splitting them into roughly equal segments can look better.\n\n\n\n\n\n\nMay 31, 2023\n\n\nW. Joel Schneider\n\n\n\n\n\n\n  \n\n\n\n\nInsert Text from One Markdown Document into Another\n\n\n\n\n\n\n\nmarkdown\n\n\n\n\nA function for retrieving a div or span from another markdown document\n\n\n\n\n\n\nMar 30, 2023\n\n\nW. Joel Schneider\n\n\n\n\n\n\n  \n\n\n\n\nMaking text labels the same size as axis labels in ggplot2\n\n\n\n\n\n\n\nggplot2\n\n\n\n\nThe geom_text and geom_label functions do not specifiy text size the same way as the rest of ggplot2 elements do. For consistent text sizes, we can apply a simple conversion.\n\n\n\n\n\n\nAug 10, 2021\n\n\nW. Joel Schneider\n\n\n\n\n\n\n  \n\n\n\n\nBar chart labels on smooth paths in ggplot2\n\n\n\n\n\n\n\nggplot2\n\n\n\n\nPlacing stacked bar chart labels on a smooth path makes them easier to compare.\n\n\n\n\n\n\nJul 31, 2021\n\n\nW. Joel Schneider\n\n\n\n\n\n\n  \n\n\n\n\nPoint labels perpendicular to a curve in ggplot2\n\n\n\n\n\n\n\nggplot2\n\n\n\n\nHow to place legible labels for points on a curve in ggplot2\n\n\n\n\n\n\nJul 27, 2021\n\n\nW. Joel Schneider\n\n\n\n\n\n\n  \n\n\n\n\nCaption on same line as axis title in ggplot2\n\n\n\n\n\n\n\nggplot2\n\n\n\n\nYou can put the caption on the line as the x-axis title\n\n\n\n\n\n\nJul 21, 2021\n\n\nW. Joel Schneider\n\n\n\n\n\n\n  \n\n\n\n\nConcatenating vectors unless a vector is empty\n\n\n\n\n\n\n\nR\n\n\n\n\nThe paste and paste0 functions have a recycle0 argument that returns an empty vector when any part of the string is empty.\n\n\n\n\n\n\nMay 13, 2021\n\n\nW. Joel Schneider\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "W. Joel Schneider, Ph.D.\nProfessor\nTemple University\nPsychological Studies in Education\n\n\n\nCounseling Psychology\n\n\nSchool Psychology\n\n\n\n Curriculum Vitae\n Contact Me\n\n\n\n\nAbout Me\nI am a professor at Temple University in the College of Education and Human Development in the Psychological Studies in Education Department. I belong to both the School Psychology and Counseling Psychology programs.\nAlthough I have diverse interests, my primary focus is trying to understand and improve the validity of psychological assessment practices. I teach courses in assessment, counseling, statistics, and research methods.\nI grew up in Southern California (1970–1990) and lived in Córdoba, Argentina (1990–1992). I completed my undergraduate degree in Psychology at the University of California at Berkeley in 1995 and my doctoral studies in clinical psychology at Texas A&M University in 2003. My internship year (2001–2002) was spent in the Dutchess County Department of Behavioral & Community Health in Poughkeepsie, NY. Since then I have been a faculty member at Illinois State University (2002–2017) and Temple University (2017–Present)."
  },
  {
    "objectID": "posts/bar-chart-labels-on-smooth-paths-in-ggplot2/index.html",
    "href": "posts/bar-chart-labels-on-smooth-paths-in-ggplot2/index.html",
    "title": "Bar chart labels on smooth paths in ggplot2",
    "section": "",
    "text": "Setup\nThis trick takes a lot of work. I only use it when I need a plot to look its best.\nSuppose I have a Likert questionnaire item with responses ranging from Strongly Disagree to Strongly Agree. Let’s say I have many groups in my study (e.g., college majors), and I want to compare their responses to the item.\nFirst I will create fake data for 26 groups, A–Z.\n\nlibrary(extrafont)\nlibrary(tidyverse)\nmyfont &lt;- \"Roboto Condensed\"\n\nd &lt;- tibble(Group = LETTERS[1:26],\n            mu = rnorm(26, 0, .5),\n            sigma = 1) %&gt;%\n  mutate(x = pmap(list(mean = mu, sd = sigma), rnorm, n = 500)) %&gt;%\n  unnest(x) %&gt;%\n  mutate(Agree = cut_number(x, 6) %&gt;%\n           factor(\n             labels = c(\n               \"Strongly\\nDisagree\",\n               \"Disagree\",\n               \"Slightly\\nDisagree\",\n               \"Slightly\\nAgree\",\n               \"Agree\",\n               \"Strongly\\nAgree\"\n             )\n           )) %&gt;%\n  group_by(Group, Agree) %&gt;%\n  summarise(n = n(), .groups = \"drop\") %&gt;%\n  group_by(Group) %&gt;%\n  arrange(Group, Agree) %&gt;%\n  mutate(p = n / sum(n)) %&gt;%\n  ungroup()\n\n\n\nFirst Attempts at Plotting\n\nd %&gt;%\n  ggplot(mapping = aes(p, Group)) +\n  geom_col(aes(fill = fct_rev(Agree))) +\n  scale_fill_viridis_d(NULL,\n                       begin = .15,\n                       end = 0.8,\n                       direction = -1) +\n  scale_x_continuous(\"Percent\", expand = expansion()) +\n  scale_y_discrete(\"Group\", expand = expansion()) +\n  coord_fixed(1 / 20.5, clip = \"off\") +\n  geom_text(\n    aes(x = p, label = round(100 * p, 0)),\n    color = \"white\",\n    family = myfont,\n    position = position_stack(vjust = .5)\n  )\n\n\n\n\nNot bad, but it would look better if we sorted the groups. We have many sorting options. One is that we can convert the Likert scale to numeric and then sort by the group with the highest mean.\n\nd %&gt;%\n  mutate(Group = fct_reorder(Group, .x = as.numeric(Agree) * p, \n                             .fun = mean)) %&gt;%\n  ggplot(mapping = aes(p, Group)) +\n  geom_col(aes(fill = fct_rev(Agree))) +\n  scale_fill_viridis_d(NULL,\n                       begin = .15,\n                       end = 0.8,\n                       direction = -1) +\n  scale_x_continuous(\"Percent\", expand = expansion()) +\n  scale_y_discrete(\"Group\", expand = expansion()) +\n  coord_fixed(1 / 20.5, clip = \"off\") +\n  geom_text(\n    aes(x = p, label = round(100 * p, 0)),\n    color = \"white\",\n    family = myfont,\n    position = position_stack(vjust = .5)\n  )\n\n\n\n\nIf I wanted to sort by the “Strongly Agree” category (or any other category):\n\nd %&gt;%\n  mutate(Group = fct_reorder(\n    Group,\n    .x = (Agree == \"Strongly\\nAgree\") * p,\n    .fun = mean\n  )) %&gt;%\n  ggplot(mapping = aes(p, Group)) +\n  geom_col(aes(fill = fct_rev(Agree))) +\n  scale_fill_viridis_d(NULL,\n                       begin = .15,\n                       end = 0.8,\n                       direction = -1) +\n  scale_x_continuous(\"Percent\", expand = expansion()) +\n  scale_y_discrete(\"Group\", expand = expansion()) +\n  coord_fixed(1 / 20.5, clip = \"off\") +\n  geom_text(\n    aes(x = p, label = round(100 * p, 0)),\n    color = \"white\",\n    family = myfont,\n    position = position_stack(vjust = .5)\n  )\n\n\n\n\n\n\nFinal Plot\nSo far, these plots look pretty good. However, I wish that the percentage labels were placed in a more aesthetically pleasing way. I am going to group by each of the response categories and then create a loess regression equation to smooth out the placement. It will mean that the labels are no longer centered in the stacked bars, but I think the sacrifice is worth it. I think that the percentage values are much easier to compare because the eye can follow the smooth line of labels.\n\nd &lt;- tibble(Group = LETTERS[1:26],\n            mu = rnorm(26, 0, .5),\n            sigma = 1) %&gt;%\n  mutate(x = pmap(list(mean = mu, sd = sigma), rnorm, n = 500)) %&gt;%\n  unnest(x) %&gt;%\n  mutate(Agree = cut_number(x, 6) %&gt;%\n           factor(\n             labels = c(\n               \"Strongly\\nDisagree\",\n               \"Disagree\",\n               \"Slightly\\nDisagree\",\n               \"Slightly\\nAgree\",\n               \"Agree\",\n               \"Strongly\\nAgree\"\n             )\n           )) %&gt;%\n  mutate(Group = fct_reorder(Group, as.numeric(Agree), .fun = mean)) %&gt;%\n  group_by(Group, Agree) %&gt;%\n  summarise(n = n(), .groups = \"drop\") %&gt;%\n  mutate(Group_position = as.numeric(Group)) %&gt;%\n  group_by(Group) %&gt;%\n  arrange(Group, Agree) %&gt;%\n  mutate(p = n / sum(n),\n         # proportion in each response category by group\n         cp = cumsum(p),\n         # cumulative proportion\n         xpos = cp - p / 2 # center of each stacked bar\n         ) %&gt;%\n         group_by(Agree) %&gt;%\n           nest() %&gt;%\n           mutate(\n             fit = map(data,\n                       loess,\n                       formula = \"xpos ~ Group_position\",\n                       span = 0.45),\n             # loess regression for each response category\n             xhat = map(fit, predict) # x-axis position on smooth line\n           ) %&gt;%\n           select(-fit) %&gt;%\n           unnest(c(data, xhat)) %&gt;%\n           mutate(Group = factor(Group, labels = rev(LETTERS[1:26])))\n         \n         d %&gt;%\n           ggplot(mapping = aes(p, Group)) +\n           geom_col(aes(fill = fct_rev(Agree))) +\n           geom_text(aes(x = xhat,\n                         label = ifelse(p &gt; .01, # No labels on small bars\n                                        round(100 * p, 0),\n                                        \"\")),\n                     color = \"white\",\n                     family = myfont) +\n           scale_fill_viridis_d(begin = .15,\n                                end = 0.8,\n                                direction = -1) +\n           scale_x_continuous(\"Percent\", expand = expansion()) +\n           scale_y_discrete(\"Group\", expand = expansion()) +\n           coord_fixed(1 / 20.5, clip = \"off\") +\n           theme_minimal(base_size = 13, base_family = myfont) +\n           theme(\n             legend.position = \"top\",\n             legend.box.spacing = unit(0.5, \"mm\"),\n             legend.text = element_text(\n               color = \"white\",\n               size = 13,\n               margin = margin(b = -40),\n               # Lower legend text into box\n               vjust = 0.5\n             ),\n             legend.spacing.x = unit(0, \"mm\"),\n             axis.text.y = element_text(hjust = 0.5)\n           ) +\n           guides(\n             fill = guide_legend(\n               title = NULL,\n               nrow = 1,\n               # Put legend on a single row\n               reverse = T,\n               # Reverse order of legend\n               label.position = \"top\",\n               # Put text atop keys\n               keyheight = unit(15, \"mm\"),\n               # Size of legend rectangles\n               keywidth = unit(22.56, \"mm\")\n             )\n           ) \n\n\n\n\nThis feels right to me.\n\n\n\n\nCitationBibTeX citation:@online{schneider2021,\n  author = {Schneider, W. Joel},\n  title = {Bar Chart Labels on Smooth Paths in Ggplot2},\n  date = {2021-07-31},\n  url = {https://wjschne.github.io/posts/bar-chart-labels-on-smooth-paths-in-ggplot2},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSchneider, W. J. (2021, July 31). Bar chart labels on smooth paths\nin ggplot2. https://wjschne.github.io/posts/bar-chart-labels-on-smooth-paths-in-ggplot2"
  },
  {
    "objectID": "posts/concatenating-vectors-unless-a-vector-is-empty/index.html",
    "href": "posts/concatenating-vectors-unless-a-vector-is-empty/index.html",
    "title": "Concatenating vectors unless a vector is empty",
    "section": "",
    "text": "I often need to add a prefix or suffix to a character vector:\n\nlibrary(tidyverse)\nx &lt;- c(\"A\", \"B\", \"C\")\npaste0(x, \"_1\")\n\n[1] \"A_1\" \"B_1\" \"C_1\"\n\n\nHowever, if the vector is empty, I do not want bare prefixes or suffixes like this:\n\nx &lt;- character(0)\npaste0(x, \"_1\")\n\n[1] \"_1\"\n\n\nI used to write a lot of tedious if statements like this:\n\nif (length(x) == 0) {\n  y &lt;- character(0)\n} else {\n  y &lt;- paste0(x, \"_1\")\n}\n\nFor R 4.0.1 and later versions, the paste and paste0 functions acquired the recycle0 argument. Setting recycle0 to TRUE returns an empty vector if at least one string is empty:\n\npaste0(x, \"_1\", recycle0 = TRUE)\n\ncharacter(0)\n\n\nIf you need to work with an earlier version of R, you can use the sprintf function instead:\n\n# Non-empty vector\nx &lt;- c(\"A\", \"B\", \"C\")\nsprintf(\"%s_1\", x)\n\n[1] \"A_1\" \"B_1\" \"C_1\"\n\n# Empty vector\nx &lt;- character(0)\nsprintf(\"%s_1\", x)\n\ncharacter(0)\n\n\nThe glue function from the glue package also works nicely:\n\n# Non-empty vector\nx &lt;- c(\"A\", \"B\", \"C\")\nglue::glue(\"{x}_1\")\n\nA_1\nB_1\nC_1\n\n# Empty vector\nx &lt;- character(0)\nglue::glue(\"{x}_1\")\n\n\n\n\nCitationBibTeX citation:@online{schneider2021,\n  author = {Schneider, W. Joel},\n  title = {Concatenating Vectors Unless a Vector Is Empty},\n  date = {2021-05-13},\n  url = {https://wjschne.github.io/posts/concatenating-vectors-unless-a-vector-is-empty},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSchneider, W. J. (2021, May 13). Concatenating vectors unless a\nvector is empty. https://wjschne.github.io/posts/concatenating-vectors-unless-a-vector-is-empty"
  },
  {
    "objectID": "posts/insert-text-from-one-markdown-document-into-another/index.html",
    "href": "posts/insert-text-from-one-markdown-document-into-another/index.html",
    "title": "Insert Text from One Markdown Document into Another",
    "section": "",
    "text": "While assembling a reply letter for a revise-and-resubmit document, I was documenting for reviewers how we addressed their concerns. The reply letter quoted numerous sentences and paragraphs that had been changed. Unfortunately, each time my co-authors and I edited the paper, I lost track of which sentences and paragraphs I had previously copied into the reply letter. I did not want to misquote my own paper.\nCopying-and-pasting with each edit was getting tedious, and it was an error-prone process. I decided to write a function that would retrieve a named div or span from the paper and print it as a quote in my reply letter. Here it is:\nget_quote &lt;- function(id, file, blockquote = TRUE) {\n  blocktext &lt;- ifelse(blockquote, \"\\n&gt; \", \"\")\n\n  refreplace &lt;- function(x) {\n    # List of sequence types\n    crossrefs &lt;- c(`@fig-` = \"Figure\",\n                   `@fig-` = \"Table\",\n                   `@eq-` = \"Equation\",\n                   `@thm-` = \"Lemma\",\n                   `@lem-` = \"Corollary\",\n                   `@cor-` = \"Proposition\",\n                   `@prp-` = \"Conjecture\",\n                   `@cnj-` = \"Definition\",\n                   `@def-` = \"Example\",\n                   `@exm-` = \"Example\",\n                   `@exr-` = \"Exercise\",\n                   `apafg-` = \"Figure\",\n                   `apatb-` = \"Figure\"\n    )\n\n    # Find all crossreference types and number them\n    make_replacements &lt;- function(x, reftype, prefix) {\n      regstring &lt;- ifelse(stringr::str_starts(reftype, \"\\\\@\"),\n                          paste0(\"\\\\\", reftype, \"(.*?)(?=[\\\\.\\\\?\\\\!\\\\]\\\\}\\\\s,])\"),\n                          paste0(\"\\\\{\", reftype, \"(.*?)\\\\}\"))\n      patterns &lt;- stringr::str_extract_all(string = x, pattern = regstring) |&gt;\n        unlist() |&gt;\n        unique() |&gt;\n        stringr::str_replace(\"\\\\{\", \"\\\\\\\\{\") |&gt;\n        stringr::str_replace(\"\\\\}\", \"\\\\\\\\}\")\n\n      if (all(is.na(patterns))) return(NULL)\n      replacements &lt;- paste(prefix, seq_along(patterns))\n      names(replacements) &lt;- patterns\n      replacements\n    }\n    allreplacements &lt;- purrr::map2(\n      names(crossrefs),\n      crossrefs,\n      \\(rt, pf) make_replacements(\n        x = x,\n        reftype = rt,\n        prefix = pf)) |&gt;\n      unlist()\n\n    stringr::str_replace_all(x, allreplacements)\n\n  }\n\n  filetext &lt;- readLines(file) |&gt;\n    refreplace()\n\n  idcount &lt;- sum(stringr::str_count(filetext, paste0(\"#\", id)))\n  if (idcount &gt; 1)\n    stop(paste0(\n      \"The id (\",\n      id ,\n      \") is not unique. There are \",\n      idcount,\n      \" instances of id = \",\n      id,\n      \".\"\n    ))\n\n  s &lt;- filetext |&gt;\n    paste0(collapse = \"\\n\") |&gt;\n    stringr::str_match(pattern = paste0(\"(?&lt;=\\\\[).+(?=\\\\]\\\\{\\\\#\",\n                               id,\n                               \"\\\\})\"))  |&gt;\n    getElement(1)\n\n  if (is.na(s)) {\n    s &lt;- filetext |&gt;\n      paste0(collapse = \"|||\") |&gt;\n      stringr::str_match(pattern = paste0(\":::\\\\{\\\\#\",\n                                 id,\n                                 \"\\\\}(.*?):::\"))  |&gt;\n      getElement(2) |&gt;\n      stringr::str_replace_all(\"\\\\|\\\\|\\\\|\", blocktext)\n  } else {\n    s &lt;- paste0(blocktext, s)\n  }\n\n  if (is.na(s)) stop(\"Could not find a div or span with id = \", id)\n\n  s\n}\nFor your convenience and mine, I have added this function into the WJSmisc package."
  },
  {
    "objectID": "posts/insert-text-from-one-markdown-document-into-another/index.html#remove-blockquote-formatting",
    "href": "posts/insert-text-from-one-markdown-document-into-another/index.html#remove-blockquote-formatting",
    "title": "Insert Text from One Markdown Document into Another",
    "section": "Remove blockquote formatting",
    "text": "Remove blockquote formatting\nBy default, the function adds a &gt; before each line in the quoted markdown so that it appears as a block quote. You can turn off the block quote formatting like so:\n`r get_quote(\"id1\", \"index.qmd\", blockquote = FALSE)`\nText in a span"
  },
  {
    "objectID": "posts/insert-text-from-one-markdown-document-into-another/index.html#curly-braces-with-additional-information",
    "href": "posts/insert-text-from-one-markdown-document-into-another/index.html#curly-braces-with-additional-information",
    "title": "Insert Text from One Markdown Document into Another",
    "section": "Curly braces with additional information",
    "text": "Curly braces with additional information\nWhat if you need to put additional information in the curly braces of the span or div (e.g., a css class)?\n[Here is more text with extra stuff in the curly braces.]{#id3 .myclass}\nYou can trick the function into thinking that the extra stuff is part of the id like so:\n`r get_quote(\"id3 .myclass\", \"index.qmd\")`\n\nHere is more text with extra stuff in the curly braces."
  },
  {
    "objectID": "posts/point-labels-perpendicular-to-a-curve-in-ggplot2/index.html",
    "href": "posts/point-labels-perpendicular-to-a-curve-in-ggplot2/index.html",
    "title": "Point labels perpendicular to a curve in ggplot2",
    "section": "",
    "text": "I would like to label points on a sine function so that the labels are always legible. In a sine wave plot in which θ ranges from 0 to 2π, sin(θ) ranges from −1 to +1. Thus, the plot’s xy ratio is\n\\text{plot ratio}= \\frac{2\\pi-0}{1- (-1)}=\\pi\nThe first derivative of the sine function is the cosine function. In my plot, the slope of the tangent line at each point is\n\n\\text{tangent slope} = \\text{plot ratio}\\times \\cos(\\theta)\n The angle of the tangent line’s slope is the arctan of the slope. I would like to place the label perpendicular to the tangent line so I will add 90 degrees (i.e., π/2 radians).\n\n\\text{text angle}=\\tan^{-1}(\\text{tangent slope})+\\pi/2\n\nNow I need a pair of functions that will convert this angle into the right values for ggplot2’s hjust and vjust arguments. I have added the angle2vjust and angle2hjust functions to the WJSmisc package, but I have defined them here as well:\n\nangle2vjust &lt;- function(theta, multiplier = 1, as_degrees = FALSE) {\n  if (as_degrees) theta &lt;- theta * pi / 180\n  (((sin(theta + pi) + 1) / 2) - 0.5) * multiplier + 0.5\n}\n\nangle2hjust &lt;- function(theta, multiplier = 1, as_degrees = FALSE) {\n  if (as_degrees) theta &lt;- theta * pi / 180\n  (((cos(theta + pi) + 1) / 2) - 0.5) * multiplier + 0.5\n}\n\nNow we plot the sine function with labels. I have used geom_richtext from the ggtext package because it allows me to set a white background along with padding and margins.\n\nlibrary(tidyverse)\nlibrary(ggtext)\n\nplot_ratio &lt;- pi\n\ntibble(theta = seq(0, 2 * pi, length.out = 13),\n            y =  sin(theta),\n            tangent_slope = cos(theta) * plot_ratio,\n            text_angle = atan(tangent_slope) + pi / 2) %&gt;%\n  ggplot(aes(theta, y)) +\n  geom_richtext(aes(label = formatC(y, digits = 2, format = \"f\"),\n                    vjust = angle2vjust(text_angle),\n                    hjust = angle2hjust(text_angle)),\n                label.color = NA,\n                label.padding = unit(1, \"pt\"),\n                label.margin = unit(5, \"pt\"),\n                size = 4) +\n  geom_point() +\n  stat_function(fun = sin) +\n  scale_x_continuous(\"&theta;\",\n                     breaks = seq(0, 2 * pi, \n                                  length.out = 13),\n                     minor_breaks = NULL,\n                     labels = function(x) round(x * 180 / pi)) +\n  scale_y_continuous(\"sin(&theta;)\") +\n  coord_fixed(ratio = plot_ratio, clip = \"off\") +\n  theme_minimal(base_size = 16) +\n  theme(axis.title.x = element_markdown(),\n        axis.title.y = element_markdown())\n\n\n\n\nIf you do not mind turning your head to one side or the other, a somewhat easier method is to set the label’s vjust to a negative value and rotate the labels by the angle of the tangent line:\n\ntibble(theta = seq(0, 2 * pi, length.out = 13),\n            y = sin(theta),\n            tangent_slope = cos(theta) * plot_ratio,\n            text_angle = atan(tangent_slope)) %&gt;%\n  ggplot(aes(theta, y)) +\n  geom_richtext(aes(label = round(y, 2),\n                    angle = text_angle * 180 / pi),\n                vjust = 0,\n                label.color = NA,\n                label.padding = unit(1, \"pt\"),\n                label.margin = unit(2, \"pt\"),\n                size = 4) +\n  geom_point() +\n  stat_function(fun = sin) +\n  scale_x_continuous(\"&theta;\",\n                     breaks = seq(0, 2 * pi, \n                                  length.out = 13),\n                     minor_breaks = NULL,\n                     labels = function(x) round(x * 180 / pi)) +\n  scale_y_continuous(\"sin(&theta;)\") +\n  coord_fixed(ratio = plot_ratio, clip = \"off\") +\n  theme_minimal(base_size = 16) +\n  theme(axis.title.x = element_markdown(),\n        axis.title.y = element_markdown())\n\n\n\n\nWhat if you do not know the function’s first derivative? You can approximate the slope of the tangent line by comparing a function’s output of each point with the output of a slightly deviated point. Here is a plot of the normal cumulative distribution function.\n\n# Small change in x\ndx &lt;- .00000001\nplot_ratio &lt;- 6\n\ntibble(x = seq(-3,3,.5),\n       y = pnorm(x),\n       tangent_slope = plot_ratio * (pnorm(x + dx) - y) / dx,\n       text_angle = atan(tangent_slope) + pi / 2,\n       degrees = text_angle * 180 / pi) %&gt;% \n  ggplot(aes(x,y)) + \n  geom_point() +\n  geom_richtext(aes(label = formatC(y, 2, format = \"f\"),\n                    vjust = angle2vjust(text_angle),\n                    hjust = angle2hjust(text_angle)),\n                label.color = NA,\n                label.padding = unit(1, \"pt\"),\n                label.margin = unit(5, \"pt\"),\n                size = 4) +\n  stat_function(fun = pnorm) + \n  theme_minimal(base_size = 16) + \n  theme(axis.title.x = element_markdown(),\n        axis.title.y = element_markdown()) +\n  coord_fixed(ratio = plot_ratio) + \n  scale_x_continuous(\"*x*\", breaks = -3:3) +\n  scale_y_continuous(\"&Phi;(*x*)\")\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{schneider2021,\n  author = {Schneider, W. Joel},\n  title = {Point Labels Perpendicular to a Curve in Ggplot2},\n  date = {2021-07-27},\n  url = {https://wjschne.github.io/posts/point-labels-perpendicular-to-a-curve-in-ggplot2},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSchneider, W. J. (2021, July 27). Point labels perpendicular to a\ncurve in ggplot2. https://wjschne.github.io/posts/point-labels-perpendicular-to-a-curve-in-ggplot2"
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "Nominal, Ordinal, Interval, and Ratio scales\n\n\n\n\n\n\n\n\nHow to visualize which values are most frequent in a distribution\n\n\n\n\n\n\n\n\nFunctions that tell us which values are more likely to occur\n\n\n\n\n\n\n\n\nAn introduction to expected value and how it is related to the concept of the mean of a variable.\n\n\n\n\n\n\n\n\nHow variance is calculated\n\n\n\n\n\n\n\n\nSum of the Reasons Variables Are Normally Normal\n\n\n\n\n\n\n\n\nAn introduction to skewness and its relationship to variability.\n\n\n\n\n\n\n\n\nAn introduction to kurtosis and how it is not just a measure of peakedness.\n\n\n\n\n\n\n\n\nAn introduction to z-scores, stanines, stens, scaled scores, T scores, and index scores\n\n\n\n\n\n\n\n\nCovariance is rarely useful by itself but is indispensable for many statistics."
  },
  {
    "objectID": "presentations.html#psychometrics-from-the-ground-up",
    "href": "presentations.html#psychometrics-from-the-ground-up",
    "title": "Presentations",
    "section": "",
    "text": "Nominal, Ordinal, Interval, and Ratio scales\n\n\n\n\n\n\n\n\nHow to visualize which values are most frequent in a distribution\n\n\n\n\n\n\n\n\nFunctions that tell us which values are more likely to occur\n\n\n\n\n\n\n\n\nAn introduction to expected value and how it is related to the concept of the mean of a variable.\n\n\n\n\n\n\n\n\nHow variance is calculated\n\n\n\n\n\n\n\n\nSum of the Reasons Variables Are Normally Normal\n\n\n\n\n\n\n\n\nAn introduction to skewness and its relationship to variability.\n\n\n\n\n\n\n\n\nAn introduction to kurtosis and how it is not just a measure of peakedness.\n\n\n\n\n\n\n\n\nAn introduction to z-scores, stanines, stens, scaled scores, T scores, and index scores\n\n\n\n\n\n\n\n\nCovariance is rarely useful by itself but is indispensable for many statistics."
  },
  {
    "objectID": "presentations.html#other-assessment-videos",
    "href": "presentations.html#other-assessment-videos",
    "title": "Presentations",
    "section": "Other Assessment Videos",
    "text": "Other Assessment Videos\n\nEmotional Intelligence and CHC Theory\nHow might emotional intelligence relate to psychometric models of intelligence?\n\n\n\n\n\n\n\nMisunderstanding Regression to the Mean\nWhat regression to the mean is and how it is often misunderstood. Examples are provided as to how it is applied to IQ and the death penalty.\n\n\n\n\n\n\n\nTaking latent variable models seriously\nApplying latent score estimates to individuals\n\n\n\n\n\n\n\nSpecific cognitive processing weaknesses are rarely full explanations for academic deficits\nIn which I confess to having had a longstanding misunderstanding about diagnosing learning disorders.\n\n\n\n\n\n\n\nTwo kinds of cognitive ability hierarchies\nSome latent variables represent “hierarchical abstractions.”\n\n\n\n\n\n\n\nA Taxonomy of Influences on Ability Tests\nSome influences are test-specific whereas others are shared across tests. Some influences are transient whereas others are stable. Some influences are relevant to the construct of interest whereas others are irrelevant.\n\n\n\n\n\n\n\nWithin-composite differences: Why measures of the same ability differ?\nThere are a number of lesser-known reasons that two tests that are intended to measure the same ability might differ substantially.\n\n\n\n\n\n\n\nWithin-composite differences: Do large subtest score differences invalidate composite scores?\nIt is often asserted that composite scores should not be interpreted when the scores that make up that composite are discrepant. I show here why this is not typically true, depending on what the composite score is used for.\n\n\n\n\n\n\n\nWriting Assessment Reports People Will Read, Understand, and Remember\nMy appearance on the School Psyched Podcast on October 20, 2019"
  },
  {
    "objectID": "presentations.html#audio-presentations",
    "href": "presentations.html#audio-presentations",
    "title": "Presentations",
    "section": "Audio Presentations",
    "text": "Audio Presentations\n\nThe evolution of cognitive assessment\nMy appearance on the Testing Psychologist Podcast on March 29, 2021"
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "R package for simulating data using standardized coefficients\nTutorial\n\n\n\n\n\n\n\n\nIn the model below, the path coefficients are standardized. You would like to simulate the variables in the model, but you do not know the disturbance and residual variances. The simstandard package can help.\n\n\n\nA standardized latent variable model\n\n\n\n\n\n\n\nAn R package for detecting unusual scores in a test profile\nTutorial\n\n\n\n\n\n\n\n\nThis package estimates how unusual a multivariate normal profile is.\n\n\n\n\n\n\nA ggplot2 extension package for creating normal violin plots\n\n\n\n\n\n\n\n\nI needed to show confidence intervals and conditional normal distributions with specific means and standard deviations. I wrote the ggnormalviolin package to make this happen.\nIt makes plots like this:\n\n\n\nExample plot made with ggnormalviolin\n\n\n\n\n\n\n\nFunctions useful for psychological evaluations\nThis package is still in a preliminary state, just like Individual Psychometrics, the book it accompanies.\n\n\n\n\n\n\n\n\n\n\n\nMulivariate Confindence Intervals\n\n\n\n\n\n\n\nA set of functions I find convenient to have readily available to me\n\n\n\n\n\n\n\n\n\n\n\nWhoa! How did you place those labels so perfectly?\n\n\n\n\n\n\n\nAn R package for making digital spirographs\nTutorial\nMy Gallery\n\n\n\n\n\n\n\n\nMaking digital spirographs is fun! I made an R package called spiro that can make animated spirographs like this one:"
  },
  {
    "objectID": "software.html#simstandard",
    "href": "software.html#simstandard",
    "title": "Software",
    "section": "",
    "text": "R package for simulating data using standardized coefficients\nTutorial\n\n\n\n\n\n\n\n\nIn the model below, the path coefficients are standardized. You would like to simulate the variables in the model, but you do not know the disturbance and residual variances. The simstandard package can help.\n\n\n\nA standardized latent variable model"
  },
  {
    "objectID": "software.html#unusualprofile",
    "href": "software.html#unusualprofile",
    "title": "Software",
    "section": "",
    "text": "An R package for detecting unusual scores in a test profile\nTutorial\n\n\n\n\n\n\n\n\nThis package estimates how unusual a multivariate normal profile is."
  },
  {
    "objectID": "software.html#ggnormalviolin",
    "href": "software.html#ggnormalviolin",
    "title": "Software",
    "section": "",
    "text": "A ggplot2 extension package for creating normal violin plots\n\n\n\n\n\n\n\n\nI needed to show confidence intervals and conditional normal distributions with specific means and standard deviations. I wrote the ggnormalviolin package to make this happen.\nIt makes plots like this:\n\n\n\nExample plot made with ggnormalviolin"
  },
  {
    "objectID": "software.html#psycheval",
    "href": "software.html#psycheval",
    "title": "Software",
    "section": "",
    "text": "Functions useful for psychological evaluations\nThis package is still in a preliminary state, just like Individual Psychometrics, the book it accompanies.\n\n\n\n\n\n\n\n\n\n\n\nMulivariate Confindence Intervals"
  },
  {
    "objectID": "software.html#wjsmisc",
    "href": "software.html#wjsmisc",
    "title": "Software",
    "section": "",
    "text": "A set of functions I find convenient to have readily available to me\n\n\n\n\n\n\n\n\n\n\n\nWhoa! How did you place those labels so perfectly?"
  },
  {
    "objectID": "software.html#spiro",
    "href": "software.html#spiro",
    "title": "Software",
    "section": "",
    "text": "An R package for making digital spirographs\nTutorial\nMy Gallery\n\n\n\n\n\n\n\n\nMaking digital spirographs is fun! I made an R package called spiro that can make animated spirographs like this one:"
  },
  {
    "objectID": "software.html#apaquarto",
    "href": "software.html#apaquarto",
    "title": "Software",
    "section": "apaquarto",
    "text": "apaquarto\nA Quarto Extension for Creating APA 7 Style Documents\nThis is a quarto article template that creates APA Style 7th Edition documents in .docx, .html. and .pdf. I made this extension for my own workflow. If it helps you, too, I am happy. The output of the template is displayed below:\n\n\nUnable to display PDF file. Download instead."
  },
  {
    "objectID": "posts/2023-07-31-making-a-custom-arrowhead-for-ggplot2-using-ggarrow/index.html",
    "href": "posts/2023-07-31-making-a-custom-arrowhead-for-ggplot2-using-ggarrow/index.html",
    "title": "Making a custom arrowhead for ggplot2 using ggarrow and arrowheadr",
    "section": "",
    "text": "Base plot for demonstrations\nlibrary(tidyverse)\n# install.packages(\"remotes\")\n# remotes::install_github(\"teunbrand/ggarrow\")\nlibrary(ggarrow)\n\nnode_radius &lt;- .2\nresection_length &lt;- .03\n\nd_node &lt;- tibble(node = c(\"A\", \"B\", \"C\"),\n       x = c(0, .5, 1),\n       y = c(0, sqrt(3) / 2, 0))\n\nd_edge &lt;- d_node |&gt; \n  mutate(theta_next = atan((y - lag(y)) / (x - lag(x))),\n         x_from = lag(x) + cos(theta_next) * (node_radius + resection_length),\n         y_from = lag(y) + sin(theta_next) * (node_radius + resection_length),\n         x_to = x + cos(theta_next + pi) * (node_radius + resection_length),\n         y_to = y + sin(theta_next + pi) * (node_radius + resection_length)) |&gt; \n  filter(!is.na(x_from))\n\np &lt;- d_edge |&gt;\n  ggplot(aes(x = x_from, y = y_from, xend = x_to, yend = y_to)) +\n  ggforce::geom_circle(aes(\n    x0 = x,\n    y0 = y,\n    r = .2,\n    fill = node\n  ),\n  data = d_node,\n  color = NA, inherit.aes = F) +\n  geom_text(aes(label = node, x = x, y = y), \n            data = d_node, \n            size = 20,\n            family = \"Roboto Condensed\",\n            inherit.aes = F) +\n  coord_fixed() +\n  theme_void() +\n  theme(legend.position = \"none\") +\n     scale_fill_viridis_d(\n       option = \"D\",\n       begin = .2,\n       end = .8,\n       alpha = .5\n     )\n\np\n\n\n\n\n\nThe default arrows in ggplot2 are perfectly serviceable. There is the open variety:\n\n\nOpen arrow code\np + geom_segment(arrow = arrow())\n\n\n\n\n\nFigure 1: The ggplot2 open arrow\n\n\n\n\nYou can specifiy which ends of the segment have arrowheads, whether the arrows are open or closed, the length of the arrow, and how sharp the arrow’s point is with the angle argument.\nI happen to prefer a longer, sharper, closed arrow:\n\n\nClosed arrow code\np + geom_segment(\n  arrow = arrow(\n    angle = 15,\n    length = unit(8, \"mm\"),\n    type = \"closed\"\n))\n\n\n\n\n\nFigure 2: The ggplot2 closed arrow\n\n\n\n\nNevertheless, I miss the variety of arrows in available in TikZ. I particularly like the latex' arrow:\n\n\nTikZ code with latex’ arrow\n\\usetikzlibrary{arrows}\n\\begin{tikzpicture}\n\\node[fill=violet!50!white, circle] (A) at (0,0) {A};\n\\node[fill=cyan!80!black, circle] (B) at (1,1.732) {B};\n\\node[fill=green!40!black!40, circle] (C) at (2,0) {C};\n\\path[-&gt;,\n    draw,\n    shorten &gt;=2pt,\n    shorten &lt;=2pt,\n    &gt;=latex',\n    thick,\n    color = black!40,\n    text = black] (A) -&gt; (B);\n    \\path[-&gt;,\n    draw,\n    shorten &gt;=2pt,\n    shorten &lt;=2pt,\n    &gt;=latex',\n    thick,\n    color = black!40,\n    text = black] (B) -&gt; (C);\n\\end{tikzpicture}\n\n\n\n\n\nFigure 3: The TikZ latex’ arrow\n\n\n\n\n\nThe ggarrow package\nIf you want more variety in drawing arrows in ggplot2, Teun van den Brand’s ggarrow package expands your limits to whatever your imagination can provide.\nThe default arrowhead is already a nice improvement:\n\n\nCode for wings arrow (i.e, stealth arrow in TikZ)\np + geom_arrow_segment(length_head = 10)\n\n\n\n\n\nFigure 4: The “wings” arrow\n\n\n\n\nYou can play around with the sharpness of the point (offset) and the sharpness of the barb (inset). You can also add feathers.\n\n\nCode for sharp barbs and feathers\np +\n  geom_arrow_segment(length_head = 4,\n                     arrow_head = arrow_head_wings(offset = 20, \n                                                   inset = 10), \n                     arrow_fins = arrow_fins_feather(), \n                     length_fins = 11)\n\n\n\n\n\nFigure 5: Sharp barbs and feathers\n\n\n\n\n\n\nCode for kite arrowhead\np +\n  geom_arrow_segment(length_head = 15,\n                     arrow_head = arrow_head_wings(offset = 22.5,\n                                                   inset = 115),\n                     arrow_fins = arrow_head_wings(offset = 22.5,\n                                                   inset = 115),\n                     length_fins = 15)\n\n\n\n\n\nFigure 6: Double-headed arrow with kite arrowhead\n\n\n\n\n\n\nCode for reverse kite arrowhead\np +\n  geom_arrow_segment(length_head = 20,\n                     arrow_head = arrow_head_wings(offset = 45,\n                                                   inset = 120))\n\n\n\n\n\nFigure 7: Reverse kite arrowhead\n\n\n\n\nIf the arrow goes too far, you can pull it back with the resect arguments.\n\n\nCode for resecting an arrowhead\np +\n  geom_arrow_segment(length_head = 6,\n                     arrow_head = arrow_head_wings(offset = 120,\n                                                   inset = 35),\n                     resect_head = 2)\n\n\n\n\n\nFigure 8: Demonstration of resecting arrowheads\n\n\n\n\nThere is much, much more that can be done. See ggarrow’s arrow ornament vignette for more options.\n\n\nCustom Arrowheads\nNot only does ggarrow offert great arrow geoms with excellent features like resection, one can create any custom arrowhead or feather that can be made with a single polygon.\nThe polygon generally falls between -1 and 1 on x and y, though you can plot outside those limits. In most cases, the point is at (0,1), and the line ends at (0,0):\n\n\nCode\npar(pty = \"s\")\nx &lt;- c(0,1)\ny &lt;- c(0,0)\nplot(x , y, xlim = c(-1, 1), ylim = c(-1, 1))\nrect(-1,-.1,0,.1)\ntext(-.5,0, labels = \"Line\")\ntext(1,0, labels = \"Arrow Point\", adj = 1.2)\npolygon(ggarrow::arrow_head_wings() |&gt; `colnames&lt;-`(c(\"a\", \"b\")))\n\n\n\n\n\nFigure 9: Grid for custom arrowheads\n\n\n\n\nThe polygon you create should be be a 2-column matrix with named columns (e.g., x and y). Here I make a elliptical arrowhead.\n\n\nCode\nmake_ellipse &lt;- function(a = 1, b = .5){\n  t &lt;- seq(0,2*pi, length.out = 361)\n  cbind(x = a * cos(t), y = b * sin(t)) \n}\n\np +\n  geom_arrow_segment(length_head = 5,\n                     arrow_head = make_ellipse())\n\n\n\n\n\nFigure 10: Make ellipse\n\n\n\n\n\n\nThe arrowheadr package\nI made the arrowheadr package to make custom arrowheads quickly. Some of them are admittedly silly. However, it is now easy to make my favorite kind of arrow in ggplot2:\n\n\nCode\nlibrary(arrowheadr)\n\np + \n  geom_arrow_segment(length_head = 5,\n                     arrow_head = arrow_head_latex())\n\n\n\n\n\nMimicking the latex prime arrowhead\n\n\n\n\nMore examples:\nA catenary:\n\n\nCode\nstlouis &lt;- arrow_head_catenary(base_width = .25, thickness = .15)\n\np + \n  geom_arrow_segment(length_head = 5,\n                     arrow_head = stlouis)\n\n\n\n\n\nFigure 11: The Gateway Arch in St. Louis is shaped like a catenary, not a parabola.\n\n\n\n\nThe Cauchy function:\n\n\nCode\np + \n  geom_arrow_segment(length_head = 5,\n                     arrow_head = arrow_head_function(dt, df = 1))\n\n\n\n\n\nFigure 12: Any function can make an arrowhead.\n\n\n\n\nRazors:\n\n\nCode\nrazors &lt;- c(1,0,\n  0,.5,\n  -.35,.25,\n  -.35, .21,\n  0,.35,\n  .90,0\n  ) |&gt; \n  v2matrix() |&gt; \n  reflecter() \n\np + \n  geom_arrow_segment(length_head = 10,\n                     arrow_head = razors)\n\n\n\n\n\nFigure 13: The reflecter function takes a set of points and makes them symmetrical.\n\n\n\n\nA candle flame:\n\n\nCode\ncandleflame &lt;- arrow_head_wittgenstein_rod(\n  fixed_point = c(-2.75, 0),\n  rod_length = 3.75,\n  nudge = c(1, 0),\n  rescale = .95\n)\n\np + \n  geom_arrow_segment(length_head = 12,\n                     arrow_head = candleflame)\n\n\n\n\n\nFigure 14: Wittgensteain’s rod makes some nice shapes\n\n\n\n\nUsing bezier curve control points:\n\n\nCode\ncurved_arrowhead &lt;- arrow_head_bezier(list(\n  c(1,  0,\n    .5, .5,\n    .2, .5),\n  c(.2, .5,\n    .2, .1,\n    -.1, .25,\n    -.3, .25),\n  c(-.3, .25,\n    0, 0,\n    -.3, -.25),\n  c(-.3, -.25,\n    -.1, -.25,\n    .2,  -.1,\n    .2, -.5),\n  c(.2, -.5,\n    .5, -.5,\n    1,  0)\n))\n\np + \n  geom_arrow_segment(length_head = 8,\n                     arrow_head = curved_arrowhead)\n\n\n\n\n\nFigure 15: Bezier curves can make almost anything.\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{schneider2023,\n  author = {Schneider, W. Joel},\n  title = {Making a Custom Arrowhead for Ggplot2 Using Ggarrow and\n    Arrowheadr},\n  date = {2023-07-31},\n  url = {https://wjschne.github.io/posts/2023-07-31-making-a-custom-arrowhead-for-ggplot2-using-ggarrow},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSchneider, W. J. (2023, July 31). Making a custom arrowhead for\nggplot2 using ggarrow and arrowheadr. https://wjschne.github.io/posts/2023-07-31-making-a-custom-arrowhead-for-ggplot2-using-ggarrow"
  },
  {
    "objectID": "posts/2023-07-31-making-a-custom-arrowhead-for-ggplot2-using-ggarrow/index.html#deltoids",
    "href": "posts/2023-07-31-making-a-custom-arrowhead-for-ggplot2-using-ggarrow/index.html#deltoids",
    "title": "Making a custom arrowhead for ggplot2 using ggarrow",
    "section": "Deltoids",
    "text": "Deltoids\nMy first attempt to recreate the latex' arrowhead started with a deltoid that I stretched.\n\n\nCode\ndeltoid &lt;- function(r = 2,\n                    R = 1,\n                    d = r + .6,\n                    windings = r,\n                    xratio = 1,\n                    yratio = 0.5,\n                    rotation = pi,\n                    x_nudge = 0,\n                    y_nudge = 0,\n                    n = 45) {\n  \n\n\n  theta &lt;- seq(0, windings * 2 * pi, length.out = n * windings)\n  x &lt;- (R - r) * cos(theta) + d * cos(theta * (R - r) / r)\n  y &lt;- (R - r) * sin(theta) + d * sin(theta * (R - r) / r)\n\n  dmax &lt;- max(sqrt(x ^ 2 + y ^ 2))\n  x &lt;- x / dmax\n  y &lt;- y / dmax\n\n  k &lt;- length(x)\n  nudger &lt;- cbind(x = rep(x_nudge, k), y = rep(y_nudge, k))\n\n  rotater &lt;- matrix(c(cos(rotation), -sin(rotation),\n                      sin(rotation), cos(rotation)), nrow = 2, ncol = 2)\n\n  xy &lt;- cbind(x = x * xratio,\n              y = y * yratio) %*% rotater  + nudger\n  colnames(xy) &lt;- c(\"x\", \"y\")\n  xy\n\n}\n\np + geom_arrow_segment(\n  linewidth = 2,\n  arrow_head = deltoid(),\n  length_head = 6,\n  color = \"gray\"\n) \n\n\n\n\n\nCode\np + geom_arrow_segment(\n  linewidth = 2,\n  arrow_head = deltoid(xratio = .5, yratio = .25, x_nudge = .37),\n  length_head = 10,\n  color = \"gray\"\n) \n\n\n\n\n\nCode\ndeltoid2 &lt;- WJSmisc::myarrowhead(xratio = 1, yratio = 1, d = 2.3)\ndeltoid2[, 1] &lt;-  (deltoid2[, 1] + .6) / 1.6\ndeltoid2[, 2] &lt;-  deltoid2[, 2] / (1.6 * 2)\n\np + geom_arrow_segment(\n  aes(\n    x = x_from,\n    xend = x_to,\n    y = y_from,\n    yend = y_to\n  ),\n  linewidth = 2,\n  arrow_head = deltoid2,\n  length_head = 10,\n  color = \"gray\"\n) \n\n\n\n\n\n\n\nCode\nlibrary(ggarrow)\nd_star_fleet &lt;- svgparser::read_svg(r'(https://upload.wikimedia.org/wikipedia/commons/9/9a/Emblem.svg)', obj_type = \"data.frame\")  \n  \n\narrowhead_starfleet &lt;- d_star_fleet |&gt; \n  select(x, y) |&gt; \n  mutate(\n    x = -x,\n    aspect_ratio = (max(y) - min(y)) / (max(x) - min(x)),\n    x = (scales::rescale(x) * 2 - 1) / ifelse(aspect_ratio &lt; 1, 1, aspect_ratio),\n    y = (scales::rescale(y) * 2 - 1) / ifelse(aspect_ratio &lt; 1, aspect_ratio, 1)) |&gt; \n  select(x, y) |&gt; \n  as.matrix() |&gt; \n  WJSmisc::rotate2dmatrix(pi / 2) |&gt; \n  `colnames&lt;-`(c(\"x\",\"y\"))\n\n\n\n\np + geom_arrow_segment(\n  arrow_head = arrowhead_starfleet,\n  length_head = 5,\n  linewidth = 2,\n  color = \"gray\"\n) \n\n\n\n\n\nFigure 9: Jesperhansen1972, CC BY-SA 3.0 https://creativecommons.org/licenses/by-sa/3.0, via Wikimedia Commons https://upload.wikimedia.org/wikipedia/commons/9/9a/Emblem.svg\n\n\n\n\n\n\nCode\narrowhead_spear &lt;-\n  svgparser::read_svg(\"spear.svg\", obj_type = \"data.frame\") |&gt;\n  filter(idx &gt; 2) |&gt;\n  select(idx, x, y) |&gt;\n  mutate(maxdist = max(sqrt(x ^ 2 + y ^ 2)),\n         x = x / maxdist,\n         y = y / maxdist) |&gt;\n  select(idx, x, y)\n\narrowhead_spear[, c(\"x\", \"y\")] &lt;-\n  arrowhead_spear[, c(\"x\", \"y\")] |&gt; as.matrix() |&gt; WJSmisc::rotate2dmatrix(-2 * pi / 8)\n\narrowhead_spear &lt;- arrowhead_spear |&gt;\n  mutate(x = (x - .5) * 2,\n         y = y * 2) |&gt;\n  select(x, y) |&gt;\n  mutate(y = scale(y, scale = F)) |&gt;\n  as.matrix()\n\n\n\n\n\np + geom_arrow_segment(\n  arrow_head = arrowhead_spear ,\n  length_head = 10,\n  linewidth = 2,\n  color = \"gray\"\n)\n\n\n\n\n\nFigure 10: License: CC Attribution. Made by game-icons.net: https://game-icons.net\n\n\n\n\n\n\nCode\nspade &lt;- function() {\n  # Parametric equation for heart\n  t &lt;- seq(0, 2 * pi, length.out = 361)\n  heart_x &lt;- 16 * sin(t) ^ 3\n  heart_y &lt;-\n    (13 * cos(t) - 5 * cos(2 * t) - 2 * cos(3 * t) - cos(4 * t)) * 1.2\n  \n  maxdist &lt;- max(sqrt(heart_x ^ 2 + heart_y ^ 2))\n  \n  heart_x &lt;- heart_x / maxdist\n  heart_y &lt;- -heart_y / maxdist\n  \n  t_x &lt;- heart_x[heart_y &lt; 0 & abs(heart_x) &lt; .6]\n  \n  \n  df &lt;- 1\n  t_y = dt(t_x * 10, df) / dt(0, df)\n  t_y &lt;- t_y - 1 - min(t_y)\n  \n  threshold &lt;- .09\n  \n  t_y &lt;-  t_y[abs(t_x) &gt; threshold]\n  t_x &lt;- t_x[abs(t_x) &gt; threshold]\n  \n  heart_x1 &lt;- heart_x[abs(heart_x) &gt; threshold | heart_y &gt; 0]\n  heart_y1 &lt;- heart_y[abs(heart_x) &gt; threshold | heart_y &gt; 0]\n  \n  # polygon(heart_x, heart_y,  col = \"#000000\", border = NA)\n  # polygon(t_x, t_y, xlim = c(-12,12), ylim = c(-1, 1), col = \"black\", border = NA)\n  \n  spade_x &lt;- c(heart_x1, -t_x)\n  spade_y &lt;- c(heart_y1, t_y)\n  \n  spade_y &lt;- spade_y * .55 + .45\n  spade_x &lt;- spade_x * .55\n  # polygon(spade_x, spade_y,  col = \"black\", border = NA)\n  cbind(x = spade_y, y = spade_x)\n  \n}\n\n\np + geom_arrow_segment(\n  linewidth = 2,\n  arrow_head = spade(),\n  length_head = 8,\n  color = \"gray\"\n) \n\n\n\n\n\n\n\nCode\n# Jean Marie (https://math.stackexchange.com/users/305862/jean-marie), Calculate third point of triangle from two points and angles, URL (version: 2020-12-01): https://math.stackexchange.com/q/1725796\nharpoon &lt;- function(point_angle = 20, barb_angle = 30, x0 = 0, y0 = 0,x1 = 1, y1 = 0, nudge_x = 0, nudge_y = -.1) {\n  theta_1 &lt;- pi * point_angle / 180\n  theta_2 &lt;- pi * barb_angle / 180\n  theta_0 &lt;- pi - (theta_1 + theta_2)\n  \n  theta_11 &lt;- atan2(y1 - y0, x1 - x0)\n  theta_00 &lt;- theta_0 + theta_11\n  \n  a_2 &lt;- norm(c(x1 - x0, y1 - y0), type = \"2\")\n  a_1 &lt;- a_2 * sin(theta_1) / sin(theta_2)\n  x2 &lt;- cos(theta_00) * a_1 + x0\n  y2 &lt;- sin(theta_00) * a_1 + y0\n  \n  \n  tibble(x = c(x0, x1, x2),\n         y = c(y0, y1, y2)) |&gt; \n    mutate(x = x + nudge_x,\n           y = y + nudge_y) |&gt; \n    as.matrix() \n}\n\np + geom_arrow_segment(\n  linewidth = 2,\n  arrow_head = harpoon(nudge_y = -.068),\n  length_head = 8,\n  color = \"gray\"\n) \n\n\n\n\n\n\n\nCode\nlatexarrow &lt;- function(\n    barbs = TRUE, \n    side_curve = TRUE, \n    point = c(1, 0),\n    p_sidecurve1 = c(7 / 12, 1 / 12),\n    p_sidecurve2 = c(-1 / 6, 1 / 4),\n    p_barb = c(-2 / 3, 5 / 8),\n    p_undercurve = c(-1 / 4, 1 / 6),\n    plot = FALSE) {\n      if (!side_curve) {\n      p_sidecurve1 &lt;- NULL\n      p_sidecurve2 &lt;- NULL\n    }\n  \n  if (!barbs) {\n    p_undercurve &lt;- NULL\n  } \n  \n    controls &lt;-list(\n    topside = c(\n      point,\n      p_sidecurve1,\n      p_sidecurve2,\n      p_barb),\n    leftside = c(\n      p_barb,\n      p_undercurve,\n      p_undercurve * c(1, -1),\n      p_barb * c(1, -1)),\n    bottomside = c(\n      p_barb * c(1, -1),\n      p_sidecurve2 * c(1, -1),\n      p_sidecurve1 * c(1, -1),\n      point)) |&gt; \n    lapply(\\(x) matrix(x, ncol = 2, byrow = TRUE, dimnames = list(NULL, c(\"x\", \"y\"))))\n  \n\n  \n\n  \n  \n  xy &lt;- map(controls, \\(x) {\n    if (nrow(x) &gt; 2) bezier::bezier(t = seq(0,1, .01), p = x) else x\n  }) |&gt; \n    do.call(what = rbind) |&gt; \n    `colnames&lt;-`(c(\"x\", \"y\"))\n    \nif (plot) {\n  par(pty = \"s\", pch = 16)\n  plot(xy, type = \"n\", xlim = c(-1,1), ylim = c(-1,1))\n  polygon(xy, border = NA, col = \"gray80\")\n  \n  walk(controls, points, col = \"firebrick\")\n  walk(controls, lines, col = \"firebrick\")\n  # points(rbind(point, p_barb), col = \"red\")\n  # if(side_curve) {\n  #   points(rbind(p_sidecurve1, p_sidecurve2), col = \"red\")\n  #   lines(rbind(point, p_sidecurve1, p_sidecurve2, p_barb), col = \"red\")\n  #   }\n  # if(barbs) {\n  #   points(rbind(p_undercurve, p_undercurve * c(1,-1)), col = \"dodgerblue\")\n  #   lines(rbind(p_barb, \n  #               p_undercurve, \n  #               p_undercurve * c(1,-1), p_barb * c(1,-1)), col = \"dodgerblue\")\n  #   }\n  \n}\n  \n  xy \n\n}\n\n    latexarrow(plot = TRUE, p_sidecurve = c(.4,.2), p_sidecurve2 = c(-.2,1), p_undercurve = c(.7,-1))\n\n\n\n\n\n                 x            y\n  [1,]  1.00000000  0.000000000\n  [2,]  0.98200013  0.006178225\n  [3,]  0.96400107  0.012705800\n  [4,]  0.94600360  0.019572075\n  [5,]  0.92800853  0.026766400\n  [6,]  0.91001667  0.034278125\n  [7,]  0.89202880  0.042096600\n  [8,]  0.87404573  0.050211175\n  [9,]  0.85606827  0.058611200\n [10,]  0.83809720  0.067286025\n [11,]  0.82013333  0.076225000\n [12,]  0.80217747  0.085417475\n [13,]  0.78423040  0.094852800\n [14,]  0.76629293  0.104520325\n [15,]  0.74836587  0.114409400\n [16,]  0.73045000  0.124509375\n [17,]  0.71254613  0.134809600\n [18,]  0.69465507  0.145299425\n [19,]  0.67677760  0.155968200\n [20,]  0.65891453  0.166805275\n [21,]  0.64106667  0.177800000\n [22,]  0.62323480  0.188941725\n [23,]  0.60541973  0.200219800\n [24,]  0.58762227  0.211623575\n [25,]  0.56984320  0.223142400\n [26,]  0.55208333  0.234765625\n [27,]  0.53434347  0.246482600\n [28,]  0.51662440  0.258282675\n [29,]  0.49892693  0.270155200\n [30,]  0.48125187  0.282089525\n [31,]  0.46360000  0.294075000\n [32,]  0.44597213  0.306100975\n [33,]  0.42836907  0.318156800\n [34,]  0.41079160  0.330231825\n [35,]  0.39324053  0.342315400\n [36,]  0.37571667  0.354396875\n [37,]  0.35822080  0.366465600\n [38,]  0.34075373  0.378510925\n [39,]  0.32331627  0.390522200\n [40,]  0.30590920  0.402488775\n [41,]  0.28853333  0.414400000\n [42,]  0.27118947  0.426245225\n [43,]  0.25387840  0.438013800\n [44,]  0.23660093  0.449695075\n [45,]  0.21935787  0.461278400\n [46,]  0.20215000  0.472753125\n [47,]  0.18497813  0.484108600\n [48,]  0.16784307  0.495334175\n [49,]  0.15074560  0.506419200\n [50,]  0.13368653  0.517353025\n [51,]  0.11666667  0.528125000\n [52,]  0.09968680  0.538724475\n [53,]  0.08274773  0.549140800\n [54,]  0.06585027  0.559363325\n [55,]  0.04899520  0.569381400\n [56,]  0.03218333  0.579184375\n [57,]  0.01541547  0.588761600\n [58,] -0.00130760  0.598102425\n [59,] -0.01798507  0.607196200\n [60,] -0.03461613  0.616032275\n [61,] -0.05120000  0.624600000\n [62,] -0.06773587  0.632888725\n [63,] -0.08422293  0.640887800\n [64,] -0.10066040  0.648586575\n [65,] -0.11704747  0.655974400\n [66,] -0.13338333  0.663040625\n [67,] -0.14966720  0.669774600\n [68,] -0.16589827  0.676165675\n [69,] -0.18207573  0.682203200\n [70,] -0.19819880  0.687876525\n [71,] -0.21426667  0.693175000\n [72,] -0.23027853  0.698087975\n [73,] -0.24623360  0.702604800\n [74,] -0.26213107  0.706714825\n [75,] -0.27797013  0.710407400\n [76,] -0.29375000  0.713671875\n [77,] -0.30946987  0.716497600\n [78,] -0.32512893  0.718873925\n [79,] -0.34072640  0.720790200\n [80,] -0.35626147  0.722235775\n [81,] -0.37173333  0.723200000\n [82,] -0.38714120  0.723672225\n [83,] -0.40248427  0.723641800\n [84,] -0.41776173  0.723098075\n [85,] -0.43297280  0.722030400\n [86,] -0.44811667  0.720428125\n [87,] -0.46319253  0.718280600\n [88,] -0.47819960  0.715577175\n [89,] -0.49313707  0.712307200\n [90,] -0.50800413  0.708460025\n [91,] -0.52280000  0.704025000\n [92,] -0.53752387  0.698991475\n [93,] -0.55217493  0.693348800\n [94,] -0.56675240  0.687086325\n [95,] -0.58125547  0.680193400\n [96,] -0.59568333  0.672659375\n [97,] -0.61003520  0.664473600\n [98,] -0.62431027  0.655625425\n [99,] -0.63850773  0.646104200\n[100,] -0.65262680  0.635899275\n[101,] -0.66666667  0.625000000\n[102,] -0.66666667  0.625000000\n[103,] -0.62607667  0.577330250\n[104,] -0.58630667  0.531792000\n[105,] -0.54735667  0.488341750\n[106,] -0.50922667  0.446936000\n[107,] -0.47191667  0.407531250\n[108,] -0.43542667  0.370084000\n[109,] -0.39975667  0.334550750\n[110,] -0.36490667  0.300888000\n[111,] -0.33087667  0.269052250\n[112,] -0.29766667  0.239000000\n[113,] -0.26527667  0.210687750\n[114,] -0.23370667  0.184072000\n[115,] -0.20295667  0.159109250\n[116,] -0.17302667  0.135756000\n[117,] -0.14391667  0.113968750\n[118,] -0.11562667  0.093704000\n[119,] -0.08815667  0.074918250\n[120,] -0.06150667  0.057568000\n[121,] -0.03567667  0.041609750\n[122,] -0.01066667  0.027000000\n[123,]  0.01352333  0.013695250\n[124,]  0.03689333  0.001652000\n[125,]  0.05944333 -0.009173250\n[126,]  0.08117333 -0.018824000\n[127,]  0.10208333 -0.027343750\n[128,]  0.12217333 -0.034776000\n[129,]  0.14144333 -0.041164250\n[130,]  0.15989333 -0.046552000\n[131,]  0.17752333 -0.050982750\n[132,]  0.19433333 -0.054500000\n[133,]  0.21032333 -0.057147250\n[134,]  0.22549333 -0.058968000\n[135,]  0.23984333 -0.060005750\n[136,]  0.25337333 -0.060304000\n[137,]  0.26608333 -0.059906250\n[138,]  0.27797333 -0.058856000\n[139,]  0.28904333 -0.057196750\n[140,]  0.29929333 -0.054972000\n[141,]  0.30872333 -0.052225250\n[142,]  0.31733333 -0.049000000\n[143,]  0.32512333 -0.045339750\n[144,]  0.33209333 -0.041288000\n[145,]  0.33824333 -0.036888250\n[146,]  0.34357333 -0.032184000\n[147,]  0.34808333 -0.027218750\n[148,]  0.35177333 -0.022036000\n[149,]  0.35464333 -0.016679250\n[150,]  0.35669333 -0.011192000\n[151,]  0.35792333 -0.005617750\n[152,]  0.35833333  0.000000000\n[153,]  0.35792333  0.005617750\n[154,]  0.35669333  0.011192000\n[155,]  0.35464333  0.016679250\n[156,]  0.35177333  0.022036000\n[157,]  0.34808333  0.027218750\n[158,]  0.34357333  0.032184000\n[159,]  0.33824333  0.036888250\n[160,]  0.33209333  0.041288000\n[161,]  0.32512333  0.045339750\n[162,]  0.31733333  0.049000000\n[163,]  0.30872333  0.052225250\n[164,]  0.29929333  0.054972000\n[165,]  0.28904333  0.057196750\n[166,]  0.27797333  0.058856000\n[167,]  0.26608333  0.059906250\n[168,]  0.25337333  0.060304000\n[169,]  0.23984333  0.060005750\n[170,]  0.22549333  0.058968000\n[171,]  0.21032333  0.057147250\n[172,]  0.19433333  0.054500000\n[173,]  0.17752333  0.050982750\n[174,]  0.15989333  0.046552000\n[175,]  0.14144333  0.041164250\n[176,]  0.12217333  0.034776000\n[177,]  0.10208333  0.027343750\n[178,]  0.08117333  0.018824000\n[179,]  0.05944333  0.009173250\n[180,]  0.03689333 -0.001652000\n[181,]  0.01352333 -0.013695250\n[182,] -0.01066667 -0.027000000\n[183,] -0.03567667 -0.041609750\n[184,] -0.06150667 -0.057568000\n[185,] -0.08815667 -0.074918250\n[186,] -0.11562667 -0.093704000\n[187,] -0.14391667 -0.113968750\n[188,] -0.17302667 -0.135756000\n[189,] -0.20295667 -0.159109250\n[190,] -0.23370667 -0.184072000\n[191,] -0.26527667 -0.210687750\n[192,] -0.29766667 -0.239000000\n[193,] -0.33087667 -0.269052250\n[194,] -0.36490667 -0.300888000\n[195,] -0.39975667 -0.334550750\n[196,] -0.43542667 -0.370084000\n[197,] -0.47191667 -0.407531250\n[198,] -0.50922667 -0.446936000\n[199,] -0.54735667 -0.488341750\n[200,] -0.58630667 -0.531792000\n[201,] -0.62607667 -0.577330250\n[202,] -0.66666667 -0.625000000\n[203,] -0.66666667 -0.625000000\n[204,] -0.65262680 -0.635899275\n[205,] -0.63850773 -0.646104200\n[206,] -0.62431027 -0.655625425\n[207,] -0.61003520 -0.664473600\n[208,] -0.59568333 -0.672659375\n[209,] -0.58125547 -0.680193400\n[210,] -0.56675240 -0.687086325\n[211,] -0.55217493 -0.693348800\n[212,] -0.53752387 -0.698991475\n[213,] -0.52280000 -0.704025000\n[214,] -0.50800413 -0.708460025\n[215,] -0.49313707 -0.712307200\n[216,] -0.47819960 -0.715577175\n[217,] -0.46319253 -0.718280600\n[218,] -0.44811667 -0.720428125\n[219,] -0.43297280 -0.722030400\n[220,] -0.41776173 -0.723098075\n[221,] -0.40248427 -0.723641800\n[222,] -0.38714120 -0.723672225\n[223,] -0.37173333 -0.723200000\n[224,] -0.35626147 -0.722235775\n[225,] -0.34072640 -0.720790200\n[226,] -0.32512893 -0.718873925\n[227,] -0.30946987 -0.716497600\n[228,] -0.29375000 -0.713671875\n[229,] -0.27797013 -0.710407400\n[230,] -0.26213107 -0.706714825\n[231,] -0.24623360 -0.702604800\n[232,] -0.23027853 -0.698087975\n[233,] -0.21426667 -0.693175000\n[234,] -0.19819880 -0.687876525\n[235,] -0.18207573 -0.682203200\n[236,] -0.16589827 -0.676165675\n[237,] -0.14966720 -0.669774600\n[238,] -0.13338333 -0.663040625\n[239,] -0.11704747 -0.655974400\n[240,] -0.10066040 -0.648586575\n[241,] -0.08422293 -0.640887800\n[242,] -0.06773587 -0.632888725\n[243,] -0.05120000 -0.624600000\n[244,] -0.03461613 -0.616032275\n[245,] -0.01798507 -0.607196200\n[246,] -0.00130760 -0.598102425\n[247,]  0.01541547 -0.588761600\n[248,]  0.03218333 -0.579184375\n[249,]  0.04899520 -0.569381400\n[250,]  0.06585027 -0.559363325\n[251,]  0.08274773 -0.549140800\n[252,]  0.09968680 -0.538724475\n[253,]  0.11666667 -0.528125000\n[254,]  0.13368653 -0.517353025\n[255,]  0.15074560 -0.506419200\n[256,]  0.16784307 -0.495334175\n[257,]  0.18497813 -0.484108600\n[258,]  0.20215000 -0.472753125\n[259,]  0.21935787 -0.461278400\n[260,]  0.23660093 -0.449695075\n[261,]  0.25387840 -0.438013800\n[262,]  0.27118947 -0.426245225\n[263,]  0.28853333 -0.414400000\n[264,]  0.30590920 -0.402488775\n[265,]  0.32331627 -0.390522200\n[266,]  0.34075373 -0.378510925\n[267,]  0.35822080 -0.366465600\n[268,]  0.37571667 -0.354396875\n[269,]  0.39324053 -0.342315400\n[270,]  0.41079160 -0.330231825\n[271,]  0.42836907 -0.318156800\n[272,]  0.44597213 -0.306100975\n[273,]  0.46360000 -0.294075000\n[274,]  0.48125187 -0.282089525\n[275,]  0.49892693 -0.270155200\n[276,]  0.51662440 -0.258282675\n[277,]  0.53434347 -0.246482600\n[278,]  0.55208333 -0.234765625\n[279,]  0.56984320 -0.223142400\n[280,]  0.58762227 -0.211623575\n[281,]  0.60541973 -0.200219800\n[282,]  0.62323480 -0.188941725\n[283,]  0.64106667 -0.177800000\n[284,]  0.65891453 -0.166805275\n[285,]  0.67677760 -0.155968200\n[286,]  0.69465507 -0.145299425\n[287,]  0.71254613 -0.134809600\n[288,]  0.73045000 -0.124509375\n[289,]  0.74836587 -0.114409400\n[290,]  0.76629293 -0.104520325\n[291,]  0.78423040 -0.094852800\n[292,]  0.80217747 -0.085417475\n[293,]  0.82013333 -0.076225000\n[294,]  0.83809720 -0.067286025\n[295,]  0.85606827 -0.058611200\n[296,]  0.87404573 -0.050211175\n[297,]  0.89202880 -0.042096600\n[298,]  0.91001667 -0.034278125\n[299,]  0.92800853 -0.026766400\n[300,]  0.94600360 -0.019572075\n[301,]  0.96400107 -0.012705800\n[302,]  0.98200013 -0.006178225\n[303,]  1.00000000  0.000000000\n\n\nCode\n# p + geom_arrow_segment(\n#   linewidth = 2,\n#   arrow_head = latexarrow(barbs = T, side_curve = T),\n#   length_head = 8,\n#   color = \"gray\"\n# ) \n\n\n\n\nCode\nd_controls &lt;- list(c(1, 0,\n                     .9, .1,\n                     .5, .3,\n                     -.2, .3),\n                   c(-.2, .3,\n                     -.2, .1,\n                     -.5, .1),\n                   c(-.5, -.1,\n                     -.2, -.1,\n                     -.2, -.3),\n                   c(-.2, -.3,\n                     .5, -.3,\n                     .9, -.1,\n                     1, 0)) |&gt; \n  map(\\(x) matrix(x, ncol = 2, byrow = T, dimnames = list(NULL, c(\"x\", \"y\"))))\n\n\nlong_spear &lt;-\n  map(d_controls, \\(x) bezier::bezier(seq(0, 1, .01), p = x)) |&gt;\n  do.call(what = rbind) |&gt;\n  `colnames&lt;-`(c(\"x\", \"y\"))\n\n\n\n\nCode\nwittgenstein_rod &lt;- function(fixed_point, rod_length = 3, nudge_x = 0, rescale = 1) {\n  t &lt;- seq(0,2*pi, length.out = 361)\n  cx &lt;- cos(t)\n  cy &lt;- sin(t)\n  fpx &lt;- fixed_point[1]\n  fpy &lt;- fixed_point[2]\n  d &lt;- sqrt((cx - fpx) ^ 2 + (cy - fpy) ^ 2)\n  x &lt;- ((fpx - cx) / d) * rod_length  + cx\n  y &lt;- ((fpy - cy) / d) * rod_length + cy\n  xy &lt;- cbind(x = x - fpx, y = y - fpy)\n  maxdist &lt;- sqrt(max(apply(xy ^ 2, 1, sum)))\n  xy &lt;- rescale * xy / maxdist\n  xy[,1] &lt;- xy[,1] + nudge_x\n  xy\n}\n\n\n\n\nCode\nupper &lt;- c(1,0,\n  0,.5,\n  -.35,.25,\n  -.35, .21,\n  0,.35,\n  .90,0\n  ) |&gt; \n  matrix(ncol = 2, byrow = T) \n\nlower &lt;- upper[seq(nrow(upper),1),]\nlower[,2] &lt;- -1 * lower[,2] \n\nrazors &lt;- rbind(upper, lower) |&gt; `colnames&lt;-`(c(\"x\", \"y\"))\n\nmountain &lt;- c(.5,0,\n              -.35,.5,\n              -.35, .35,\n              .4, 0,\n              -.35,-.35,\n              -.35, -.5,\n              .5,0) |&gt; \n  matrix(ncol = 2, byrow = T) |&gt; \n  `colnames&lt;-`(c(\"x\", \"y\"))\n\n\n\n\nCode\na &lt;- 68.7672\n\ny &lt;- seq(-2.1 * a, 2.1 * a, length.out = 1001)\nx &lt;- -1.6 * a * cosh(y / a) + 350\nmaxdist &lt;- max(sqrt(x ^ 2 + y ^ 2))\nx &lt;- x / maxdist\ny &lt;- y / maxdist\n\nstlouis &lt;- rbind(cbind(x, y * 1.1), \n      cbind(x[x &gt; min(x) + .15] - .15, y[x &gt; min(x) + .15] * -.8)) |&gt; \n  `colnames&lt;-`(c(\"x\", \"y\"))\n\n# stlouis &lt;- stlouis[stlouis[,1] &gt;= min(x)-.001, ]\n\n\n\n\nCode\nnode_radius &lt;- .2\nresection_length &lt;- .03\n\nd_node &lt;- tibble(node = c(\"A\", \"B\"),\n       x = c(0, 0),\n       y = c(0, 1))\n\nd_edge &lt;- d_node |&gt; \n  mutate(theta_next = atan((y - lag(y)) / (x - lag(x))),\n         x_from = lag(x) + cos(theta_next) * (node_radius + resection_length),\n         y_from = lag(y) + sin(theta_next) * (node_radius + resection_length),\n         x_to = x + cos(theta_next + pi) * (node_radius + resection_length),\n         y_to = y + sin(theta_next + pi) * (node_radius + resection_length)) |&gt; \n  filter(!is.na(x_from))\n\nd_edge |&gt; \n  crossing(tibble(arrowtype = c(\"open\", \"closed\",\"wings\",\"kite\",  \"deltoid\", \"deltoid2\", \"barb\", \"latex\", \"latex'\", \"ellipse\", \"flame\", \"razors\", \"St. Louis\", \"harpoon\", \"starfleet\", \"spade\", \"spear\", \"spear2\")) |&gt; mutate(\n    arrowtype = fct_inorder(arrowtype)\n  )) |&gt; \nggplot(aes(x = x_from, y = y_from, xend = x_to, yend = y_to)) +\n  ggforce::geom_circle(aes(\n    x0 = x,\n    y0 = y,\n    r = node_radius,\n    fill = node,\n  ), color = NA, data = d_node, inherit.aes = F) +\n  # geom_text(aes(label = node), size = 15, color = \"gray45\") +\n  coord_equal() +\n  theme_light(base_size = 14) +\n  facet_wrap(vars(arrowtype), nrow = 2) +\n  theme(legend.position = \"none\", \n        panel.grid = element_blank()) + \n  scale_x_continuous(NULL, breaks = NULL) + \n  scale_y_continuous(NULL, breaks = NULL) +\n  scale_fill_viridis_d(alpha = .3, begin = .2, end = .6) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"open\"),\n    arrow_head = arrow_head_line(angle = 20),\n    length_head = 8\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"closed\"),\n    arrow_head = arrow_head_wings(20,70),\n    length_head = 8\n  )  +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"wings\"),\n    length_head = 6.5\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"deltoid\"),\n    arrow_head = deltoid,\n    length_head = 6.5\n  ) +\n    geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"deltoid2\"),\n    arrow_head = deltoid2,\n    length_head = 6.5 * 1.6\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"starfleet\"),\n    arrow_head = arrowhead_starfleet,\n    length_head = 5\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"harpoon\"),\n    arrow_head = harpoon(nudge_y = -.06),\n    length_head = unit(18, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"spade\"),\n    arrow_head = spade(),\n    length_head = unit(20, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"kite\"),\n    arrow_head = arrow_head_wings(inset = 120),\n    length_head = unit(25, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"latex\"),\n    arrow_head = latexarrow(barbs = FALSE),\n    length_head = unit(13, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"latex'\"),\n    arrow_head = latexarrow(),\n    length_head = unit(13, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"barb\"),\n    arrow_head = latexarrow(side_curve = F),\n    length_head = unit(11, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"spear2\"),\n    arrow_head = arrowhead_spear,\n    length_head = unit(25, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"spear\"),\n    arrow_head = long_spear,\n    length_head = unit(15, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"flame\"),\n    arrow_head = wittgenstein_rod(c(-2.75, 0), 3.75, nudge_x = 1, 1.3),\n    length_head = unit(15, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"razors\"),\n    arrow_head = razors,\n    mid_place = 1.05,\n    length_head = unit(15, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"St. Louis\"),\n    arrow_head = stlouis,\n    length_head = unit(12, \"pt\")\n  ) +\n  geom_arrow_segment(\n    data = ~ filter(.x, arrowtype == \"ellipse\"),\n    arrow_head = make_ellipse(),\n    length_head = unit(9, \"pt\")\n  )"
  }
]