<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="W. Joel Schneider">
<meta name="dcterms.date" content="2016-10-26">
<meta name="description" content="W. Joel Schneider is a professor at Temple University.">

<title>W. Joel Schneider</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../..//images/favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-04c4e107efec5be477c7dc5d62d6de6d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>

<script src="../../site_libs/rglWebGL-binding-1.3.18/rglWebGL.js"></script>

<link href="../../site_libs/rglwidgetClass-1.3.18/rgl.css" rel="stylesheet">

<script src="../../site_libs/rglwidgetClass-1.3.18/rglClass.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/utils.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/buffer.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/subscenes.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/shaders.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/shadersrc.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/textures.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/projection.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/mouse.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/init.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/pieces.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/draw.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/controls.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/selection.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/rglTimer.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/pretty.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/axes.src.js"></script>

<script src="../../site_libs/rglwidgetClass-1.3.18/animation.src.js"></script>

<script src="../../site_libs/CanvasMatrix4-1.3.18/CanvasMatrix.src.js"></script>



<meta property="og:title" content="W. Joel Schneider">
<meta property="og:description" content="A Review of the Receptive, Expressive &amp; Social Communication Assessment–Elementary">
<meta property="og:image" content="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/CHC.svg">
<meta property="og:site_name" content="W. Joel Schneider">
<meta property="og:image:alt" content="A graphical depiction of CHC Theory">
<meta name="citation_title" content="The RESCA-E Subtests Are Thoughtfully Designed and Highly Refined Measures of CHC Constructs">
<meta name="citation_author" content="W. Joel Schneider">
<meta name="citation_publication_date" content="2016-10-26">
<meta name="citation_cover_date" content="2016-10-26">
<meta name="citation_year" content="2016">
<meta name="citation_online_date" content="2016-10-26">
<meta name="citation_fulltext_html_url" content="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE.html">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="AssessingPsyche">
<meta name="citation_reference" content="citation_title=Human cognitive abilities: A survey of factor-analytic studies;,citation_author=John Bissell Carroll;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;">
<meta name="citation_reference" content="citation_title=Human cognitive abilities: A critique;,citation_author=John Bissell Carroll;,citation_editor=J. J. McArdle;,citation_editor=R. W. Woodcock;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_inbook_title=Human cognitive abilities in theory and practice;">
<meta name="citation_reference" content="citation_title=The higher-stratum structure of cognitive abilities: Current evidence supports &amp;amp;amp;lt;i&amp;gt;g&amp;lt;/i&amp;gt; and about ten broad factors;,citation_author=John Bissell Carroll;,citation_editor=Helmuth Nyborg;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_inbook_title=The scientific study of general intelligence: Tribute to Arthur R. Jensen;">
<meta name="citation_reference" content="citation_title=The neurology of syntax: Language use without Broca’s area;,citation_author=Yosef Grodzinsky;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=1;,citation_volume=23;,citation_journal_title=Behavioral and brain sciences;,citation_publisher=Cambridge Univ Press;">
<meta name="citation_reference" content="citation_title=psych: Procedures for psychological, psychometric, and personality research;,citation_author=William Revelle;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Integrating hot and cool intelligences: Thinking broadly about broad abilities;,citation_author=William Joel Schneider;,citation_author=John D. Mayer;,citation_author=Daniel A. Newman;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=http://www.mdpi.com/2079-3200/4/1/1;,citation_issue=1;,citation_doi=10.3390/jintelligence4010001;,citation_issn=2079-3200;,citation_volume=4;,citation_journal_title=Journal of Intelligence;">
<meta name="citation_reference" content="citation_title=Evaluation of parallel analysis methods for determining the number of factors;,citation_author=Aaron V Crawford;,citation_author=Samuel B Green;,citation_author=Roy Levy;,citation_author=Wen-Juo Lo;,citation_author=Lietta Scott;,citation_author=Dubravka Svetina;,citation_author=Marilyn S Thompson;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=6;,citation_doi=10.1177/0013164410379332;,citation_volume=70;,citation_journal_title=Educational and Psychological Measurement;,citation_publisher=Sage Publications;">
<meta name="citation_reference" content="citation_title=The Cattell-Horn-Carroll Theory of Cognitive Abilities: Past, present, and future.;,citation_author=Kevin S McGrew;,citation_editor=D. P. Flanagan;,citation_editor=P. L. Harrison;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_inbook_title=Contemporary intellectual assessment. Theories, tests, and issues;">
<meta name="citation_reference" content="citation_title=The Cattell-Horn-Carroll model of intelligence;,citation_author=William Joel Schneider;,citation_author=Kevin S McGrew;,citation_editor=Dawn P. Flanagan;,citation_editor=Patti L. Harrison;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_inbook_title=Contemporary intellectual assessment: Theories, tests and issues;">
<meta name="citation_reference" content="citation_title=The nature of human intelligence.;,citation_author=Joy Paul Guilford;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;">
<meta name="citation_reference" content="citation_title=Mayer-Salovey-Caruso Emotional Intelligence Test (MSCEIT) user’s manual;,citation_author=John D. Mayer;,citation_author=Peter Salovey;,citation_author=David R Caruso;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;">
<meta name="citation_reference" content="citation_title=Emotional intelligence is a second-stratum factor of intelligence: Evidence from hierarchical and bifactor models.;,citation_author=Carolyn MacCann;,citation_author=Dana L Joseph;,citation_author=Daniel A Newman;,citation_author=Richard D Roberts;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_volume=14;,citation_journal_title=Emotion;,citation_publisher=American Psychological Association;">
<meta name="citation_reference" content="citation_title=Human abilities: Emotional intelligence;,citation_author=John D. Mayer;,citation_author=Richard D Roberts;,citation_author=Sigal G Barsade;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=59;,citation_journal_title=Annual Review of Psychology;,citation_publisher=Annual Reviews;">
<meta name="citation_reference" content="citation_title=The relationship between theories of intelligence and intelligence tests;,citation_author=William Joel Schneider;,citation_author=Dawn P Flanagan;,citation_editor=S. Goldstein;,citation_editor=D. Princiotta;,citation_editor=J. A. Naglieri;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_inbook_title=Handbook of intelligence: Evolutionary theory, historical perspective, and current concepts;">
<meta name="citation_reference" content="citation_title=The measurement and appraisal of adult intelligence;,citation_author=David Wechsler;,citation_publication_date=1958;,citation_cover_date=1958;,citation_year=1958;">
<meta name="citation_reference" content="citation_title=Principles of assessment of aptitude and achievement;,citation_author=William Joel Schneider;,citation_editor=Don Saklofske;,citation_editor=Cecil Reynolds;,citation_editor=Vicki Schwean;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://books.google.com/books?id=bFZpAgAAQBAJ&amp;amp;amp;pg=PA290&amp;lpg=PA290#v=onepage&amp;q&amp;f=false;,citation_doi=10.1093/oxfordhb/9780199796304.013.0013;,citation_inbook_title=The Oxford handbook of child psychological assessment;">
<meta name="citation_reference" content="citation_title=Repetitive transcranial magnetic stimulation of Broca’s area affects verbal responses to gesture observation;,citation_author=Maurizio Gentilucci;,citation_author=Paolo Bernardis;,citation_author=Girolamo Crisi;,citation_author=Riccardo Dalla Volta;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=7;,citation_volume=18;,citation_journal_title=Journal of Cognitive Neuroscience;,citation_publisher=MIT Press;">
<meta name="citation_reference" content="citation_title=The human action recognition system and its relationship to Broca’s area: An fMRI study;,citation_author=Farsin Hamzei;,citation_author=Michel Rijntjes;,citation_author=Christian Dettmers;,citation_author=Volkmar Glauche;,citation_author=Cornelius Weiller;,citation_author=Christian Büchel;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=3;,citation_volume=19;,citation_journal_title=Neuroimage;,citation_publisher=Elsevier;">
</head>

<body class="floating nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">W. Joel Schneider</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">R Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../assessingpsyche.html"> 
<span class="menu-text">Assessment Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../vita.html"> 
<span class="menu-text">Vita</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../presentations.html"> 
<span class="menu-text">Presentations</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../tutorials.html"> 
<span class="menu-text">Tutorials</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="mailto:schneider@temple.edu" rel="noreferrer noopener" target="_blank"> <i class="bi bi-envelope" role="img" aria-label="Email">
</i> 
<span class="menu-text">Email</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/wjschne" rel="noreferrer noopener" target="_blank"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text">GitHub</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../blog.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The RESCA-E Subtests Are Thoughtfully Designed and Highly Refined Measures of CHC Constructs</h1>
            <p class="subtitle lead">A Review of the Receptive, Expressive &amp; Social Communication Assessment–Elementary</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>W. Joel Schneider </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 26, 2016</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sections</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#first-impressions" id="toc-first-impressions" class="nav-link" data-scroll-target="#first-impressions">First Impressions</a></li>
  <li><a href="#looking-deeper" id="toc-looking-deeper" class="nav-link" data-scroll-target="#looking-deeper">Looking Deeper</a></li>
  </ul></li>
  <li><a href="#chc-theory-a-work-in-progress" id="toc-chc-theory-a-work-in-progress" class="nav-link" data-scroll-target="#chc-theory-a-work-in-progress">CHC Theory: A Work in Progress</a></li>
  <li><a href="#receptive-language-subtests" id="toc-receptive-language-subtests" class="nav-link" data-scroll-target="#receptive-language-subtests">Receptive Language Subtests</a>
  <ul class="collapse">
  <li><a href="#comprehension-of-vocabulary" id="toc-comprehension-of-vocabulary" class="nav-link" data-scroll-target="#comprehension-of-vocabulary">Comprehension of Vocabulary</a></li>
  <li><a href="#comprehension-of-oral-directions" id="toc-comprehension-of-oral-directions" class="nav-link" data-scroll-target="#comprehension-of-oral-directions">Comprehension of Oral Directions</a></li>
  <li><a href="#comprehension-of-stories-and-questions" id="toc-comprehension-of-stories-and-questions" class="nav-link" data-scroll-target="#comprehension-of-stories-and-questions">Comprehension of Stories and Questions</a></li>
  <li><a href="#comprehsion-of-basic-morphology-and-syntax" id="toc-comprehsion-of-basic-morphology-and-syntax" class="nav-link" data-scroll-target="#comprehsion-of-basic-morphology-and-syntax">Comprehsion of Basic Morphology and Syntax</a></li>
  <li><a href="#executing-oral-directions" id="toc-executing-oral-directions" class="nav-link" data-scroll-target="#executing-oral-directions">Executing Oral Directions</a></li>
  </ul></li>
  <li><a href="#expressive-language-subtests" id="toc-expressive-language-subtests" class="nav-link" data-scroll-target="#expressive-language-subtests">Expressive Language Subtests</a>
  <ul class="collapse">
  <li><a href="#expressive-labeling-of-vocabulary" id="toc-expressive-labeling-of-vocabulary" class="nav-link" data-scroll-target="#expressive-labeling-of-vocabulary">Expressive Labeling of Vocabulary</a></li>
  <li><a href="#expressive-skills-for-describing-and-explaining" id="toc-expressive-skills-for-describing-and-explaining" class="nav-link" data-scroll-target="#expressive-skills-for-describing-and-explaining">Expressive Skills for Describing and Explaining</a></li>
  <li><a href="#narrative-skills" id="toc-narrative-skills" class="nav-link" data-scroll-target="#narrative-skills">Narrative Skills</a></li>
  <li><a href="#expressive-use-of-basic-morphology-and-syntax" id="toc-expressive-use-of-basic-morphology-and-syntax" class="nav-link" data-scroll-target="#expressive-use-of-basic-morphology-and-syntax">Expressive Use of Basic Morphology and Syntax</a></li>
  </ul></li>
  <li><a href="#social-communication" id="toc-social-communication" class="nav-link" data-scroll-target="#social-communication">Social Communication</a>
  <ul class="collapse">
  <li><a href="#comprehension-of-body-language-and-vocal-emotion" id="toc-comprehension-of-body-language-and-vocal-emotion" class="nav-link" data-scroll-target="#comprehension-of-body-language-and-vocal-emotion">Comprehension of Body Language and Vocal Emotion</a></li>
  <li><a href="#social-and-language-inference" id="toc-social-and-language-inference" class="nav-link" data-scroll-target="#social-and-language-inference">Social and Language Inference</a></li>
  <li><a href="#situational-language-use" id="toc-situational-language-use" class="nav-link" data-scroll-target="#situational-language-use">Situational Language Use</a></li>
  <li><a href="#elicited-body-language" id="toc-elicited-body-language" class="nav-link" data-scroll-target="#elicited-body-language">Elicited Body Language</a></li>
  </ul></li>
  <li><a href="#summary-of-influences-on-resca-e-performances" id="toc-summary-of-influences-on-resca-e-performances" class="nav-link" data-scroll-target="#summary-of-influences-on-resca-e-performances">Summary of Influences on RESCA-E Performances</a></li>
  <li><a href="#the-structure-of-the-resca-e" id="toc-the-structure-of-the-resca-e" class="nav-link" data-scroll-target="#the-structure-of-the-resca-e">The Structure of the RESCA-E</a>
  <ul class="collapse">
  <li><a href="#exploratory-factor-analysis" id="toc-exploratory-factor-analysis" class="nav-link" data-scroll-target="#exploratory-factor-analysis">Exploratory Factor Analysis</a></li>
  <li><a href="#might-mulitdimensional-scaling-detect-a-faceted-relationship-among-the-three-language-domains" id="toc-might-mulitdimensional-scaling-detect-a-faceted-relationship-among-the-three-language-domains" class="nav-link" data-scroll-target="#might-mulitdimensional-scaling-detect-a-faceted-relationship-among-the-three-language-domains">Might Mulitdimensional Scaling Detect a Faceted Relationship Among the Three Language Domains?</a></li>
  <li><a href="#confirmatory-factor-analysis-to-the-rescue" id="toc-confirmatory-factor-analysis-to-the-rescue" class="nav-link" data-scroll-target="#confirmatory-factor-analysis-to-the-rescue">Confirmatory Factor Analysis to the rescue?</a></li>
  <li><a href="#conclusion-the-three-resca-e-language-domains-are-descriptive-categories-not-distinct-abilities" id="toc-conclusion-the-three-resca-e-language-domains-are-descriptive-categories-not-distinct-abilities" class="nav-link" data-scroll-target="#conclusion-the-three-resca-e-language-domains-are-descriptive-categories-not-distinct-abilities">Conclusion: The Three RESCA-E Language Domains Are Descriptive Categories, Not Distinct Abilities</a></li>
  <li><a href="#alternative-structure" id="toc-alternative-structure" class="nav-link" data-scroll-target="#alternative-structure">Alternative Structure</a></li>
  </ul></li>
  <li><a href="#overall-evaluation-of-the-resca-e" id="toc-overall-evaluation-of-the-resca-e" class="nav-link" data-scroll-target="#overall-evaluation-of-the-resca-e">Overall Evaluation of the RESCA-E</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<section id="introduction" class="level1 page-columns page-full">
<h1>Introduction</h1>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Conflict of Interest Statement:</strong> <a href="https://www.academictherapy.com/support/assessments.tpl">ATP Assessments</a>, the publisher of the RESCA-E, commissioned me to write a descriptive account of the likely relations among the RESCA-E subtests and CHC Theory constructs. I billed them for the hours that I spent researching this topic and writing my thoughts on the matter. However, I was so impressed the the RESCA-E that I wanted to write a short review of it, and I also conducted additional analyses about its structure. Because ATP Assessments did not ask for my opinion about the quality of the RESCA-E nor for the statistical analyses I conducted, I did not bill for the many additional hours I spent on these activities. If I were not impressed with the RESCA-E, this document would have been much shorter.”)</p>
</div></div><p>The <a href="https://www.academictherapy.com/detailATP.tpl?action=search&amp;eqskudatarq=8995-7">Receptive, Expressive &amp; Social Communication Assessment–Elementary (RESCA-E)</a> is a new measure of language abilities for children in the elementary school years. The purpose of this review is to evaluate the RESCA-E in terms of the Cattell-Horn-Carroll Theory of Cognitive Abilities [CHC theory; <span class="citation" data-cites="McGrew2005">McGrew (<a href="#ref-McGrew2005" role="doc-biblioref">2005</a>)</span>; <span class="citation" data-cites="Schneider2012">Schneider &amp; McGrew (<a href="#ref-Schneider2012" role="doc-biblioref">2012</a>)</span>]. However, some preliminary remarks about the test’s design are in order.</p>
<section id="first-impressions" class="level2">
<h2 class="anchored" data-anchor-id="first-impressions">First Impressions</h2>
<p>Modest elegance, by its nature, attracts little praise. I will do my part here to rectify this injustice. The RESCA-E test materials, stimuli, and protocols are designed for practical efficiency but sacrifice nothing in aesthetic appeal. This might not seem to matter, but it does. Spending time with ugly, frustrating test materials makes one yearn for early retirement.</p>
<p>The application of sound typographical principles has enhanced the readability and ease of use of the protocol; the whole document is thoughtfully coded by font, color, and shading. The protocol does not feel cramped; it has generous space for notes, yet no space is wasted. Sure, the designers could have shortened the protocol by making everything smaller and more compact, but that would have been <em>penny wise, pound foolish.</em> This same care and consistency was extended to everything in the test kit.</p>
</section>
<section id="looking-deeper" class="level2">
<h2 class="anchored" data-anchor-id="looking-deeper">Looking Deeper</h2>
<p>I do not know the test’s authors, Patricia Hamaguchi and Deborah Ross-Swain, and I have had no contact with them. Yet, I can tell something about their work process and their scholarly values. To someone who has never tried to design an ability test, it may not be obvious that the RESCA-E subtest items were labored over for untold hours until they were just right. In most test batteries I find several items (or whole subtests) that seem a bit off, like bum notes in a singer’s solo. I found none here. The items are so smoothly written that they draw no attention to themselves—no small feat.</p>
<p>Even more importantly, the item content reflects a deep understanding on the part of the authors of what matters in the evaluation of children. No item is merely easy or merely difficult, chosen to meet some psychometric need. No, each item is intended to measure something substantial and relevant to everyday functioning. A rare patience was required to keep working with each item until it was easy to understand, quick to administer, and simple to score, all the while remaining clinically relevant, yet psychometrically sound. For this accomplishment, Patricia Hamaguchi, Deborah Ross-Swain, and their associates at ATP Assessments deserve a tip of the hat and hearty congratulations.</p>
</section>
</section>
<section id="chc-theory-a-work-in-progress" class="level1 page-columns page-full">
<h1>CHC Theory: A Work in Progress</h1>
<p>Because a complete description of CHC theory can be found in <a href="http://www.iapsych.com/articles/schneider2012.pdf">Schneider and McGrew (2012)</a>, no space will be wasted on a summary here. <a href="#fig-chc" class="quarto-xref">Figure&nbsp;1</a> displays the broad abilities arranged conceptually.</p>
<div class="cell fig-cap-location-bottom page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-chc" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" alt="A graphical depiction of CHC Theory" data-cap-location="bottom">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-chc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<img src="CHC.svg" class="img-fluid figure-img column-page-right" style="width:100.0%" alt="A graphical depiction of CHC Theory">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-chc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Conceptual Groupings in the Cattell-Horn-Carroll Theory of Cognitive Abilities
</figcaption>
</figure>
</div>
</div>
</div>
<p>CHC theory is largely based on John Carroll’s <span class="citation" data-cites="Carroll1993">(<a href="#ref-Carroll1993" role="doc-biblioref">1993</a>)</span> Three-Stratum Theory of Cognitive Abilities.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Because it was based on all the factor-analytic evidence available at the time, Carroll’s synthesis created more consensus in the the field of individual differences in cognitive abilities research than any previous work. However, this strength was also its weakness—one that Carroll <span class="citation" data-cites="Carroll2003 Carroll1998">(<a href="#ref-Carroll1998" role="doc-biblioref">1998</a>, <a href="#ref-Carroll2003" role="doc-biblioref">2003</a>)</span> was candid about. Because his theory was based on all the world’s existing data sets, his theorizing process was necessarily exploratory. None of the data sets were designed explicitly to confirm or disconfirm his theory. No one was more aware that the Three-Stratum Theory was incomplete than Carroll (1998) himself:</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Carroll’s conceptualization drew heavily from John Horn’s taxonomy of intelligence, which was an elaboration of Raymond Cattell’s theories, which extended Spearman’s model, which was a work of singular genius.</p></div></div><blockquote class="blockquote">
<p>Whether or not my book on human cognitive abilities can be regarded as an important milestone in its field, I hope that it can at least serve as a guide and reference for future researchers. However, I also think that my book leaves much to be desired, in that it fails to answer a plethora of fundamental questions about cognitive abilities—their structure, sources and meanings. (p.&nbsp;22)</p>
</blockquote>
<p>With Carroll’s passing in 2003, it now falls to us to trim the parts of Carroll’s theory that are inaccurate and supplement those parts that are admittedly incomplete. CHC theory represents such an effort. Although this creative synthesis was instigated by the tireless wizard, Kevin McGrew, CHC theory is a constantly evolving theory and anyone can participate in its upkeep. Schneider &amp; McGrew (2012) issued this standing invitation:</p>
<blockquote class="blockquote">
<p>CHC theory is put forward as a candidate for a common framework for cognitive abilities researchers. All are invited to help build it, and anyone is entitled to try to knock it down by subjecting it to critical tests of its assumptions. (p.&nbsp;100)</p>
</blockquote>
<p>When CHC theory was new, considerable effort was necessarily devoted to retrofitting the meaning of old tests to the new framework <span class="citation" data-cites="Schneider2015a">(<a href="#ref-Schneider2015a" role="doc-biblioref">Schneider &amp; Flanagan, 2015</a>)</span>. With new tests like the RESCA-E, we should resist the urge to fit each innovation into an existing slot in the CHC taxonomy. Nevertheless, if there are places where the fit is comfortable, it should be acknowledged so that future research with the RESCA-E can more easily build on existing knowledge. I therefore turn to an examination of each subtest of the RESCA-E and speculate how it might relate to CHC narrow and broad abilities.</p>
</section>
<section id="receptive-language-subtests" class="level1 page-columns page-full">
<h1>Receptive Language Subtests</h1>
<section id="comprehension-of-vocabulary" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="comprehension-of-vocabulary">Comprehension of Vocabulary</h2>
<p>The examiner shows four drawings to the examinee and says a word. The examinee points to the one best depicts the word.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> The advantage of this format is that it cleanly measures the CHC narrow ability <em>Lexical Knowledge</em>, a facet of <em>Comprehension/Knowledge (Gc)</em>. The “disadvantage” of the multiple choice format is that its loading on general intelligence is likely to be smaller than with tests with more open-ended formats (e.g., WISC-V Vocabulary). Why? No judgment is required to decide which aspects of a definition to emphasize. Wechsler’s <span class="citation" data-cites="Wechsler1958">(<a href="#ref-Wechsler1958" role="doc-biblioref">1958</a>)</span> goal was never to measure things like knowledge <em>per se</em>, but to measure intelligence in all its integrative, glorious complexity.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> However, when your goal is to measure word knowledge, not judgment, this item format is exactly what you want.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Similar to the <a href="http://www.pearsonclinical.com/language/products/100000501/peabody-picture-vocabulary-test-fourth-edition-ppvt-4.html">Peabody Picture Vocabulary Test, Fourth Edition</a> and the <a href="http://www.academictherapy.com/detailATP.tpl?eqskudatarq=8547-8">Receptive One-Word Picture Vocabulary Test-4</a></p></div><div id="fn3"><p><sup>3</sup>&nbsp;Wechsler (1958, p.&nbsp;15) wrote, “Then, when an examiner employs an arithmetic or a vocabulary test as part of an intelligence scale, the object of the examiner is not to discover the subject’s aptitude for arithmetic or extent of his word knowledge, although these are inevitably involved, but his capacity to function in overall areas which are assumed to require intelligence.”</p></div></div><p>All picture vocabulary tests start with simple objects one encounters frequently (e.g., spoon, ball, dog). Where the test designers go from there matters quite a bit. There are two ways to make a picture vocabulary test more difficult:</p>
<ul>
<li>Show pictures of increasingly unusual objects (e.g., fob, lappets, ait, manometer).</li>
<li>Show pictures illustrating increasingly complex concepts (e.g., relieved, hesitant, shrewd, intimacy) or increasingly subtle distinctions between related words (e.g., ask vs.&nbsp;beg, sad vs.&nbsp;sobbing, consider vs.&nbsp;ponder).</li>
</ul>
<p>Which approach do you think is more applicable to everyday life? Me, too. Fortunately, this is the approach that the RESCA-E takes, with more difficult items focusing mostly on emotions, interpersonal relations, measurements, and abstractions. None of the words are particularly unusual, technical, or esoteric.</p>
</section>
<section id="comprehension-of-oral-directions" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="comprehension-of-oral-directions">Comprehension of Oral Directions</h2>
<p>This measure is similar to the Comprehension of Vocabulary subtest in its format. The examiner shows four drawings to the examinee and says a sentence that contains an instruction. The examinee chooses the picture that is consistent with the instruction. For example, the sentence might be, “You may not ride bicycles in the park.” The four pictures might be various configurations of a child, a bicycle, and a park. The correct answer might be a picture of child in the park with a bicycle chained outside its gates.</p>
<p>The items of this test are ingeniously designed to avoid problems in similar tests of oral direction comprehension. Some tests give increasingly long directions that tax working memory instead of comprehension <em>per se</em>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> This subtest minimizes working memory load by presenting directions that rarely have more than three parts. Items become increasingly difficult mostly because of the complexity of the command rather than its length.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Which is fine, if we wish to measure the degree to which working memory deficits interfere with comprehension.</p></div><div id="fn5"><p><sup>5</sup>&nbsp;For example, “Write a letter that has only curved lines or only straight lines, but not both kinds of lines. Which letter could be written? [shows letters] B, D, O, or P”</p></div><div id="fn6"><p><sup>6</sup>&nbsp;You might ask, “If CHC theory has holes in it, why not just fill them?” Good question. Theory building, especially the assembly of a comprehensive taxonomy, must be a slow, deliberate, systematic process. Adding new features that are not well validated into the taxonomy will undermine trust in its utility.</p></div></div><p>In terms of CHC theory, it appears that this subtest measures <em>Listening Ability</em>, a facet of Gc. However, it seems likely that Carroll’s <em>Listening Ability</em> factor comprises multiple subfactors, and that this subtest measures a narrow subset of them (e.g., understanding of English syntax). Thus, the model of language that underlies RESCA-E is more elaborated than the model of language ability in CHC theory. Ideally, research using instruments like the RESCA-E will refine and extend CHC theory’s treatment of language abilities.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
</section>
<section id="comprehension-of-stories-and-questions" class="level2">
<h2 class="anchored" data-anchor-id="comprehension-of-stories-and-questions">Comprehension of Stories and Questions</h2>
<p>In this subtest, the examiner reads a short story to the examinee and asks questions about the examinee’s understanding of it. For each question, there are four possible answers that the examinee can point to (either words that the examiner reads aloud or pictures that are shown). The passages are carefully crafted to be stories rather than barely concealed lists of random details and events. To answer the questions correctly, the examinee must understand the gist of the story rather than recall highly specific details. Thus, it is a true comprehension test rather than a memory test.</p>
<p>Comprehension of Stories and Questions is, like Comprehension of Oral Directions, a measure of <em>Listening Ability</em>, but less about syntax and more about semantics. To some degree, it is also a measure of <em>Meaningful Memory</em> (Gl).</p>
</section>
<section id="comprehsion-of-basic-morphology-and-syntax" class="level2">
<h2 class="anchored" data-anchor-id="comprehsion-of-basic-morphology-and-syntax">Comprehsion of Basic Morphology and Syntax</h2>
<p>Like the other receptive language subtests, this supplementary subtest is a multiple-choice test. It is cleverly designed to measure a child’s understanding of syntax and morphology. For example, to measure one’s understanding of plurality, the prompt could be “The birds are swimming.” The child has to choose among pictures of birds swimming, but only one picture has more than one bird. In similar fashion, understanding of a variety of other features of English are tested: past vs.&nbsp;present vs.&nbsp;future tense, negation (e.g., none, not, never), prepositions (e.g., on, in, above, between), gender (he vs.&nbsp;she, him vs.&nbsp;her), singular vs.&nbsp;plural, self vs.&nbsp;other (me vs.&nbsp;her), before vs.&nbsp;after, active vs.&nbsp;passive voice (e.g., the boy touched the dog, the boy was touched by the dog).</p>
<p>This subtest is another measure of <em>Listening Ability</em> but with a focus on syntax. From the name of Carroll’s <em>Grammatical Sensitivity</em> factor, it might seem that this is what Comprehension of Basic Morphology and Syntax measures. However, the Grammatical Sensitivity ability factor was a measure of formal knowledge of grammar. Obviously, knowing formal grammatical rules will help on this test but that is not what is being measured here directly.</p>
</section>
<section id="executing-oral-directions" class="level2">
<h2 class="anchored" data-anchor-id="executing-oral-directions">Executing Oral Directions</h2>
<p>This supplementary test is of obvious importance. It can resolve questions such as, “Does the child understand simple commands?” The subtest is similar to and is most correlated with Comprehension of Oral Directions (<em>r</em> = .52). It differs from that test in that it is not a multiple-choice test. Instead, it requires the examinee to follow simple commands at first (e.g., “Touch your knee. Go.”) and increasingly complex sentences at the end of the test (e.g., “Stand up and walk to the door. When you get there, knock on it three times or open it, but not both. Go.”). Near the end of the test, the commands are long and thus the working memory demands are high.</p>
</section>
</section>
<section id="expressive-language-subtests" class="level1 page-columns page-full">
<h1>Expressive Language Subtests</h1>
<section id="expressive-labeling-of-vocabulary" class="level2">
<h2 class="anchored" data-anchor-id="expressive-labeling-of-vocabulary">Expressive Labeling of Vocabulary</h2>
<p>Like the Comprehension of Vocabulary subtest, this test measures <em>Lexical Knowledge</em>. On some items examinee is asked what object is in a picture. In many confrontational naming tests, the objects in the pictures become increasingly unusual. Not so, here. As with the Comprehension of Vocabulary subtest, the pictures measure knowledge of words related to abstract concepts, emotions, and interpersonal relations.</p>
<p>Although Comprehension of Vocabulary (CV) and Expressive Labeling of Vocabulary (ELV) have the highest correlation of all the RESCA-E subtests (<em>r</em> = .6), the correlation is not so high that they are redundant. In my opinion, the RESCA-E should have a Vocabulary composite score consisting of these tests. Using formulas explained in <span class="citation" data-cites="schneider2013principles">Schneider (<a href="#ref-schneider2013principles" role="doc-biblioref">2013</a>)</span>, you can compute a custom vocabulary composite score like so:</p>
<p><em>Vocabulary Composite</em> = 2.795(<em>CV</em> + <em>ELV</em>) − 44.1</p>
</section>
<section id="expressive-skills-for-describing-and-explaining" class="level2">
<h2 class="anchored" data-anchor-id="expressive-skills-for-describing-and-explaining">Expressive Skills for Describing and Explaining</h2>
<p><span class="citation" data-cites="Guilford1967">Guilford (<a href="#ref-Guilford1967" role="doc-biblioref">1967</a>)</span> distinguished between tests requiring <em>convergent</em> production (i.e., a single answer is correct) and tests requiring <em>divergent production</em> (e.g., the examinee gives as many correct answers, such as naming as many ice cream flavors as possible within the time allotted). Cattell originally grouped divergent production tests with crystallized intelligence. The reason for this is that his tests had generous time limits so that the tests were measures of <em>how much</em> information was in the person’s knowledge banks instead <em>how fast</em> it could be pulled out of memory. The results will be quite different if one is given 1 minute to name as many words as possible ending in <em>-tion</em> compared to the same task but with a 5-minute time limit. With generous time limits, the test becomes more like a breadth-of-vocabulary test rather than a memory retrieval speed test. Almost all commercially available tests of divergent production have short time limits and thus function as memory retrieval speed tests.</p>
<p>In this subtest, the examinee is shown a picture (e.g., a family preparing a meal) or given a scenario (e.g., a child getting ready for bed) and the examinee is prompted to tell the examiner everything he or she knows about this situation. Unlike many divergent processing tests (e.g., COWAT), the child does not get 1 point for every answer. Instead there is a checklist of criteria for scoring points. In general, the examinee is awarded points for mentioning aspects of the picture or scenario that are most salient or of central importance.</p>
<p>This is a test paradigm I have never seen before. If it is indeed novel, it is potentially a major advance. It is rare in life to have to name as many exemplars of a category as possible (e.g., sports, furniture, animals, words that begin with H). In contrast, spontaneously describing the most salient aspects of a situation is a hallmark of intelligence. I look forward to seeing validation efforts to evaluate this paradigm’s utility.</p>
<p>This subtest has relatively small correlations with the other tests (<em>r</em> in the .2–.3 range), suggesting that it is not merely a Gc test, though it is undoubtedly influenced by Gc. In CHC theory, there is a little-understood narrow ability called <em>Associational Fluency</em> in the Gr (Memory Retrieval Fluency) broad ability cluster. It is distinguished from the better-known <em>Ideational Fluency</em> factor in that the quality of the responses matters more than the number. Given how points are awarded for mentioning important aspects of a picture or scenario, it seems likely that this is what is being measured. It also seems like that having general knowledge, an intermediate factor within Gc, would help a person perform well on this test.</p>
</section>
<section id="narrative-skills" class="level2">
<h2 class="anchored" data-anchor-id="narrative-skills">Narrative Skills</h2>
<p>In this subtest, the examinee is prompted to tell the gist of a narrative that the examiner read. Another type of item involves telling the examiner about an experience (e.g., taking a long trip in a car or bus). As with the Expressive Skills for Describing and Explaining subtest, the examiner scores the response for the quality of the answers, not for how much is said. It may sound from this description that this subtest is a bear to score, but it is quite straightforward.</p>
<p>The Narrative Skills subtest is most highly correlated with Expressive Skills for Describing and Explaining. It seems likely that it too is a measure of <em>Associational Fluency</em>. It does not seem to draw on background knowledge to the same degree and instead requires <em>Meaningful Memory</em>. Supporting this interpretation is the fact that its second-highest correlation is with Comprehension of Stories and Questions, which is also hypothesized to be influenced by <em>Meaningful Memory.</em></p>
</section>
<section id="expressive-use-of-basic-morphology-and-syntax" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="expressive-use-of-basic-morphology-and-syntax">Expressive Use of Basic Morphology and Syntax</h2>
<p>In this subtest, the examiner prompts the examinee to answer questions about pictures. The questions are cleverly worded so that the examinee’s answers are expected to conform to certain syntactical rules (e.g., “This girl here is running. What is this other girl doing? Answer: Walking”).</p>
<p>Given the similarity in names, it seems reasonable to suppose that this subtest would be strongly correlated with Comprehension of Basic Morphology and Syntax. Its correlation is only <em>r</em> = .45, a value that is similar to the correlations it has with many other subtests. Factor analyses of the RESCA-E reveal no evidence that there is a special relationship between these two measures of morphology and syntax understanding. Examining the pattern of critical difference scores in the Technical Manual, it appears that the correlation between these two tests decreases with age. Why this happens deserves scrutiny. One likely explanation is that both tests have very low ceilings for older children, which means that the scores are imprecise for children with average or better understanding of morphology and syntax.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;A test with a <em>low ceiling</em> does not have enough difficult items to distinguish reliably among high-ability examinees. Low ceilings are a major problem for intelligence tests, but are not so problematic for tests like the RESCA-E, which are designed to identify children with language deficits rather than designed to identify the superstars of syntactic sophistication.</p></div></div><p>In terms of CHC theory, it appears that this subtest measures aspects of <em>Communication Ability</em>, a little-researched factor. As with Comprehension of Basic Morphology &amp; Syntax, it seems likely that Grammatical Sensitivity also influences performance on the test.</p>
</section>
</section>
<section id="social-communication" class="level1">
<h1>Social Communication</h1>
<p>Note that there is no reason to suppose that social communication is distinct from receptive and expressive language. We can imagine receptive social comprehension and expressive social communication. Nevertheless, there is reason to suppose that there as aspects of social communication that deserve separate consideration.</p>
<section id="comprehension-of-body-language-and-vocal-emotion" class="level2">
<h2 class="anchored" data-anchor-id="comprehension-of-body-language-and-vocal-emotion">Comprehension of Body Language and Vocal Emotion</h2>
<p>In this subtest, the examiner shows the examinee four pictures of people making different gestures or with different facial expressions. The examiner plays an audio CD that asks a question like, “Which person is thinking, ‘I am confused.’” and the examinee picks the picture of the person who looks confused. The items are well designed and toward the end of the subtest assess fairly subtle social signals. This subtest would fit it with emotional intelligence tests like the MSCEIT’s <span class="citation" data-cites="Mayer2002">(<a href="#ref-Mayer2002" role="doc-biblioref">Mayer et al., 2002</a>)</span> measures of emotion perception.</p>
<p>Because of Guildford’s work in social intelligence, Carroll’s model has a factor called <em>Knowledge of Behavioral Content</em>, an aspect of achievement. However, there is already strong evidence that social and emotional reasoning have several narrow ability factors associated with them <span class="citation" data-cites="Mayer2008a">(<a href="#ref-Mayer2008a" role="doc-biblioref">Mayer et al., 2008</a>)</span>. It is not clear where these factors belong in CHC theory, but the evidence keeps pouring in that these factors matter. Sooner or later, CHC theory is going to have to provide a more nuanced account of aspects of social and emotional intelligence <span class="citation" data-cites="MacCann2014 schneider2016integrating">(<a href="#ref-MacCann2014" role="doc-biblioref">MacCann et al., 2014</a>; <a href="#ref-schneider2016integrating" role="doc-biblioref">Schneider et al., 2016</a>)</span>.</p>
</section>
<section id="social-and-language-inference" class="level2">
<h2 class="anchored" data-anchor-id="social-and-language-inference">Social and Language Inference</h2>
<p>In this test, the examiner presents a scenario in which someone uses indirect or idiomatic language. In many items, the examinee selects the correct answer from four answer choices. For example, two children are talking in class and the teacher says, “Hey, knock it off, you two!” The correct inference will be that the teacher wants the children to stop talking.</p>
<p>In terms of CHC theory, this seems to be a general <em>Language Development</em> measure with emphasis on <em>Knowledge of Behavioral Content</em> as well.</p>
</section>
<section id="situational-language-use" class="level2">
<h2 class="anchored" data-anchor-id="situational-language-use">Situational Language Use</h2>
<p>In this subtest, the examiner presents the examinee with a scenario and prompts the examinee to say how he or she would respond in that situation. For example, “Your mother introduces you to a woman you do not know. The woman smiles and extends her hand, saying ‘Pleased to meet you.’ How would you respond in a friendly and polite manner?” The examinee’s response is scored according to straightforward criteria.</p>
<p>In terms of CHC theory, this subtest measures <em>Communication Ability</em> as well as <em>Knowledge of Behavioral Content</em>.</p>
</section>
<section id="elicited-body-language" class="level2">
<h2 class="anchored" data-anchor-id="elicited-body-language">Elicited Body Language</h2>
<p>In this subtest, the examiner asks the examinee to act out various common situations (e.g., Pretend you just took a bite of your favorite food. Pretend you accidentally hurt your finger. Pretend you are listening to someone who whispers a surprising secret.). This test may supplant the SB5 Verbal Absurdities as the most delightful test to administer.</p>
<p>Once again, CHC theory’s taxonomy is too sparse in this domain to explain what is going on in this subtest. Nevertheless, the narrow ability that is being measured is mostly likely <em>Knowledge of Behavioral Content</em>.</p>
</section>
</section>
<section id="summary-of-influences-on-resca-e-performances" class="level1">
<h1>Summary of Influences on RESCA-E Performances</h1>
<p><a href="#tbl-subtests" class="quarto-xref">Table&nbsp;1</a> summarizes my hypotheses about which CHC narrow abilities are measured by each RESCA-E subtest. Evidence is cruel to armchair speculation, and the probability that I am right in every case is low. There are two kinds of errors I might have made. First, it is possible that some other CHC narrow ability is a more important influence on test performance than what I have listed. Second, it is possible that CHC theory simply does not have the right categories to characterize what the RESCA-E subtests measure. There is a reasonable chance I have made few or no errors of the first type. However, it is certain that errors of the second type have been made, particularly with respect to the Social Communication subtests.</p>
<div class="cell">
<div id="tbl-subtests" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-subtests-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: CHC Constructs Hypothesized to Influence Performance on RESCA-E Subtests
</figcaption>
<div aria-describedby="tbl-subtests-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="nhvjzaocxc" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#nhvjzaocxc table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#nhvjzaocxc thead, #nhvjzaocxc tbody, #nhvjzaocxc tfoot, #nhvjzaocxc tr, #nhvjzaocxc td, #nhvjzaocxc th {
  border-style: none;
}

#nhvjzaocxc p {
  margin: 0;
  padding: 0;
}

#nhvjzaocxc .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#nhvjzaocxc .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#nhvjzaocxc .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#nhvjzaocxc .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#nhvjzaocxc .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#nhvjzaocxc .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nhvjzaocxc .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#nhvjzaocxc .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#nhvjzaocxc .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#nhvjzaocxc .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#nhvjzaocxc .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#nhvjzaocxc .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#nhvjzaocxc .gt_spanner_row {
  border-bottom-style: hidden;
}

#nhvjzaocxc .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#nhvjzaocxc .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#nhvjzaocxc .gt_from_md > :first-child {
  margin-top: 0;
}

#nhvjzaocxc .gt_from_md > :last-child {
  margin-bottom: 0;
}

#nhvjzaocxc .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: hidden;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#nhvjzaocxc .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#nhvjzaocxc .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#nhvjzaocxc .gt_row_group_first td {
  border-top-width: 2px;
}

#nhvjzaocxc .gt_row_group_first th {
  border-top-width: 2px;
}

#nhvjzaocxc .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#nhvjzaocxc .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#nhvjzaocxc .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#nhvjzaocxc .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nhvjzaocxc .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#nhvjzaocxc .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#nhvjzaocxc .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#nhvjzaocxc .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#nhvjzaocxc .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nhvjzaocxc .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#nhvjzaocxc .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#nhvjzaocxc .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#nhvjzaocxc .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#nhvjzaocxc .gt_left {
  text-align: left;
}

#nhvjzaocxc .gt_center {
  text-align: center;
}

#nhvjzaocxc .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#nhvjzaocxc .gt_font_normal {
  font-weight: normal;
}

#nhvjzaocxc .gt_font_bold {
  font-weight: bold;
}

#nhvjzaocxc .gt_font_italic {
  font-style: italic;
}

#nhvjzaocxc .gt_super {
  font-size: 65%;
}

#nhvjzaocxc .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#nhvjzaocxc .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#nhvjzaocxc .gt_indent_1 {
  text-indent: 5px;
}

#nhvjzaocxc .gt_indent_2 {
  text-indent: 10px;
}

#nhvjzaocxc .gt_indent_3 {
  text-indent: 15px;
}

#nhvjzaocxc .gt_indent_4 {
  text-indent: 20px;
}

#nhvjzaocxc .gt_indent_5 {
  text-indent: 25px;
}

#nhvjzaocxc .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#nhvjzaocxc div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-bootstrap="false">
<thead>
<tr class="gt_col_headings header">
<th id="Subtest" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" style="font-weight: bold" scope="col">Subtest</th>
<th id="Primary-Influence" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" style="font-weight: bold" scope="col">Primary Influence</th>
<th id="Secondary-Influences" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" style="font-weight: bold" scope="col">Secondary Influences</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="gt_group_heading_row odd">
<th colspan="3" id="Social Communication" class="gt_group_heading" data-quarto-table-cell-role="th" style="font-weight: bold" scope="colgroup">Social Communication</th>
</tr>
<tr class="gt_row_group_first even">
<td class="gt_row gt_left" headers="Social Communication  Subtest">Comprehension of Body Language and Vocal Emotion</td>
<td class="gt_row gt_left" headers="Social Communication  Primary Influence">Knowledge of Behavioral Content</td>
<td class="gt_row gt_left" headers="Social Communication  Secondary Influences"></td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Social Communication  Subtest">Social and Language Inference</td>
<td class="gt_row gt_left" headers="Social Communication  Primary Influence">Language Development</td>
<td class="gt_row gt_left" headers="Social Communication  Secondary Influences">Knowledge of Behavioral Content</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Social Communication  Subtest">Situational Language Use</td>
<td class="gt_row gt_left" headers="Social Communication  Primary Influence">Communication Ability</td>
<td class="gt_row gt_left" headers="Social Communication  Secondary Influences">Knowledge of Behavioral Content</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Social Communication  Subtest">Elicited Body Language</td>
<td class="gt_row gt_left" headers="Social Communication  Primary Influence">Knowledge of Behavioral Content</td>
<td class="gt_row gt_left" headers="Social Communication  Secondary Influences"></td>
</tr>
<tr class="gt_group_heading_row even">
<th colspan="3" id="Expressive Language" class="gt_group_heading" data-quarto-table-cell-role="th" style="font-weight: bold" scope="colgroup">Expressive Language</th>
</tr>
<tr class="gt_row_group_first odd">
<td class="gt_row gt_left" headers="Expressive Language  Subtest">Expressive Labeling of Vocabulary</td>
<td class="gt_row gt_left" headers="Expressive Language  Primary Influence">Lexical Knowledge</td>
<td class="gt_row gt_left" headers="Expressive Language  Secondary Influences"></td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Expressive Language  Subtest">Expressive Skills for Describing and Explaining</td>
<td class="gt_row gt_left" headers="Expressive Language  Primary Influence">Associational Fluency</td>
<td class="gt_row gt_left" headers="Expressive Language  Secondary Influences">General Knowledge</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Expressive Language  Subtest">Narrative Skills</td>
<td class="gt_row gt_left" headers="Expressive Language  Primary Influence">Associational Fluency</td>
<td class="gt_row gt_left" headers="Expressive Language  Secondary Influences">Meaningful Memory</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Expressive Language  Subtest">Expressive Use of Basic Morphology and Syntax</td>
<td class="gt_row gt_left" headers="Expressive Language  Primary Influence">Communication Ability</td>
<td class="gt_row gt_left" headers="Expressive Language  Secondary Influences">Grammatical Sensitivity</td>
</tr>
<tr class="gt_group_heading_row odd">
<th colspan="3" id="Receptive Language" class="gt_group_heading" data-quarto-table-cell-role="th" style="font-weight: bold" scope="colgroup">Receptive Language</th>
</tr>
<tr class="gt_row_group_first even">
<td class="gt_row gt_left" headers="Receptive Language  Subtest">Comprehension of Vocabulary</td>
<td class="gt_row gt_left" headers="Receptive Language  Primary Influence">Lexical Knowledge</td>
<td class="gt_row gt_left" headers="Receptive Language  Secondary Influences"></td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Receptive Language  Subtest">Comprehension of Oral Directions</td>
<td class="gt_row gt_left" headers="Receptive Language  Primary Influence">Listening Ability</td>
<td class="gt_row gt_left" headers="Receptive Language  Secondary Influences">Working Memory Capacity</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Receptive Language  Subtest">Comprehension of Stories &amp; Questions</td>
<td class="gt_row gt_left" headers="Receptive Language  Primary Influence">Listening Ability</td>
<td class="gt_row gt_left" headers="Receptive Language  Secondary Influences">Meaningful Memory</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Receptive Language  Subtest">Comprehension of Basic Morphology &amp; Syntax</td>
<td class="gt_row gt_left" headers="Receptive Language  Primary Influence">Listening Ability</td>
<td class="gt_row gt_left" headers="Receptive Language  Secondary Influences">Grammatical Sensitivity</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Receptive Language  Subtest">Executing Oral Directions</td>
<td class="gt_row gt_left" headers="Receptive Language  Primary Influence">Listening Ability</td>
<td class="gt_row gt_left" headers="Receptive Language  Secondary Influences">Working Memory Capacity</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
</section>
<section id="the-structure-of-the-resca-e" class="level1">
<h1>The Structure of the RESCA-E</h1>
<p>It is telling that only in the language domain did Carroll offer elaborate speculations that went substantially beyond his data. Carroll was, if anything, an expert in language abilities, having studied them intensely since the beginning of his career in the 1930s. He knew that the available data sets, rich and varied as they were, could not capture all of what he suspected was true of language abilities. For example, although the distinction between receptive language and expressive language could not be verified directly with the available data, he made the distinction nonetheless (Carroll, 1993, p.&nbsp;147).</p>
<p>The fact that we comprehend language and we communicate via language is so obvious a distinction that we simply do not care how the factor analyses shake out. Since the early work of Wernicke and Broca, we have known that damage to certain areas of the brain impair receptive language more than expressive language and that damage to other brain regions produces the opposite pattern of deficits. Even so, nature has no desire to conform to our preferences for theoretical tidiness. For example, damage to Broca’s area impairs expressive language more than receptive language but also impairs understanding of specific aspects of syntax <span class="citation" data-cites="grodzinsky2000neurology">(<a href="#ref-grodzinsky2000neurology" role="doc-biblioref">Grodzinsky, 2000</a>)</span>.</p>
<p>The authors of the RESCA-E not only distinguish between receptive and expressive language abilities, but also social communication as well. These distinctions are important, but it is important to be clear as to what kind of distinction is being made. Are these language domains, expressive, receptive, and social, cohesive broad ability domains? If so, factor analysis should suggest that they are distinct. If not, it should be emphasized that there are many other kinds of theoretical distinctions that factor analysis does not detect <span class="citation" data-cites="schneider2016integrating">(<a href="#ref-schneider2016integrating" role="doc-biblioref">Schneider et al., 2016</a>)</span>. They may be conceptual categories that are useful for pragmatic description even if factor analysis does not show them to be cohesive.</p>
<section id="exploratory-factor-analysis" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-factor-analysis">Exploratory Factor Analysis</h2>
<p>I used the RESCA-E correlation matrix for the entire standardization sample (<em>N</em> = 825) to conduct all analyses. I removed the Social Communication Inventory scale from consideration because it is not an ability test. It has low correlations with the other tests and thus would produce an uninformative singleton factor.</p>
<p>To see how many factors to extract, I conducted a parallel analysis using the <code>psych</code> package <span class="citation" data-cites="revelle2016psych">(<a href="#ref-revelle2016psych" role="doc-biblioref">Revelle, 2016</a>)</span> in R. I used the type of parallel analysis based on principal factors rather than the more commonly-used principal components method because it is more accurate when there is a large general factor <span class="citation" data-cites="crawford2010evaluation">(<a href="#ref-crawford2010evaluation" role="doc-biblioref">Crawford et al., 2010</a>)</span>. As seen in <a href="#fig-parallel" class="quarto-xref">Figure&nbsp;2</a>, the results suggest that extracting five principal factors is a reasonable choice.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-parallel" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-parallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="RESCAE_files/figure-html/fig-parallel-1.svg" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-parallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Principal Factor Analysis–Based Parallel Analysis of the RESCA-E Subtests
</figcaption>
</figure>
</div>
</div>
</div>
<p>I extracted 1, 2, 3, 4, and then 5 principal factors with an oblimin rotation (See Tables 1–5). In no solution did the three language domains—expressive, receptive, and social communication—hang together. Does this result mean that the structure of RESCA-E is not valid? No, but it suggests that the three ability domains are not the same kind of constructs that factor-analysts are used to. The three language domains are not cohesive clusters of relatively unitary abilities, and the subtests in each of the three composite scores will often not hang together as closely as factor-based composites would.</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption><em>Table 2</em>. Factor loadings of RESCA-E subtests in a principal factor analysis with oblimin rotation (1-factor solution)</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Domain</th>
<th style="text-align: right;">PA1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Comprehension of Stories and Questions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.75</td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Labeling of Vocabulary</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.75</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.73</td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Vocabulary</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.72</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Social and Language Inference</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.69</td>
</tr>
<tr class="even">
<td style="text-align: left;">Situational Language Use</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.68</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Use of Basic Morphology and Syntax</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.66</td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Basic Morphology and Syntax</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.65</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Narrative Skills</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.63</td>
</tr>
<tr class="even">
<td style="text-align: left;">Executing Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.61</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Body Language and Vocal Emotion</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.59</td>
</tr>
<tr class="even">
<td style="text-align: left;">Elicited Body Language</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.54</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Skills for Describing and Explaining</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.54</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption><em>Table 3</em>. Factor loadings of RESCA-E subtests in a principal factor analysis with oblimin rotation (2-factor solution)</caption>
<colgroup>
<col style="width: 72%">
<col style="width: 16%">
<col style="width: 5%">
<col style="width: 5%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Domain</th>
<th style="text-align: right;">PA1</th>
<th style="text-align: right;">PA2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Social and Language Inference</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.80</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Basic Morphology and Syntax</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.77</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Vocabulary</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.73</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.72</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Stories and Questions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.67</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Labeling of Vocabulary</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.63</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Executing Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.59</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Use of Basic Morphology and Syntax</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.57</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Body Language and Vocal Emotion</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.55</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Situational Language Use</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.47</td>
<td style="text-align: right;">.28</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Elicited Body Language</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.33</td>
<td style="text-align: right;">.28</td>
</tr>
<tr class="even">
<td style="text-align: left;">Narrative Skills</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.75</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Skills for Describing and Explaining</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.70</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption><em>Table 4</em>. Factor loadings of RESCA-E subtests in a principal factor analysis with oblimin rotation (3-factor solution)</caption>
<colgroup>
<col style="width: 68%">
<col style="width: 15%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Domain</th>
<th style="text-align: right;">PA1</th>
<th style="text-align: right;">PA2</th>
<th style="text-align: right;">PA3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Comprehension of Vocabulary</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.76</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Labeling of Vocabulary</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.74</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Social and Language Inference</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.74</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Stories and Questions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.69</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Basic Morphology and Syntax</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.68</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.65</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Body Language and Vocal Emotion</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.53</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Skills for Describing and Explaining</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.75</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Narrative Skills</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.61</td>
<td style="text-align: right;">.23</td>
</tr>
<tr class="even">
<td style="text-align: left;">Situational Language Use</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.20</td>
<td style="text-align: right;">.55</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Elicited Body Language</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.20</td>
<td style="text-align: right;">.44</td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Use of Basic Morphology and Syntax</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.32</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.39</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Executing Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.36</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.37</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption><em>Table 5</em>. Factor loadings of RESCA-E subtests in a principal factor analysis with oblimin rotation (4-factor solution)</caption>
<colgroup>
<col style="width: 64%">
<col style="width: 14%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Domain</th>
<th style="text-align: right;">PA1</th>
<th style="text-align: right;">PA3</th>
<th style="text-align: right;">PA2</th>
<th style="text-align: right;">PA4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Comprehension of Vocabulary</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.78</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Labeling of Vocabulary</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.75</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Social and Language Inference</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.69</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Stories and Questions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.65</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Basic Morphology and Syntax</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.62</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.56</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.24</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Body Language and Vocal Emotion</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.54</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Use of Basic Morphology and Syntax</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.32</td>
<td style="text-align: right;">.25</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Situational Language Use</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.93</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Elicited Body Language</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.34</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Skills for Describing and Explaining</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.71</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Narrative Skills</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.68</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Executing Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.79</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption><em>Table 6</em>. Factor loadings of RESCA-E subtests in a principal factor analysis with oblimin rotation (5-factor solution)</caption>
<colgroup>
<col style="width: 61%">
<col style="width: 13%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Domain</th>
<th style="text-align: right;">PA1</th>
<th style="text-align: right;">PA2</th>
<th style="text-align: right;">PA5</th>
<th style="text-align: right;">PA3</th>
<th style="text-align: right;">PA4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Comprehension of Vocabulary</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.73</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Expressive Labeling of Vocabulary</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;">.65</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Stories and Questions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.52</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Social and Language Inference</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.51</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.24</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Body Language and Vocal Emotion</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;">.49</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.23</td>
</tr>
<tr class="even">
<td style="text-align: left;">Comprehension of Basic Morphology and Syntax</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;">.39</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.31</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Skills for Describing and Explaining</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.79</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Narrative Skills</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.65</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Comprehension of Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.68</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Executing Oral Directions</td>
<td style="text-align: left;">Receptive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.51</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.29</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Elicited Body Language</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.83</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Situational Language Use</td>
<td style="text-align: left;">Social</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.33</td>
<td style="text-align: right;">.28</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Expressive Use of Basic Morphology and Syntax</td>
<td style="text-align: left;">Expressive</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">.52</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="might-mulitdimensional-scaling-detect-a-faceted-relationship-among-the-three-language-domains" class="level2">
<h2 class="anchored" data-anchor-id="might-mulitdimensional-scaling-detect-a-faceted-relationship-among-the-three-language-domains">Might Mulitdimensional Scaling Detect a Faceted Relationship Among the Three Language Domains?</h2>
<p>Is there some sort of faceted relationship that the three language domains might have that factor analysis cannot detect (e.g., process × domain)? If so, it should show up in a multidimensional scaling (MDS). Using the correlations subtracted from 1 as distances, a two-dimensional MDS suggests no obvious cohesion of the three domains (See <a href="#fig-mds2d" class="quarto-xref">Figure&nbsp;3</a>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-mds2d" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mds2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="RESCAE_files/figure-html/fig-mds2d-1.svg" class="img-fluid figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mds2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Two-dimensional Multidimensional Scaling of the RESCA-E Subtests. Blue = Receptive, Red = Expressive, Green = Social Communication
</figcaption>
</figure>
</div>
</div>
</div>
<p>Perhaps there is order that can be seen in three dimensions that cannot be detected in two. You can grab <a href="#fig-mds3d" class="quarto-xref">Figure&nbsp;4</a> with your mouse and rotate it. I am unable to detect any patterns that show the three domains to be elegantly cohesive.</p>
<div class="cell">
<div id="fig-mds3d" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored no-overflow-x">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mds3d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="rgl84812" style="width:100%;height:650px;" class="rglWebGL html-widget" role="img" aria-labelledby="rgl84812-aria"></div>
<script type="application/json" data-for="rgl84812">{"x":{"material":{"color":"#000000","alpha":1,"lit":true,"ambient":"#000000","specular":"#FFFFFF","emission":"#000000","shininess":50,"smooth":true,"front":"filled","back":"filled","size":3,"lwd":1,"fog":true,"point_antialias":false,"line_antialias":false,"texture":null,"textype":"rgb","texmode":"modulate","texmipmap":false,"texminfilter":"linear","texmagfilter":"linear","texenvmap":false,"depth_mask":true,"depth_test":"less","isTransparent":false,"polygon_offset":[0,0],"margin":"","floating":false,"tag":"","blend":["src_alpha","one_minus_src_alpha"]},"rootSubscene":6,"objects":{"13":{"id":13,"type":"lines","material":{"lit":false},"vertices":"0","colors":"1","centers":"2","ignoreExtent":false,"flags":32832},"15":{"id":15,"type":"text","material":{"lit":false,"margin":0,"floating":true,"edge":[0,1,1]},"vertices":"3","colors":"4","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"5","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"16":{"id":16,"type":"text","material":{"lit":false,"margin":1,"floating":true,"edge":[1,1,1]},"vertices":"6","colors":"7","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"8","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"17":{"id":17,"type":"text","material":{"lit":false,"margin":2,"floating":true,"edge":[1,1,1]},"vertices":"9","colors":"10","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"11","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"18":{"id":18,"type":"text","material":{"lit":false},"vertices":"12","colors":"13","texts":[["Comprehension of Vocabulary"],["Comprehension of Oral Directions"],["Comprehension of Stories and Questions"],["Comprehension of Basic Morphology and Syntax"],["Executing Oral Directions"],["Expressive Labeling of Vocabulary"],["Expressive Skills for Describing and Explaining"],["Narrative Skills"],["Expressive Use of Basic Morphology and Syntax"],["Comprehension of Body Language and Vocal Emotion"],["Social and Language Inference"],["Situational Language Use"],["Elicited Body Language"]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"14","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"10":{"id":10,"type":"light","vertices":[[0,0,1]],"colors":[[1,1,1,1],[1,1,1,1],[1,1,1,1]],"viewpoint":true,"finite":false},"12":{"id":12,"type":"background","material":{"lit":false,"back":"lines"},"colors":"15","centers":"16","sphere":false,"fogtype":"none","fogscale":1,"flags":32768},"14":{"id":14,"type":"bboxdeco","material":{"front":"culled","back":"culled"},"colors":"17","axes":{"mode":["none","none","none"],"step":[-1,-1,-1],"nticks":[0,0,0],"marklen":[15,15,15],"expand":[1.029999971389771,1.029999971389771,1.029999971389771]},"draw_front":false,"flags":32769},"6":{"id":6,"type":"subscene","par3d":{"antialias":8,"FOV":30,"ignoreExtent":false,"listeners":6,"mouseMode":{"none":"none","left":"trackball","right":"zoom","middle":"fov","wheel":"pull"},"observer":[0,0,2.31765079498291],"modelMatrix":[[0.8736469745635986,0,0,-0.07076582312583923],[0,0.3524267971515656,1.086503148078918,0.05582863464951515],[0,-0.9682846069335938,0.3954548239707947,-2.364319324493408],[0,0,0,1]],"projMatrix":[[3.732050895690918,0,0,0],[0,3.732050895690918,0,0],[0,0,-3.863703727722168,-8.354864120483398],[0,0,-1,0]],"skipRedraw":false,"userMatrix":[[1,0,0,0],[0,0.3420201433256682,0.9396926207859085,0],[0,-0.9396926207859085,0.3420201433256682,0],[0,0,0,1]],"userProjection":[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],"scale":[0.8736469745635986,1.030426979064941,1.156232476234436],"viewport":{"x":0,"y":0,"width":1,"height":1},"zoom":1,"bbox":[-0.2319569736719131,0.3939579129219055,-0.3264305591583252,0.2042510360479355,-0.2680382430553436,0.2049018144607544],"windowRect":[0,0,256,256],"family":"serif","font":1,"cex":1,"useFreeType":false,"fontname":"NULL","maxClipPlanes":2147483647,"glVersion":"NA","activeSubscene":0},"embeddings":{"viewport":"replace","projection":"replace","model":"replace","mouse":"replace"},"objects":[12,14,13,15,16,17,18,10],"subscenes":[],"flags":34129}},"crosstalk":{"key":[],"group":[],"id":[],"options":[]},"width":768,"height":768,"buffer":{"accessors":[{"bufferView":0,"componentType":5126,"count":4,"type":"VEC3"},{"bufferView":1,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":2,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":3,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":4,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":5,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":6,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":7,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":8,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":9,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":10,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":11,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":12,"componentType":5126,"count":13,"type":"VEC3"},{"bufferView":13,"componentType":5121,"count":14,"type":"VEC4","normalized":true},{"bufferView":14,"componentType":5126,"count":13,"type":"VEC3"},{"bufferView":15,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":16,"componentType":5121,"count":1,"type":"VEC3"},{"bufferView":17,"componentType":5121,"count":1,"type":"VEC4"}],"bufferViews":[{"buffer":0,"byteLength":48,"byteOffset":0},{"buffer":0,"byteLength":4,"byteOffset":48},{"buffer":0,"byteLength":24,"byteOffset":52},{"buffer":0,"byteLength":12,"byteOffset":76},{"buffer":0,"byteLength":4,"byteOffset":88},{"buffer":0,"byteLength":12,"byteOffset":92},{"buffer":0,"byteLength":12,"byteOffset":104},{"buffer":0,"byteLength":4,"byteOffset":116},{"buffer":0,"byteLength":12,"byteOffset":120},{"buffer":0,"byteLength":12,"byteOffset":132},{"buffer":0,"byteLength":4,"byteOffset":144},{"buffer":0,"byteLength":12,"byteOffset":148},{"buffer":0,"byteLength":156,"byteOffset":160},{"buffer":0,"byteLength":56,"byteOffset":316},{"buffer":0,"byteLength":156,"byteOffset":372},{"buffer":0,"byteLength":4,"byteOffset":528},{"buffer":0,"byteLength":3,"byteOffset":532},{"buffer":0,"byteLength":4,"byteOffset":535}],"buffers":[{"byteLength":539,"bytes":"IYZtvughp75PPIm+IYZtvughp75PPIm+2rTJPi8nUT7I0VE+2rTJPi8nUT7I0VE+AAAAASGG\nbb7oIae+TzyJvtq0yT4vJ1E+yNFRPgAAwH8AAIBAAACAPwAAAAEAAMB/AACAQAAAgD8AAMB/\nAACAQAAAgD8AAAABAADAfwAAgEAAAIA/AADAfwAAgEAAAIA/AAAAAQAAwH8AAIBAAACAP7SU\n5L2gzKo9u+M1vWZVtL1MVGC89fpNPngDQr2y+pQ9RaaxPCGGbb6swRs9oumyPZf+DL6F022+\nyNFRPhiTRrxAXyA+EcMfPNq0yT7BKUM+FQLMPQVamj6ogD0970G7PaI0SL2bHrS9W/wIvvvS\n1b0vJ1E+TzyJvlZdQ76GovU8NelnO3j3tD3XbCW+twwIvleeQT7oIae+kLkPvkFp4f9BaeH/\nQWnh/0Fp4f9BaeH/siIi/7IiIv+yIiL/siIi/0WLAP9FiwD/RYsA/0WLAP9FiwD/tJTkvaDM\nqj274zW9ZlW0vUxUYLz1+k0+eANCvbL6lD1FprE8IYZtvqzBGz2i6bI9l/4MvoXTbb7I0VE+\nGJNGvEBfID4Rwx882rTJPsEpQz4VAsw9BVqaPqiAPT3vQbs9ojRIvZsetL1b/Ai++9LVvS8n\nUT5PPIm+Vl1Dvoai9Tw16Wc7ePe0PddsJb63DAi+V55BPughp76QuQ++AQEBAQAAAAAAAAE="}]},"context":{"shiny":false,"rmarkdown":null},"vertexShader":"#line 2 1\n// File 1 is the vertex shader\n#ifdef GL_ES\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n#endif\n\nattribute vec3 aPos;\nattribute vec4 aCol;\nuniform mat4 mvMatrix;\nuniform mat4 prMatrix;\nvarying vec4 vCol;\nvarying vec4 vPosition;\n\n#ifdef NEEDS_VNORMAL\nattribute vec3 aNorm;\nuniform mat4 normMatrix;\nvarying vec4 vNormal;\n#endif\n\n#if defined(HAS_TEXTURE) || defined (IS_TEXT)\nattribute vec2 aTexcoord;\nvarying vec2 vTexcoord;\n#endif\n\n#ifdef FIXED_SIZE\nuniform vec3 textScale;\n#endif\n\n#ifdef FIXED_QUADS\nattribute vec3 aOfs;\n#endif\n\n#ifdef IS_TWOSIDED\n#ifdef HAS_NORMALS\nvarying float normz;\nuniform mat4 invPrMatrix;\n#else\nattribute vec3 aPos1;\nattribute vec3 aPos2;\nvarying float normz;\n#endif\n#endif // IS_TWOSIDED\n\n#ifdef FAT_LINES\nattribute vec3 aNext;\nattribute vec2 aPoint;\nvarying vec2 vPoint;\nvarying float vLength;\nuniform float uAspect;\nuniform float uLwd;\n#endif\n\n#ifdef USE_ENVMAP\nvarying vec3 vReflection;\n#endif\n\nvoid main(void) {\n  \n#ifndef IS_BRUSH\n#if defined(NCLIPPLANES) || !defined(FIXED_QUADS) || defined(HAS_FOG) || defined(USE_ENVMAP)\n  vPosition = mvMatrix * vec4(aPos, 1.);\n#endif\n  \n#ifndef FIXED_QUADS\n  gl_Position = prMatrix * vPosition;\n#endif\n#endif // !IS_BRUSH\n  \n#ifdef IS_POINTS\n  gl_PointSize = POINTSIZE;\n#endif\n  \n  vCol = aCol;\n  \n// USE_ENVMAP implies NEEDS_VNORMAL\n\n#ifdef NEEDS_VNORMAL\n  vNormal = normMatrix * vec4(-aNorm, dot(aNorm, aPos));\n#endif\n\n#ifdef USE_ENVMAP\n  vReflection = normalize(reflect(vPosition.xyz/vPosition.w, \n                        normalize(vNormal.xyz/vNormal.w)));\n#endif\n  \n#ifdef IS_TWOSIDED\n#ifdef HAS_NORMALS\n  /* normz should be calculated *after* projection */\n  normz = (invPrMatrix*vNormal).z;\n#else\n  vec4 pos1 = prMatrix*(mvMatrix*vec4(aPos1, 1.));\n  pos1 = pos1/pos1.w - gl_Position/gl_Position.w;\n  vec4 pos2 = prMatrix*(mvMatrix*vec4(aPos2, 1.));\n  pos2 = pos2/pos2.w - gl_Position/gl_Position.w;\n  normz = pos1.x*pos2.y - pos1.y*pos2.x;\n#endif\n#endif // IS_TWOSIDED\n  \n#ifdef NEEDS_VNORMAL\n  vNormal = vec4(normalize(vNormal.xyz), 1);\n#endif\n  \n#if defined(HAS_TEXTURE) || defined(IS_TEXT)\n  vTexcoord = aTexcoord;\n#endif\n  \n#if defined(FIXED_SIZE) && !defined(ROTATING)\n  vec4 pos = prMatrix * mvMatrix * vec4(aPos, 1.);\n  pos = pos/pos.w;\n  gl_Position = pos + vec4(aOfs*textScale, 0.);\n#endif\n  \n#if defined(IS_SPRITES) && !defined(FIXED_SIZE)\n  vec4 pos = mvMatrix * vec4(aPos, 1.);\n  pos = pos/pos.w + vec4(aOfs,  0.);\n  gl_Position = prMatrix*pos;\n#endif\n  \n#ifdef FAT_LINES\n  /* This code was inspired by Matt Deslauriers' code in \n   https://mattdesl.svbtle.com/drawing-lines-is-hard */\n  vec2 aspectVec = vec2(uAspect, 1.0);\n  mat4 projViewModel = prMatrix * mvMatrix;\n  vec4 currentProjected = projViewModel * vec4(aPos, 1.0);\n  currentProjected = currentProjected/currentProjected.w;\n  vec4 nextProjected = projViewModel * vec4(aNext, 1.0);\n  vec2 currentScreen = currentProjected.xy * aspectVec;\n  vec2 nextScreen = (nextProjected.xy / nextProjected.w) * aspectVec;\n  float len = uLwd;\n  vec2 dir = vec2(1.0, 0.0);\n  vPoint = aPoint;\n  vLength = length(nextScreen - currentScreen)/2.0;\n  vLength = vLength/(vLength + len);\n  if (vLength > 0.0) {\n    dir = normalize(nextScreen - currentScreen);\n  }\n  vec2 normal = vec2(-dir.y, dir.x);\n  dir.x /= uAspect;\n  normal.x /= uAspect;\n  vec4 offset = vec4(len*(normal*aPoint.x*aPoint.y - dir), 0.0, 0.0);\n  gl_Position = currentProjected + offset;\n#endif\n  \n#ifdef IS_BRUSH\n  gl_Position = vec4(aPos, 1.);\n#endif\n}","fragmentShader":"#line 2 2\n// File 2 is the fragment shader\n#ifdef GL_ES\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n#endif\nvarying vec4 vCol; // carries alpha\nvarying vec4 vPosition;\n#if defined(HAS_TEXTURE) || defined (IS_TEXT)\nvarying vec2 vTexcoord;\nuniform sampler2D uSampler;\n#endif\n\n#ifdef HAS_FOG\nuniform int uFogMode;\nuniform vec3 uFogColor;\nuniform vec4 uFogParms;\n#endif\n\n#if defined(IS_LIT) && !defined(FIXED_QUADS)\nvarying vec4 vNormal;\n#endif\n\n#if NCLIPPLANES > 0\nuniform vec4 vClipplane[NCLIPPLANES];\n#endif\n\n#if NLIGHTS > 0\nuniform mat4 mvMatrix;\n#endif\n\n#ifdef IS_LIT\nuniform vec3 emission;\nuniform float shininess;\n#if NLIGHTS > 0\nuniform vec3 ambient[NLIGHTS];\nuniform vec3 specular[NLIGHTS]; // light*material\nuniform vec3 diffuse[NLIGHTS];\nuniform vec3 lightDir[NLIGHTS];\nuniform bool viewpoint[NLIGHTS];\nuniform bool finite[NLIGHTS];\n#endif\n#endif // IS_LIT\n\n#ifdef IS_TWOSIDED\nuniform bool front;\nvarying float normz;\n#endif\n\n#ifdef FAT_LINES\nvarying vec2 vPoint;\nvarying float vLength;\n#endif\n\n#ifdef USE_ENVMAP\nvarying vec3 vReflection;\n#endif\n\nvoid main(void) {\n  vec4 fragColor;\n#ifdef FAT_LINES\n  vec2 point = vPoint;\n  bool neg = point.y < 0.0;\n  point.y = neg ? (point.y + vLength)/(1.0 - vLength) :\n                 -(point.y - vLength)/(1.0 - vLength);\n#if defined(IS_TRANSPARENT) && defined(IS_LINESTRIP)\n  if (neg && length(point) <= 1.0) discard;\n#endif\n  point.y = min(point.y, 0.0);\n  if (length(point) > 1.0) discard;\n#endif // FAT_LINES\n  \n#ifdef ROUND_POINTS\n  vec2 coord = gl_PointCoord - vec2(0.5);\n  if (length(coord) > 0.5) discard;\n#endif\n  \n#if NCLIPPLANES > 0\n  for (int i = 0; i < NCLIPPLANES; i++)\n    if (dot(vPosition, vClipplane[i]) < 0.0) discard;\n#endif\n    \n#ifdef FIXED_QUADS\n    vec3 n = vec3(0., 0., 1.);\n#elif defined(IS_LIT)\n    vec3 n = normalize(vNormal.xyz);\n#endif\n    \n#ifdef IS_TWOSIDED\n    if ((normz <= 0.) != front) discard;\n#endif\n\n#ifdef IS_LIT\n    vec3 eye = normalize(-vPosition.xyz/vPosition.w);\n    vec3 lightdir;\n    vec4 colDiff;\n    vec3 halfVec;\n    vec4 lighteffect = vec4(emission, 0.);\n    vec3 col;\n    float nDotL;\n#ifdef FIXED_QUADS\n    n = -faceforward(n, n, eye);\n#endif\n    \n#if NLIGHTS > 0\n    // Simulate two-sided lighting\n    if (n.z < 0.0)\n      n = -n;\n    for (int i=0;i<NLIGHTS;i++) {\n      colDiff = vec4(vCol.rgb * diffuse[i], vCol.a);\n      lightdir = lightDir[i];\n      if (!viewpoint[i]) {\n        if (finite[i]) {\n          lightdir = (mvMatrix * vec4(lightdir, 1.)).xyz;\n        } else {\n          lightdir = (mvMatrix * vec4(lightdir, 0.)).xyz;\n        }\n      }\n      if (!finite[i]) {\n        halfVec = normalize(lightdir + eye);\n      } else {\n        lightdir = normalize(lightdir - vPosition.xyz/vPosition.w);\n        halfVec = normalize(lightdir + eye);\n      }\n      col = ambient[i];\n      nDotL = dot(n, lightdir);\n      col = col + max(nDotL, 0.) * colDiff.rgb;\n      col = col + pow(max(dot(halfVec, n), 0.), shininess) * specular[i];\n      lighteffect = lighteffect + vec4(col, colDiff.a);\n    }\n#endif\n    \n#else // not IS_LIT\n    vec4 colDiff = vCol;\n    vec4 lighteffect = colDiff;\n#endif\n    \n#ifdef IS_TEXT\n    vec4 textureColor = lighteffect*texture2D(uSampler, vTexcoord);\n#endif\n    \n#ifdef HAS_TEXTURE\n\n// These calculations use the definitions from \n// https://docs.gl/gl3/glTexEnv\n\n#ifdef USE_ENVMAP\n    float m = 2.0 * sqrt(dot(vReflection, vReflection) + 2.0*vReflection.z + 1.0);\n    vec4 textureColor = texture2D(uSampler, vReflection.xy / m + vec2(0.5, 0.5));\n#else\n    vec4 textureColor = texture2D(uSampler, vTexcoord);\n#endif\n\n#ifdef TEXTURE_rgb\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(textureColor.rgb, lighteffect.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = lighteffect*vec4(textureColor.rgb, 1.);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - textureColor.rgb) * lighteffect.rgb, lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(lighteffect.rgb + textureColor.rgb, lighteffect.a);\n#endif\n\n#endif //TEXTURE_rgb\n        \n#ifdef TEXTURE_rgba\n\n#ifdef TEXMODE_replace\n// already done\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = lighteffect*textureColor;\n#endif\n\n#ifdef TEXMODE_decal\n    textureColor = vec4((1. - textureColor.a)*lighteffect.rgb) +\n                     textureColor.a*textureColor.rgb, \n                     lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - textureColor.rgb) * lighteffect.rgb,\n                    lighteffect.a*textureColor.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(lighteffect.rgb + textureColor.rgb,\n                    lighteffect.a*textureColor.a);\n#endif\n    \n#endif //TEXTURE_rgba\n    \n#ifdef TEXTURE_alpha\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(lighteffect.rgb, luminance);\n#endif \n\n#if defined(TEXMODE_modulate) || defined(TEXMODE_blend) || defined(TEXMODE_add)\n    textureColor = vec4(lighteffect.rgb, lighteffect.a*luminance);\n#endif\n \n#endif // TEXTURE_alpha\n    \n// The TEXTURE_luminance values are not from that reference    \n#ifdef TEXTURE_luminance\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(luminance, luminance, luminance, lighteffect.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = vec4(luminance*lighteffect.rgb, lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - luminance)*lighteffect.rgb,\n                        lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(luminance + lighteffect.rgb, lighteffect.a);\n#endif\n\n#endif // TEXTURE_luminance\n \n    \n#ifdef TEXTURE_luminance_alpha\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(luminance, luminance, luminance, textureColor.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = vec4(luminance*lighteffect.rgb, \n                        textureColor.a*lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - luminance)*lighteffect.rgb,\n                        textureColor.a*lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(luminance + lighteffect.rgb, \n                        textureColor.a*lighteffect.a);\n\n#endif\n\n#endif // TEXTURE_luminance_alpha\n    \n    fragColor = textureColor;\n\n#elif defined(IS_TEXT)\n    if (textureColor.a < 0.1)\n      discard;\n    else\n      fragColor = textureColor;\n#else\n    fragColor = lighteffect;\n#endif // HAS_TEXTURE\n    \n#ifdef HAS_FOG\n    // uFogParms elements: x = near, y = far, z = fogscale, w = (1-sin(FOV/2))/(1+sin(FOV/2))\n    // In Exp and Exp2: use density = density/far\n    // fogF will be the proportion of fog\n    // Initialize it to the linear value\n    float fogF;\n    if (uFogMode > 0) {\n      fogF = (uFogParms.y - vPosition.z/vPosition.w)/(uFogParms.y - uFogParms.x);\n      if (uFogMode > 1)\n        fogF = mix(uFogParms.w, 1.0, fogF);\n      fogF = fogF*uFogParms.z;\n      if (uFogMode == 2)\n        fogF = 1.0 - exp(-fogF);\n      // Docs are wrong: use (density*c)^2, not density*c^2\n      // https://gitlab.freedesktop.org/mesa/mesa/-/blob/master/src/mesa/swrast/s_fog.c#L58\n      else if (uFogMode == 3)\n        fogF = 1.0 - exp(-fogF*fogF);\n      fogF = clamp(fogF, 0.0, 1.0);\n      gl_FragColor = vec4(mix(fragColor.rgb, uFogColor, fogF), fragColor.a);\n    } else gl_FragColor = fragColor;\n#else\n    gl_FragColor = fragColor;\n#endif // HAS_FOG\n    \n}","players":[],"webGLoptions":{"preserveDrawingBuffer":true},"fastTransparency":true},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mds3d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Three-dimensional Multidimensional Scaling of the RESCA-E Subtests. Blue = Receptive, Red = Expressive, Green = Social Communication
</figcaption>
</figure>
</div>
</div>
</section>
<section id="confirmatory-factor-analysis-to-the-rescue" class="level2">
<h2 class="anchored" data-anchor-id="confirmatory-factor-analysis-to-the-rescue">Confirmatory Factor Analysis to the rescue?</h2>
<p>These previous analyses were exploratory analyses. Would confirmatory factor analysis (CFA) have supported the hypothesis that the three domains are cohesive? No, but it might have given the illusion of such a finding.</p>
<p>If we conduct a one-factor CFA (<a href="#fig-genfactor" class="quarto-xref">Figure&nbsp;5</a>) and compare it to a three-factor CFA (<a href="#fig-factor3" class="quarto-xref">Figure&nbsp;6</a>), the model fit improves significantly (<em>p</em> &lt; .001). The loadings all look healthy in <a href="#fig-factor3" class="quarto-xref">Figure&nbsp;6</a>. What is the problem? The problem is that the factors are almost perfectly correlated, meaning that if the latent variables could be measured without error, there would be little point in distinguishing among them. Had Figure 5.1 of the <em>RESCA-E Technical Manual</em> shown the correlations among the latent factors, this would have been plainly visible (Compare with <a href="#fig-factorcore" class="quarto-xref">Figure&nbsp;7</a>). In contrast, the correlations among the three-factor EFA latent variables are between .62, and .84, which means that they do not yield redundant information.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-genfactor" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-genfactor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="RESCAE_files/figure-html/fig-genfactor-1.svg" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-genfactor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: General-factor CFA of RESCA-E Subtests
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-factor3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-factor3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="RESCAE_files/figure-html/fig-factor3-1.svg" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-factor3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Three-factor CFA of RESCA-E Subtests
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-factorcore" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-factorcore-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="RESCAE_files/figure-html/fig-factorcore-1.svg" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-factorcore-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Three-factor CFA of RESCA-E Core Subtests
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="conclusion-the-three-resca-e-language-domains-are-descriptive-categories-not-distinct-abilities" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-the-three-resca-e-language-domains-are-descriptive-categories-not-distinct-abilities">Conclusion: The Three RESCA-E Language Domains Are Descriptive Categories, Not Distinct Abilities</h2>
<p>The available evidence suggests that the distinction between receptive, expressive, and social communication abilities is mostly descriptive. There are language abilities that are legitimately classified as <em>receptive</em> or <em>expressive</em>, or <em>social</em>, but no cohesive ability constructs we could call <em>receptive language ability</em>, <em>expressive language ability</em>, or <em>social communication ability</em>. If Carroll could not find them with 400+ data sets, we should not be surprised to not find them here in this one. The three RESCA-E composites should be interpreted in this light.</p>
</section>
<section id="alternative-structure" class="level2">
<h2 class="anchored" data-anchor-id="alternative-structure">Alternative Structure</h2>
<p>A cluster analysis can sometimes detect patterns that exploratory factor analyses miss. First, we see the correlation plot (<a href="#fig-cor" class="quarto-xref">Figure&nbsp;8</a>), with rectangles around 4 clusters (Ward’s method applied to the correlations subtracted from 1). Again, the pattern is not consistent with the 3 groupings.</p>
<div class="cell" data-fig.fullwidth="true">
<div class="cell-output-display">
<div id="fig-cor" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="RESCAE_files/figure-html/fig-cor-1.svg" class="img-fluid figure-img" width="960">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Correlation plot of the RESCA-E Subtests. Blue = Receptive, Red = Expressive, Green = Social Communication
</figcaption>
</figure>
</div>
</div>
</div>
<p>Instead, in the dendrogram in <a href="#fig-hierarchical" class="quarto-xref">Figure&nbsp;9</a>, four clusters are highlighted plus a very narrow vocabulary cluster is singled out.</p>
<div class="cell" data-fig.fullwidth="true">
<div class="cell-output-display">
<div id="fig-hierarchical" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hierarchical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="RESCAE_files/figure-html/fig-hierarchical-1.svg" class="img-fluid figure-img" width="960">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hierarchical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Hierarchical Cluster Analysis of the RESCA-E Subtest Correlation Matrix (Ward’s Method). Suggested intepretations of clusters in blue.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Instead of a three-part division between receptive, expressive, and social communication, this analysis suggests a 2 × 2 matrix (See <a href="#fig-matrix" class="quarto-xref">Figure&nbsp;10</a>). There are two expressive clusters, one of which emphasizes social communication whereas the other emphasizes narrative communication (not that narrative is non-social). There are two “receptive” clusters, one of which is more social in that it is about understanding others’ intentions, sometimes via understanding English syntax. The other comprehension cluster consists of tests measuring semantic knowledge (e.g., vocabulary) and narratives.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-matrix" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="RESCAE_files/figure-html/fig-matrix-1.svg" class="img-fluid figure-img" width="864">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Matrix of Concpetual Groupings
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-regroup" class="quarto-xref">Figure&nbsp;11</a> shows that the 2 × 2 structure suggested by hierarchical cluster analysis is also present in the the 3D MDS model. Grab the picture with your mouse and move it around to see the structure better.</p>
<div class="cell">
<div id="fig-regroup" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored no-overflow-x">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-regroup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="rgl11117" style="width:100%;height:650px;" class="rglWebGL html-widget" role="img" aria-labelledby="rgl11117-aria"></div>
<script type="application/json" data-for="rgl11117">{"x":{"material":{"color":"#000000","alpha":1,"lit":true,"ambient":"#000000","specular":"#FFFFFF","emission":"#000000","shininess":50,"smooth":true,"front":"filled","back":"filled","size":3,"lwd":1,"fog":true,"point_antialias":false,"line_antialias":false,"texture":null,"textype":"rgb","texmode":"modulate","texmipmap":false,"texminfilter":"linear","texmagfilter":"linear","texenvmap":false,"depth_mask":true,"depth_test":"less","isTransparent":false,"polygon_offset":[0,0],"margin":"","floating":false,"tag":"","blend":["src_alpha","one_minus_src_alpha"]},"rootSubscene":6,"objects":{"26":{"id":26,"type":"lines","material":{"lit":false},"vertices":"0","colors":"1","centers":"2","ignoreExtent":false,"flags":32832},"28":{"id":28,"type":"text","material":{"lit":false,"margin":0,"floating":true,"edge":[0,1,1]},"vertices":"3","colors":"4","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"5","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"29":{"id":29,"type":"text","material":{"lit":false,"margin":1,"floating":true,"edge":[1,1,1]},"vertices":"6","colors":"7","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"8","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"30":{"id":30,"type":"text","material":{"lit":false,"margin":2,"floating":true,"edge":[1,1,1]},"vertices":"9","colors":"10","texts":[[""]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"11","family":[["serif"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"31":{"id":31,"type":"text","material":{"lit":false},"vertices":"12","colors":"13","texts":[["Expressive Skills for Describing and Explaining"],["Narrative Skills"],["Elicited Body Language"],["Expressive Use of Basic Morphology and Syntax"],["Situational Language Use"],["Executing Oral Directions"],["Social and Language Inference"],["Comprehension of Oral Directions"],["Comprehension of Basic Morphology and Syntax"],["Comprehension of Body Language and Vocal Emotion"],["Comprehension of Stories and Questions"],["Expressive Labeling of Vocabulary"],["Comprehension of Vocabulary"]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"14","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"32":{"id":32,"type":"lines","material":{"lit":false},"vertices":"15","colors":"16","centers":"17","ignoreExtent":false,"flags":32832},"33":{"id":33,"type":"lines","material":{"lit":false},"vertices":"18","colors":"19","centers":"20","ignoreExtent":false,"flags":32832},"34":{"id":34,"type":"lines","material":{"lit":false},"vertices":"21","colors":"22","centers":"23","ignoreExtent":false,"flags":32832},"35":{"id":35,"type":"lines","material":{"lit":false},"vertices":"24","colors":"25","centers":"26","ignoreExtent":false,"flags":32832},"36":{"id":36,"type":"lines","material":{"lit":false},"vertices":"27","colors":"28","centers":"29","ignoreExtent":false,"flags":32832},"37":{"id":37,"type":"lines","material":{"lit":false},"vertices":"30","colors":"31","centers":"32","ignoreExtent":false,"flags":32832},"38":{"id":38,"type":"lines","material":{"lit":false},"vertices":"33","colors":"34","centers":"35","ignoreExtent":false,"flags":32832},"39":{"id":39,"type":"lines","material":{"lit":false},"vertices":"36","colors":"37","centers":"38","ignoreExtent":false,"flags":32832},"40":{"id":40,"type":"lines","material":{"lit":false},"vertices":"39","colors":"40","centers":"41","ignoreExtent":false,"flags":32832},"41":{"id":41,"type":"lines","material":{"lit":false},"vertices":"42","colors":"43","centers":"44","ignoreExtent":false,"flags":32832},"42":{"id":42,"type":"lines","material":{"lit":false},"vertices":"45","colors":"46","centers":"47","ignoreExtent":false,"flags":32832},"43":{"id":43,"type":"lines","material":{"lit":false},"vertices":"48","colors":"49","centers":"50","ignoreExtent":false,"flags":32832},"44":{"id":44,"type":"text","material":{"lit":false},"vertices":"51","colors":"52","texts":[["Narrative/Semantic Communication"]],"cex":[[1.5]],"adj":[[0.5,0.5,0.5]],"centers":"53","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"45":{"id":45,"type":"text","material":{"lit":false},"vertices":"54","colors":"55","texts":[["Social/Syntactic Communication"]],"cex":[[1.5]],"adj":[[0.5,0.5,0.5]],"centers":"56","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"46":{"id":46,"type":"text","material":{"lit":false},"vertices":"57","colors":"58","texts":[["Social/Syntactic Comprehension"]],"cex":[[1.5]],"adj":[[0.5,0.5,0.5]],"centers":"59","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"47":{"id":47,"type":"text","material":{"lit":false},"vertices":"60","colors":"61","texts":[["Narrative/Semantic Comprehension"]],"cex":[[1.5]],"adj":[[0.5,0.5,0.5]],"centers":"62","family":[["serif"]],"font":[[1]],"ignoreExtent":false,"flags":33808},"10":{"id":10,"type":"light","vertices":[[0,0,1]],"colors":[[1,1,1,1],[1,1,1,1],[1,1,1,1]],"viewpoint":true,"finite":false},"12":{"id":12,"type":"background","material":{"lit":false,"back":"lines"},"colors":"63","centers":"64","sphere":false,"fogtype":"none","fogscale":1,"flags":32768},"27":{"id":27,"type":"bboxdeco","material":{"front":"culled","back":"culled"},"colors":"65","axes":{"mode":["none","none","none"],"step":[-1,-1,-1],"nticks":[0,0,0],"marklen":[15,15,15],"expand":[1.029999971389771,1.029999971389771,1.029999971389771]},"draw_front":false,"flags":32769},"6":{"id":6,"type":"subscene","par3d":{"antialias":8,"FOV":30,"ignoreExtent":false,"listeners":6,"mouseMode":{"none":"none","left":"trackball","right":"zoom","middle":"fov","wheel":"pull"},"observer":[0,0,2.31765079498291],"modelMatrix":[[0.8736469745635986,0,0,-0.07076582312583923],[0,0.3524267971515656,1.086503148078918,0.05582863464951515],[0,-0.9682846069335938,0.3954548239707947,-2.364319324493408],[0,0,0,1]],"projMatrix":[[3.732050895690918,0,0,0],[0,3.732050895690918,0,0],[0,0,-3.863703727722168,-8.354864120483398],[0,0,-1,0]],"skipRedraw":false,"userMatrix":[[1,0,0,0],[0,0.3420201433256682,0.9396926207859085,0],[0,-0.9396926207859085,0.3420201433256682,0],[0,0,0,1]],"userProjection":[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],"scale":[0.8736469745635986,1.030426979064941,1.156232476234436],"viewport":{"x":0,"y":0,"width":1,"height":1},"zoom":1,"bbox":[-0.2319569736719131,0.3939579129219055,-0.3264305591583252,0.2042510360479355,-0.2680382430553436,0.2049018144607544],"windowRect":[0,0,256,256],"family":"serif","font":1,"cex":1,"useFreeType":false,"fontname":"NULL","maxClipPlanes":2147483647,"glVersion":"NA","activeSubscene":0},"embeddings":{"viewport":"replace","projection":"replace","model":"replace","mouse":"replace"},"objects":[12,27,26,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,10],"subscenes":[],"flags":34129}},"crosstalk":{"key":[],"group":[],"id":[],"options":[]},"width":768,"height":768,"buffer":{"accessors":[{"bufferView":0,"componentType":5126,"count":4,"type":"VEC3"},{"bufferView":1,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":2,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":3,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":4,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":5,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":6,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":7,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":8,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":9,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":10,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":11,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":12,"componentType":5126,"count":13,"type":"VEC3"},{"bufferView":13,"componentType":5121,"count":13,"type":"VEC4","normalized":true},{"bufferView":14,"componentType":5126,"count":13,"type":"VEC3"},{"bufferView":15,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":16,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":17,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":18,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":19,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":20,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":21,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":22,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":23,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":24,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":25,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":26,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":27,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":28,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":29,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":30,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":31,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":32,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":33,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":34,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":35,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":36,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":37,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":38,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":39,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":40,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":41,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":42,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":43,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":44,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":45,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":46,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":47,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":48,"componentType":5126,"count":2,"type":"VEC3"},{"bufferView":49,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":50,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":51,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":52,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":53,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":54,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":55,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":56,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":57,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":58,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":59,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":60,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":61,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":62,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":63,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":64,"componentType":5121,"count":1,"type":"VEC3"},{"bufferView":65,"componentType":5121,"count":1,"type":"VEC4"}],"bufferViews":[{"buffer":0,"byteLength":48,"byteOffset":0},{"buffer":0,"byteLength":4,"byteOffset":48},{"buffer":0,"byteLength":24,"byteOffset":52},{"buffer":0,"byteLength":12,"byteOffset":76},{"buffer":0,"byteLength":4,"byteOffset":88},{"buffer":0,"byteLength":12,"byteOffset":92},{"buffer":0,"byteLength":12,"byteOffset":104},{"buffer":0,"byteLength":4,"byteOffset":116},{"buffer":0,"byteLength":12,"byteOffset":120},{"buffer":0,"byteLength":12,"byteOffset":132},{"buffer":0,"byteLength":4,"byteOffset":144},{"buffer":0,"byteLength":12,"byteOffset":148},{"buffer":0,"byteLength":156,"byteOffset":160},{"buffer":0,"byteLength":52,"byteOffset":316},{"buffer":0,"byteLength":156,"byteOffset":368},{"buffer":0,"byteLength":24,"byteOffset":524},{"buffer":0,"byteLength":16,"byteOffset":548},{"buffer":0,"byteLength":12,"byteOffset":564},{"buffer":0,"byteLength":24,"byteOffset":576},{"buffer":0,"byteLength":16,"byteOffset":600},{"buffer":0,"byteLength":12,"byteOffset":616},{"buffer":0,"byteLength":24,"byteOffset":628},{"buffer":0,"byteLength":16,"byteOffset":652},{"buffer":0,"byteLength":12,"byteOffset":668},{"buffer":0,"byteLength":24,"byteOffset":680},{"buffer":0,"byteLength":16,"byteOffset":704},{"buffer":0,"byteLength":12,"byteOffset":720},{"buffer":0,"byteLength":24,"byteOffset":732},{"buffer":0,"byteLength":16,"byteOffset":756},{"buffer":0,"byteLength":12,"byteOffset":772},{"buffer":0,"byteLength":24,"byteOffset":784},{"buffer":0,"byteLength":16,"byteOffset":808},{"buffer":0,"byteLength":12,"byteOffset":824},{"buffer":0,"byteLength":24,"byteOffset":836},{"buffer":0,"byteLength":16,"byteOffset":860},{"buffer":0,"byteLength":12,"byteOffset":876},{"buffer":0,"byteLength":24,"byteOffset":888},{"buffer":0,"byteLength":16,"byteOffset":912},{"buffer":0,"byteLength":12,"byteOffset":928},{"buffer":0,"byteLength":24,"byteOffset":940},{"buffer":0,"byteLength":16,"byteOffset":964},{"buffer":0,"byteLength":12,"byteOffset":980},{"buffer":0,"byteLength":24,"byteOffset":992},{"buffer":0,"byteLength":16,"byteOffset":1016},{"buffer":0,"byteLength":12,"byteOffset":1032},{"buffer":0,"byteLength":24,"byteOffset":1044},{"buffer":0,"byteLength":16,"byteOffset":1068},{"buffer":0,"byteLength":12,"byteOffset":1084},{"buffer":0,"byteLength":24,"byteOffset":1096},{"buffer":0,"byteLength":16,"byteOffset":1120},{"buffer":0,"byteLength":12,"byteOffset":1136},{"buffer":0,"byteLength":12,"byteOffset":1148},{"buffer":0,"byteLength":16,"byteOffset":1160},{"buffer":0,"byteLength":12,"byteOffset":1176},{"buffer":0,"byteLength":12,"byteOffset":1188},{"buffer":0,"byteLength":16,"byteOffset":1200},{"buffer":0,"byteLength":12,"byteOffset":1216},{"buffer":0,"byteLength":12,"byteOffset":1228},{"buffer":0,"byteLength":16,"byteOffset":1240},{"buffer":0,"byteLength":12,"byteOffset":1256},{"buffer":0,"byteLength":12,"byteOffset":1268},{"buffer":0,"byteLength":16,"byteOffset":1280},{"buffer":0,"byteLength":12,"byteOffset":1296},{"buffer":0,"byteLength":4,"byteOffset":1308},{"buffer":0,"byteLength":3,"byteOffset":1312},{"buffer":0,"byteLength":4,"byteOffset":1315}],"buffers":[{"byteLength":1319,"bytes":"IYZtvughp75PPIm+IYZtvughp75PPIm+2rTJPi8nUT7I0VE+2rTJPi8nUT7I0VE+AAAAASGG\nbb7oIae+TzyJvtq0yT4vJ1E+yNFRPgAAwH8AAIBAAACAPwAAAAEAAMB/AACAQAAAgD8AAMB/\nAACAQAAAgD8AAAABAADAfwAAgEAAAIA/AADAfwAAgEAAAIA/AAAAAQAAwH8AAIBAAACAP9q0\nyT7BKUM+FQLMPQVamj6ogD0970G7PVeeQT7oIae+kLkPvqI0SL2bHrS9W/wIvnj3tD3XbCW+\ntwwIvpf+DL6F022+yNFRPlZdQ76GovU8NelnO2ZVtL1MVGC89fpNPiGGbb6swRs9oumyPfvS\n1b0vJ1E+TzyJvngDQr2y+pQ9RaaxPBiTRrxAXyA+EcMfPLSU5L2gzKo9u+M1vSdAi/8nQIv/\nSHb//0h2//9Idv///zAw//8wMP//MDD//zAw/4saGv+LGhr/ixoa/4saGv/atMk+wSlDPhUC\nzD0FWpo+qIA9Pe9Buz1XnkE+6CGnvpC5D76iNEi9mx60vVv8CL5497Q912wlvrcMCL6X/gy+\nhdNtvsjRUT5WXUO+hqL1PDXpZztmVbS9TFRgvPX6TT4hhm2+rMEbPaLpsj370tW9LydRPk88\nib54A0K9svqUPUWmsTwYk0a8QF8gPhHDHzy0lOS9oMyqPbvjNb2fbcE+8lMpPnUUyT1AoaI+\n82uSPY8vvj2dnBw+gYCAPoyLCz8AAIA/cAeyPuyJ8j0CosM9l+wrPu9CnL73Hw++Q9vivIGa\n3731lQm+kZCQPu3s7D4AAIA/AACAPy+Rjz2PKVS+9loMvkPVt7ztJ9G9Mc4IvvCkfT0u6Ba+\n4ToIvpGQkD7t7Ow+AACAPwAAgD9OuqE8JHz/vYmECL5s+NQ9EZ8/vpE9Cb7enTE+ywiavraI\nDr6RkJA+7ezsPgAAgD8AAIA/Cg0OPlTYeb4k4wu+JjEGvpDfT74/TlE+SPDBverkL71+fk4+\nAACAP8HAQD7BwEA+AACAP0op573K2Pu9XuZPPv234r2E7bW7/aM7PtVUVr6T1PQ8k5fXPQAA\ngD/BwEA+wcBAPgAAgD9q2CO+MllHPOO3Ez7GB2C+yTYRPTrwdz2x21C+JlwFPTzD+DwAAIA/\nwcBAPsHAQD4AAIA/vHFYvnhJCz3sKDo9YX4+vle11DtZxbA8jd0Rvt/EVb7CWD8+AACAP8HA\nQD7BwEA+AACAP/ctKL40H8+9bXHVPYu0wr3yN0w+SLJ1vk7Dr7x+TiU+IlGWvIyLCz/R0NA9\n0dDQPQAAgD9epW69OMM4PjY+BL6UscG8vUoEPtuxXzx0zxK9tyPNPd+ukTyMiws/0dDQPdHQ\n0D0AAIA/PqjzvJjc6j3mw4A8U4yLvcYInD1c2aU5Hgq6vYy+oz2YuLy8jIsLP9HQ0D3R0NA9\nAACAPzjLor2p4589MyE6vAvX4r15/8c9pvmQvaSQ173DjUI+uXR3voyLCz/R0NA90dDQPQAA\ngD/YM929wEYTPsb4H75vB7I+64nyPQKiwz2dnBw+gYCAPoyLCz8AAIA/bweyPuuJ8j0CosM9\nnQicPVKVRL6L6wq+kZCQPu3s7D4AAIA/AACAP50InD1SlUS+i+sKvjADJr4ONDa9mnD+PQAA\ngD/BwEA+wcBAPgAAgD8wAya+DjQ2vZpw/j30Do29hloEPkngj72Miws/0dDQPdHQ0D0AAIA/\n9A6NvYZaBD5J4I+9AQEBAQAAAAAAAAE="}]},"context":{"shiny":false,"rmarkdown":null},"vertexShader":"#line 2 1\n// File 1 is the vertex shader\n#ifdef GL_ES\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n#endif\n\nattribute vec3 aPos;\nattribute vec4 aCol;\nuniform mat4 mvMatrix;\nuniform mat4 prMatrix;\nvarying vec4 vCol;\nvarying vec4 vPosition;\n\n#ifdef NEEDS_VNORMAL\nattribute vec3 aNorm;\nuniform mat4 normMatrix;\nvarying vec4 vNormal;\n#endif\n\n#if defined(HAS_TEXTURE) || defined (IS_TEXT)\nattribute vec2 aTexcoord;\nvarying vec2 vTexcoord;\n#endif\n\n#ifdef FIXED_SIZE\nuniform vec3 textScale;\n#endif\n\n#ifdef FIXED_QUADS\nattribute vec3 aOfs;\n#endif\n\n#ifdef IS_TWOSIDED\n#ifdef HAS_NORMALS\nvarying float normz;\nuniform mat4 invPrMatrix;\n#else\nattribute vec3 aPos1;\nattribute vec3 aPos2;\nvarying float normz;\n#endif\n#endif // IS_TWOSIDED\n\n#ifdef FAT_LINES\nattribute vec3 aNext;\nattribute vec2 aPoint;\nvarying vec2 vPoint;\nvarying float vLength;\nuniform float uAspect;\nuniform float uLwd;\n#endif\n\n#ifdef USE_ENVMAP\nvarying vec3 vReflection;\n#endif\n\nvoid main(void) {\n  \n#ifndef IS_BRUSH\n#if defined(NCLIPPLANES) || !defined(FIXED_QUADS) || defined(HAS_FOG) || defined(USE_ENVMAP)\n  vPosition = mvMatrix * vec4(aPos, 1.);\n#endif\n  \n#ifndef FIXED_QUADS\n  gl_Position = prMatrix * vPosition;\n#endif\n#endif // !IS_BRUSH\n  \n#ifdef IS_POINTS\n  gl_PointSize = POINTSIZE;\n#endif\n  \n  vCol = aCol;\n  \n// USE_ENVMAP implies NEEDS_VNORMAL\n\n#ifdef NEEDS_VNORMAL\n  vNormal = normMatrix * vec4(-aNorm, dot(aNorm, aPos));\n#endif\n\n#ifdef USE_ENVMAP\n  vReflection = normalize(reflect(vPosition.xyz/vPosition.w, \n                        normalize(vNormal.xyz/vNormal.w)));\n#endif\n  \n#ifdef IS_TWOSIDED\n#ifdef HAS_NORMALS\n  /* normz should be calculated *after* projection */\n  normz = (invPrMatrix*vNormal).z;\n#else\n  vec4 pos1 = prMatrix*(mvMatrix*vec4(aPos1, 1.));\n  pos1 = pos1/pos1.w - gl_Position/gl_Position.w;\n  vec4 pos2 = prMatrix*(mvMatrix*vec4(aPos2, 1.));\n  pos2 = pos2/pos2.w - gl_Position/gl_Position.w;\n  normz = pos1.x*pos2.y - pos1.y*pos2.x;\n#endif\n#endif // IS_TWOSIDED\n  \n#ifdef NEEDS_VNORMAL\n  vNormal = vec4(normalize(vNormal.xyz), 1);\n#endif\n  \n#if defined(HAS_TEXTURE) || defined(IS_TEXT)\n  vTexcoord = aTexcoord;\n#endif\n  \n#if defined(FIXED_SIZE) && !defined(ROTATING)\n  vec4 pos = prMatrix * mvMatrix * vec4(aPos, 1.);\n  pos = pos/pos.w;\n  gl_Position = pos + vec4(aOfs*textScale, 0.);\n#endif\n  \n#if defined(IS_SPRITES) && !defined(FIXED_SIZE)\n  vec4 pos = mvMatrix * vec4(aPos, 1.);\n  pos = pos/pos.w + vec4(aOfs,  0.);\n  gl_Position = prMatrix*pos;\n#endif\n  \n#ifdef FAT_LINES\n  /* This code was inspired by Matt Deslauriers' code in \n   https://mattdesl.svbtle.com/drawing-lines-is-hard */\n  vec2 aspectVec = vec2(uAspect, 1.0);\n  mat4 projViewModel = prMatrix * mvMatrix;\n  vec4 currentProjected = projViewModel * vec4(aPos, 1.0);\n  currentProjected = currentProjected/currentProjected.w;\n  vec4 nextProjected = projViewModel * vec4(aNext, 1.0);\n  vec2 currentScreen = currentProjected.xy * aspectVec;\n  vec2 nextScreen = (nextProjected.xy / nextProjected.w) * aspectVec;\n  float len = uLwd;\n  vec2 dir = vec2(1.0, 0.0);\n  vPoint = aPoint;\n  vLength = length(nextScreen - currentScreen)/2.0;\n  vLength = vLength/(vLength + len);\n  if (vLength > 0.0) {\n    dir = normalize(nextScreen - currentScreen);\n  }\n  vec2 normal = vec2(-dir.y, dir.x);\n  dir.x /= uAspect;\n  normal.x /= uAspect;\n  vec4 offset = vec4(len*(normal*aPoint.x*aPoint.y - dir), 0.0, 0.0);\n  gl_Position = currentProjected + offset;\n#endif\n  \n#ifdef IS_BRUSH\n  gl_Position = vec4(aPos, 1.);\n#endif\n}","fragmentShader":"#line 2 2\n// File 2 is the fragment shader\n#ifdef GL_ES\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n#endif\nvarying vec4 vCol; // carries alpha\nvarying vec4 vPosition;\n#if defined(HAS_TEXTURE) || defined (IS_TEXT)\nvarying vec2 vTexcoord;\nuniform sampler2D uSampler;\n#endif\n\n#ifdef HAS_FOG\nuniform int uFogMode;\nuniform vec3 uFogColor;\nuniform vec4 uFogParms;\n#endif\n\n#if defined(IS_LIT) && !defined(FIXED_QUADS)\nvarying vec4 vNormal;\n#endif\n\n#if NCLIPPLANES > 0\nuniform vec4 vClipplane[NCLIPPLANES];\n#endif\n\n#if NLIGHTS > 0\nuniform mat4 mvMatrix;\n#endif\n\n#ifdef IS_LIT\nuniform vec3 emission;\nuniform float shininess;\n#if NLIGHTS > 0\nuniform vec3 ambient[NLIGHTS];\nuniform vec3 specular[NLIGHTS]; // light*material\nuniform vec3 diffuse[NLIGHTS];\nuniform vec3 lightDir[NLIGHTS];\nuniform bool viewpoint[NLIGHTS];\nuniform bool finite[NLIGHTS];\n#endif\n#endif // IS_LIT\n\n#ifdef IS_TWOSIDED\nuniform bool front;\nvarying float normz;\n#endif\n\n#ifdef FAT_LINES\nvarying vec2 vPoint;\nvarying float vLength;\n#endif\n\n#ifdef USE_ENVMAP\nvarying vec3 vReflection;\n#endif\n\nvoid main(void) {\n  vec4 fragColor;\n#ifdef FAT_LINES\n  vec2 point = vPoint;\n  bool neg = point.y < 0.0;\n  point.y = neg ? (point.y + vLength)/(1.0 - vLength) :\n                 -(point.y - vLength)/(1.0 - vLength);\n#if defined(IS_TRANSPARENT) && defined(IS_LINESTRIP)\n  if (neg && length(point) <= 1.0) discard;\n#endif\n  point.y = min(point.y, 0.0);\n  if (length(point) > 1.0) discard;\n#endif // FAT_LINES\n  \n#ifdef ROUND_POINTS\n  vec2 coord = gl_PointCoord - vec2(0.5);\n  if (length(coord) > 0.5) discard;\n#endif\n  \n#if NCLIPPLANES > 0\n  for (int i = 0; i < NCLIPPLANES; i++)\n    if (dot(vPosition, vClipplane[i]) < 0.0) discard;\n#endif\n    \n#ifdef FIXED_QUADS\n    vec3 n = vec3(0., 0., 1.);\n#elif defined(IS_LIT)\n    vec3 n = normalize(vNormal.xyz);\n#endif\n    \n#ifdef IS_TWOSIDED\n    if ((normz <= 0.) != front) discard;\n#endif\n\n#ifdef IS_LIT\n    vec3 eye = normalize(-vPosition.xyz/vPosition.w);\n    vec3 lightdir;\n    vec4 colDiff;\n    vec3 halfVec;\n    vec4 lighteffect = vec4(emission, 0.);\n    vec3 col;\n    float nDotL;\n#ifdef FIXED_QUADS\n    n = -faceforward(n, n, eye);\n#endif\n    \n#if NLIGHTS > 0\n    // Simulate two-sided lighting\n    if (n.z < 0.0)\n      n = -n;\n    for (int i=0;i<NLIGHTS;i++) {\n      colDiff = vec4(vCol.rgb * diffuse[i], vCol.a);\n      lightdir = lightDir[i];\n      if (!viewpoint[i]) {\n        if (finite[i]) {\n          lightdir = (mvMatrix * vec4(lightdir, 1.)).xyz;\n        } else {\n          lightdir = (mvMatrix * vec4(lightdir, 0.)).xyz;\n        }\n      }\n      if (!finite[i]) {\n        halfVec = normalize(lightdir + eye);\n      } else {\n        lightdir = normalize(lightdir - vPosition.xyz/vPosition.w);\n        halfVec = normalize(lightdir + eye);\n      }\n      col = ambient[i];\n      nDotL = dot(n, lightdir);\n      col = col + max(nDotL, 0.) * colDiff.rgb;\n      col = col + pow(max(dot(halfVec, n), 0.), shininess) * specular[i];\n      lighteffect = lighteffect + vec4(col, colDiff.a);\n    }\n#endif\n    \n#else // not IS_LIT\n    vec4 colDiff = vCol;\n    vec4 lighteffect = colDiff;\n#endif\n    \n#ifdef IS_TEXT\n    vec4 textureColor = lighteffect*texture2D(uSampler, vTexcoord);\n#endif\n    \n#ifdef HAS_TEXTURE\n\n// These calculations use the definitions from \n// https://docs.gl/gl3/glTexEnv\n\n#ifdef USE_ENVMAP\n    float m = 2.0 * sqrt(dot(vReflection, vReflection) + 2.0*vReflection.z + 1.0);\n    vec4 textureColor = texture2D(uSampler, vReflection.xy / m + vec2(0.5, 0.5));\n#else\n    vec4 textureColor = texture2D(uSampler, vTexcoord);\n#endif\n\n#ifdef TEXTURE_rgb\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(textureColor.rgb, lighteffect.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = lighteffect*vec4(textureColor.rgb, 1.);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - textureColor.rgb) * lighteffect.rgb, lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(lighteffect.rgb + textureColor.rgb, lighteffect.a);\n#endif\n\n#endif //TEXTURE_rgb\n        \n#ifdef TEXTURE_rgba\n\n#ifdef TEXMODE_replace\n// already done\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = lighteffect*textureColor;\n#endif\n\n#ifdef TEXMODE_decal\n    textureColor = vec4((1. - textureColor.a)*lighteffect.rgb) +\n                     textureColor.a*textureColor.rgb, \n                     lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - textureColor.rgb) * lighteffect.rgb,\n                    lighteffect.a*textureColor.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(lighteffect.rgb + textureColor.rgb,\n                    lighteffect.a*textureColor.a);\n#endif\n    \n#endif //TEXTURE_rgba\n    \n#ifdef TEXTURE_alpha\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(lighteffect.rgb, luminance);\n#endif \n\n#if defined(TEXMODE_modulate) || defined(TEXMODE_blend) || defined(TEXMODE_add)\n    textureColor = vec4(lighteffect.rgb, lighteffect.a*luminance);\n#endif\n \n#endif // TEXTURE_alpha\n    \n// The TEXTURE_luminance values are not from that reference    \n#ifdef TEXTURE_luminance\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(luminance, luminance, luminance, lighteffect.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = vec4(luminance*lighteffect.rgb, lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - luminance)*lighteffect.rgb,\n                        lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(luminance + lighteffect.rgb, lighteffect.a);\n#endif\n\n#endif // TEXTURE_luminance\n \n    \n#ifdef TEXTURE_luminance_alpha\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(luminance, luminance, luminance, textureColor.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = vec4(luminance*lighteffect.rgb, \n                        textureColor.a*lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - luminance)*lighteffect.rgb,\n                        textureColor.a*lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(luminance + lighteffect.rgb, \n                        textureColor.a*lighteffect.a);\n\n#endif\n\n#endif // TEXTURE_luminance_alpha\n    \n    fragColor = textureColor;\n\n#elif defined(IS_TEXT)\n    if (textureColor.a < 0.1)\n      discard;\n    else\n      fragColor = textureColor;\n#else\n    fragColor = lighteffect;\n#endif // HAS_TEXTURE\n    \n#ifdef HAS_FOG\n    // uFogParms elements: x = near, y = far, z = fogscale, w = (1-sin(FOV/2))/(1+sin(FOV/2))\n    // In Exp and Exp2: use density = density/far\n    // fogF will be the proportion of fog\n    // Initialize it to the linear value\n    float fogF;\n    if (uFogMode > 0) {\n      fogF = (uFogParms.y - vPosition.z/vPosition.w)/(uFogParms.y - uFogParms.x);\n      if (uFogMode > 1)\n        fogF = mix(uFogParms.w, 1.0, fogF);\n      fogF = fogF*uFogParms.z;\n      if (uFogMode == 2)\n        fogF = 1.0 - exp(-fogF);\n      // Docs are wrong: use (density*c)^2, not density*c^2\n      // https://gitlab.freedesktop.org/mesa/mesa/-/blob/master/src/mesa/swrast/s_fog.c#L58\n      else if (uFogMode == 3)\n        fogF = 1.0 - exp(-fogF*fogF);\n      fogF = clamp(fogF, 0.0, 1.0);\n      gl_FragColor = vec4(mix(fragColor.rgb, uFogColor, fogF), fragColor.a);\n    } else gl_FragColor = fragColor;\n#else\n    gl_FragColor = fragColor;\n#endif // HAS_FOG\n    \n}","players":[],"webGLoptions":{"preserveDrawingBuffer":true},"fastTransparency":true},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-regroup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: A suggested regrouping of the RESCA-E Subtests.
</figcaption>
</figure>
</div>
</div>
<p>Why might there be a division between narrative/semantic vs.&nbsp;social/syntactic abilities? I can only speculate. The clumping of narrative and semantic abilities evokes the classic division of declarative memory into episodic memory and semantic memory. Why would social and syntactic subtests clump together? This is deeply speculative on my part, but there is a developing body of evidence that Broca’s Area not only is vital for the comprehension of syntax, but also the intentions of others <span class="citation" data-cites="hamzei2003human gentilucci2006repetitive">(<a href="#ref-gentilucci2006repetitive" role="doc-biblioref">Gentilucci et al., 2006</a>; <a href="#ref-hamzei2003human" role="doc-biblioref">Hamzei et al., 2003</a>)</span>. To oversimplify, perhaps the narrative/semantic vs.&nbsp;social/syntactic abilities distinction reflects to some degree the relative health and functioning of Wernicke’s and Broca’s area, respectively.</p>
</section>
</section>
<section id="overall-evaluation-of-the-resca-e" class="level1">
<h1>Overall Evaluation of the RESCA-E</h1>
<p>I have nothing but admiration for the scholarship, artistry, and craft so clearly evident in every aspect of the RESCA-E. Of course, one’s judgment of a test is never final; validity evidence for the RESCA-E, though so far encouraging, is still quite sparse. Nevertheless, I expect that future validation research will justify the painstaking effort that went into developing the RESCA-E, and that it will show the RESCA-E to be a sensitive and powerful tool in the assessment of language abilities</p>
</section>
<section id="references" class="level1 unnumbered invisible">
<h1 class="unnumbered invisible">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-Carroll1993" class="csl-entry" role="listitem">
Carroll, J. B. (1993). <em>Human cognitive abilities: A survey of factor-analytic studies</em>. Cambridge University Press.
</div>
<div id="ref-Carroll1998" class="csl-entry" role="listitem">
Carroll, J. B. (1998). Human cognitive abilities: A critique. In J. J. McArdle &amp; R. W. Woodcock (Eds.), <em>Human cognitive abilities in theory and practice</em> (pp. 5–24). Erlbaum.
</div>
<div id="ref-Carroll2003" class="csl-entry" role="listitem">
Carroll, J. B. (2003). The higher-stratum structure of cognitive abilities: Current evidence supports <em>g</em> and about ten broad factors. In H. Nyborg (Ed.), <em>The scientific study of general intelligence: Tribute to <span>A</span>rthur <span>R</span>. <span>J</span>ensen</em> (pp. 5–22). Pergamon.
</div>
<div id="ref-crawford2010evaluation" class="csl-entry" role="listitem">
Crawford, A. V., Green, S. B., Levy, R., Lo, W.-J., Scott, L., Svetina, D., &amp; Thompson, M. S. (2010). Evaluation of parallel analysis methods for determining the number of factors. <em>Educational and Psychological Measurement</em>, <em>70</em>(6), 885–901. <a href="https://doi.org/10.1177/0013164410379332">https://doi.org/10.1177/0013164410379332</a>
</div>
<div id="ref-gentilucci2006repetitive" class="csl-entry" role="listitem">
Gentilucci, M., Bernardis, P., Crisi, G., &amp; Dalla Volta, R. (2006). Repetitive transcranial magnetic stimulation of <span>B</span>roca’s area affects verbal responses to gesture observation. <em>Journal of Cognitive Neuroscience</em>, <em>18</em>(7), 1059–1074.
</div>
<div id="ref-grodzinsky2000neurology" class="csl-entry" role="listitem">
Grodzinsky, Y. (2000). The neurology of syntax: Language use without <span>B</span>roca’s area. <em>Behavioral and Brain Sciences</em>, <em>23</em>(1), 1–21.
</div>
<div id="ref-Guilford1967" class="csl-entry" role="listitem">
Guilford, J. P. (1967). <em>The nature of human intelligence.</em> McGraw-Hill.
</div>
<div id="ref-hamzei2003human" class="csl-entry" role="listitem">
Hamzei, F., Rijntjes, M., Dettmers, C., Glauche, V., Weiller, C., &amp; Büchel, C. (2003). The human action recognition system and its relationship to <span>B</span>roca’s area: An fMRI study. <em>Neuroimage</em>, <em>19</em>(3), 637–644.
</div>
<div id="ref-MacCann2014" class="csl-entry" role="listitem">
MacCann, C., Joseph, D. L., Newman, D. A., &amp; Roberts, R. D. (2014). Emotional intelligence is a second-stratum factor of intelligence: Evidence from hierarchical and bifactor models. <em>Emotion</em>, <em>14</em>(2), 358–374.
</div>
<div id="ref-Mayer2008a" class="csl-entry" role="listitem">
Mayer, J. D., Roberts, R. D., &amp; Barsade, S. G. (2008). Human abilities: Emotional intelligence. <em>Annual Review of Psychology</em>, <em>59</em>, 507–536.
</div>
<div id="ref-Mayer2002" class="csl-entry" role="listitem">
Mayer, J. D., Salovey, P., &amp; Caruso, D. R. (2002). <em><span class="nocase">Mayer-Salovey-Caruso Emotional Intelligence Test (MSCEIT) user’s manual</span></em>. Multi-Health Systems.
</div>
<div id="ref-McGrew2005" class="csl-entry" role="listitem">
McGrew, K. S. (2005). The <span>C</span>attell-<span>H</span>orn-<span>C</span>arroll <span>T</span>heory of <span>C</span>ognitive <span>A</span>bilities: Past, present, and future. In D. P. Flanagan &amp; P. L. Harrison (Eds.), <em>Contemporary intellectual assessment. Theories, tests, and issues</em> (2nd ed., pp. 136–181). Guilford Press.
</div>
<div id="ref-revelle2016psych" class="csl-entry" role="listitem">
Revelle, W. (2016). <em><span class="nocase">psych</span>: Procedures for psychological, psychometric, and personality research</em>. Northwestern University.
</div>
<div id="ref-schneider2013principles" class="csl-entry" role="listitem">
Schneider, W. J. (2013). Principles of assessment of aptitude and achievement. In D. Saklofske, C. Reynolds, &amp; V. Schwean (Eds.), <em>The <span>O</span>xford handbook of child psychological assessment</em> (pp. 286–330). Oxford University Press. <a href="https://doi.org/10.1093/oxfordhb/9780199796304.013.0013">https://doi.org/10.1093/oxfordhb/9780199796304.013.0013</a>
</div>
<div id="ref-Schneider2015a" class="csl-entry" role="listitem">
Schneider, W. J., &amp; Flanagan, D. P. (2015). The relationship between theories of intelligence and intelligence tests. In S. Goldstein, D. Princiotta, &amp; J. A. Naglieri (Eds.), <em>Handbook of intelligence: Evolutionary theory, historical perspective, and current concepts</em> (pp. 317–340). Springer.
</div>
<div id="ref-schneider2016integrating" class="csl-entry" role="listitem">
Schneider, W. J., Mayer, J. D., &amp; Newman, D. A. (2016). Integrating hot and cool intelligences: Thinking broadly about broad abilities. <em>Journal of Intelligence</em>, <em>4</em>(1), 1:1–25. <a href="https://doi.org/10.3390/jintelligence4010001">https://doi.org/10.3390/jintelligence4010001</a>
</div>
<div id="ref-Schneider2012" class="csl-entry" role="listitem">
Schneider, W. J., &amp; McGrew, K. S. (2012). The <span>C</span>attell-<span>H</span>orn-<span>C</span>arroll model of intelligence. In D. P. Flanagan &amp; P. L. Harrison (Eds.), <em>Contemporary intellectual assessment: Theories, tests and issues</em> (3rd ed., pp. 99–144). Guilford Press.
</div>
<div id="ref-Wechsler1958" class="csl-entry" role="listitem">
Wechsler, D. (1958). <em>The measurement and appraisal of adult intelligence</em> (4th ed.). Williams &amp; Wilkins.
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{schneider2016,
  author = {Schneider, W. Joel and Joel Schneider, W.},
  title = {The {RESCA-E} {Subtests} {Are} {Thoughtfully} {Designed} and
    {Highly} {Refined} {Measures} of {CHC} {Constructs}},
  date = {2016-10-26},
  url = {https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-schneider2016" class="csl-entry quarto-appendix-citeas" role="listitem">
Schneider, W. J., &amp; Joel Schneider, W. (2016, October 26). The
RESCA-E Subtests Are Thoughtfully Designed and Highly Refined Measures
of CHC Constructs. <em>AssessingPsyche</em>. <a href="https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE.html">https://wjschne.github.io/AssessingPsyche/2016-10-26-rescae/RESCAE.html</a>
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/wjschne\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>